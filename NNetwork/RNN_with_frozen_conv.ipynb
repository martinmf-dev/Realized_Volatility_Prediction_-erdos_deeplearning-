{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77e9ebe",
   "metadata": {},
   "source": [
    "## RNN with frozen convolution layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6b854e",
   "metadata": {},
   "source": [
    "The idea is inspired by an application of RNN in predicting if an online review (say, for a product) is positive or negative (1 or 0). Each word in the review sentence is first projected to a large dimension vector space and then sent into an RNN network sequentially. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f6b66b",
   "metadata": {},
   "source": [
    "We will make use of frozen convolution layer to create derivative like features for our time series features. Then, we use the derivative values of a certain time as if a \"word\" in a \"review\", the target RV as if the \"score\" of the \"review\" to train an RNN network that predicts the target RV with the time series features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bd88f7",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "907e47ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from proj_mod import training, data_processing\n",
    "importlib.reload(training);\n",
    "importlib.reload(data_processing);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12efccd",
   "metadata": {},
   "source": [
    "Below is what Yuan needed to get his gpu working, do not run if you do not need it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd83d5f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m load_dotenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../dotenv_env/deep_learning.env\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"../dotenv_env/deep_learning.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd9ea17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.3.0\n"
     ]
    }
   ],
   "source": [
    "print(os.environ.get(\"HSA_OVERRIDE_GFX_VERSION\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cb26cd",
   "metadata": {},
   "source": [
    "Let's say, we have following timeseries feature (created randomly), we will create the derivative features first. As a reminder, the zero dimension is the batch size, the dimension one is channel (needed for the first convolution layer, not really a \"thing\" for time series like features). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3d0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_feature=torch.randn(1,1,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b28d5ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6195, -0.6389, -0.1555, -0.3383,  0.0798, -1.6650,  1.1695,\n",
       "          -0.2593,  1.7058,  0.2396,  0.4143, -2.1079, -0.7786,  0.8063,\n",
       "          -1.2070,  0.1275, -1.1544, -1.7544,  0.6644, -0.6037, -0.3678,\n",
       "           0.1948, -1.8461,  0.4062,  0.4913,  0.3940,  1.2150, -1.6215,\n",
       "           0.2274, -1.1374, -0.2868,  0.5215, -1.2731, -0.7222,  2.1310,\n",
       "           0.0263, -0.4286, -1.1935,  2.1196, -0.3426,  0.5490, -0.7507,\n",
       "          -0.2163,  0.7056,  0.3744, -2.0829,  0.8318,  0.5373,  0.6641,\n",
       "          -1.2179, -0.4955, -0.5833, -0.0965,  0.4021,  0.2072, -0.6592,\n",
       "          -0.1757, -1.8129, -0.4105, -0.4676]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "739b2fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_create_diff=training.frozen_diff_conv(n_diff=4)\n",
    "ts_diff_feature=conv_create_diff(ts_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c48f9ca2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6195e+00, -6.3887e-01, -1.5554e-01, -3.3828e-01,  7.9807e-02,\n",
       "          -1.6650e+00,  1.1695e+00, -2.5925e-01,  1.7058e+00,  2.3961e-01,\n",
       "           4.1431e-01, -2.1079e+00, -7.7858e-01,  8.0633e-01, -1.2070e+00,\n",
       "           1.2753e-01, -1.1544e+00, -1.7544e+00,  6.6437e-01, -6.0370e-01,\n",
       "          -3.6780e-01,  1.9476e-01, -1.8461e+00,  4.0624e-01,  4.9125e-01,\n",
       "           3.9399e-01,  1.2150e+00, -1.6215e+00,  2.2744e-01, -1.1374e+00,\n",
       "          -2.8682e-01,  5.2154e-01, -1.2731e+00, -7.2217e-01,  2.1310e+00,\n",
       "           2.6333e-02, -4.2858e-01, -1.1935e+00,  2.1196e+00, -3.4262e-01,\n",
       "           5.4896e-01, -7.5067e-01, -2.1627e-01,  7.0559e-01,  3.7443e-01,\n",
       "          -2.0829e+00,  8.3176e-01,  5.3735e-01,  6.6414e-01, -1.2179e+00,\n",
       "          -4.9555e-01, -5.8328e-01, -9.6545e-02,  4.0210e-01,  2.0719e-01,\n",
       "          -6.5925e-01, -1.7569e-01, -1.8129e+00, -4.1051e-01, -4.6761e-01],\n",
       "         [-2.2584e+00,  4.8334e-01, -1.8275e-01,  4.1809e-01, -1.7448e+00,\n",
       "           2.8345e+00, -1.4288e+00,  1.9651e+00, -1.4662e+00,  1.7470e-01,\n",
       "          -2.5222e+00,  1.3293e+00,  1.5849e+00, -2.0134e+00,  1.3346e+00,\n",
       "          -1.2819e+00, -5.9996e-01,  2.4187e+00, -1.2681e+00,  2.3589e-01,\n",
       "           5.6257e-01, -2.0409e+00,  2.2524e+00,  8.5012e-02, -9.7262e-02,\n",
       "           8.2102e-01, -2.8365e+00,  1.8489e+00, -1.3649e+00,  8.5060e-01,\n",
       "           8.0836e-01, -1.7947e+00,  5.5097e-01,  2.8532e+00, -2.1047e+00,\n",
       "          -4.5491e-01, -7.6488e-01,  3.3130e+00, -2.4622e+00,  8.9158e-01,\n",
       "          -1.2996e+00,  5.3440e-01,  9.2187e-01, -3.3116e-01, -2.4573e+00,\n",
       "           2.9146e+00, -2.9441e-01,  1.2680e-01, -1.8821e+00,  7.2238e-01,\n",
       "          -8.7733e-02,  4.8674e-01,  4.9864e-01, -1.9491e-01, -8.6643e-01,\n",
       "           4.8356e-01, -1.6372e+00,  1.4024e+00, -5.7104e-02,  0.0000e+00],\n",
       "         [ 2.7417e+00, -6.6608e-01,  6.0083e-01, -2.1629e+00,  4.5793e+00,\n",
       "          -4.2633e+00,  3.3938e+00, -3.4313e+00,  1.6409e+00, -2.6969e+00,\n",
       "           3.8515e+00,  2.5562e-01, -3.5983e+00,  3.3479e+00, -2.6165e+00,\n",
       "           6.8196e-01,  3.0187e+00, -3.6868e+00,  1.5040e+00,  3.2667e-01,\n",
       "          -2.6035e+00,  4.2932e+00, -2.1674e+00, -1.8227e-01,  9.1828e-01,\n",
       "          -3.6575e+00,  4.6854e+00, -3.2138e+00,  2.2155e+00, -4.2240e-02,\n",
       "          -2.6030e+00,  2.3457e+00,  2.3022e+00, -4.9578e+00,  1.6498e+00,\n",
       "          -3.0997e-01,  4.0779e+00, -5.7752e+00,  3.3538e+00, -2.1912e+00,\n",
       "           1.8340e+00,  3.8747e-01, -1.2530e+00, -2.1261e+00,  5.3719e+00,\n",
       "          -3.2090e+00,  4.2121e-01, -2.0089e+00,  2.6044e+00, -8.1011e-01,\n",
       "           5.7447e-01,  1.1906e-02, -6.9355e-01, -6.7152e-01,  1.3500e+00,\n",
       "          -2.1208e+00,  3.0396e+00, -1.4595e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-3.4078e+00,  1.2669e+00, -2.7637e+00,  6.7423e+00, -8.8426e+00,\n",
       "           7.6571e+00, -6.8251e+00,  5.0722e+00, -4.3378e+00,  6.5483e+00,\n",
       "          -3.5958e+00, -3.8539e+00,  6.9462e+00, -5.9644e+00,  3.2984e+00,\n",
       "           2.3367e+00, -6.7055e+00,  5.1907e+00, -1.1773e+00, -2.9301e+00,\n",
       "           6.8967e+00, -6.4606e+00,  1.9851e+00,  1.1006e+00, -4.5758e+00,\n",
       "           8.3429e+00, -7.8992e+00,  5.4292e+00, -2.2577e+00, -2.5608e+00,\n",
       "           4.9487e+00, -4.3453e-02, -7.2600e+00,  6.6076e+00, -1.9597e+00,\n",
       "           4.3879e+00, -9.8532e+00,  9.1290e+00, -5.5450e+00,  4.0252e+00,\n",
       "          -1.4466e+00, -1.6405e+00, -8.7309e-01,  7.4980e+00, -8.5809e+00,\n",
       "           3.6302e+00, -2.4301e+00,  4.6133e+00, -3.4146e+00,  1.3846e+00,\n",
       "          -5.6256e-01, -7.0546e-01,  2.2026e-02,  2.0215e+00, -3.4708e+00,\n",
       "           5.1604e+00, -4.4991e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 4.6747e+00, -4.0307e+00,  9.5060e+00, -1.5585e+01,  1.6500e+01,\n",
       "          -1.4482e+01,  1.1897e+01, -9.4100e+00,  1.0886e+01, -1.0144e+01,\n",
       "          -2.5807e-01,  1.0800e+01, -1.2911e+01,  9.2629e+00, -9.6171e-01,\n",
       "          -9.0422e+00,  1.1896e+01, -6.3680e+00, -1.7528e+00,  9.8268e+00,\n",
       "          -1.3357e+01,  8.4457e+00, -8.8452e-01, -5.6763e+00,  1.2919e+01,\n",
       "          -1.6242e+01,  1.3328e+01, -7.6869e+00, -3.0310e-01,  7.5095e+00,\n",
       "          -4.9921e+00, -7.2166e+00,  1.3868e+01, -8.5673e+00,  6.3476e+00,\n",
       "          -1.4241e+01,  1.8982e+01, -1.4674e+01,  9.5702e+00, -5.4718e+00,\n",
       "          -1.9394e-01,  7.6741e-01,  8.3711e+00, -1.6079e+01,  1.2211e+01,\n",
       "          -6.0603e+00,  7.0434e+00, -8.0279e+00,  4.7991e+00, -1.9471e+00,\n",
       "          -1.4289e-01,  7.2748e-01,  1.9995e+00, -5.4923e+00,  8.6311e+00,\n",
       "          -9.6594e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_diff_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79075913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 60])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_diff_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3354b4",
   "metadata": {},
   "source": [
    "We now permute the last two dimensions, essentially, this is just a transposition of the last two dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76682d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_diff_feature=ts_diff_feature.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed4b060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_diff_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cff150",
   "metadata": {},
   "source": [
    "Now, this is a batch (of size 1) of timeseries feature with 60 time steps, and 5 features in each step. We then expand the 5 features, say, to 32 by projection. As a reminder, nn.Linear automatically apply to the last dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b7d96c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_proj=nn.Linear(5,32)\n",
    "ts_feature_proj=linear_proj(ts_diff_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33f82b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_feature_proj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e40c151",
   "metadata": {},
   "source": [
    "In this example, we will not go into too much detail, so let's make the most simple version. We then pass through a layer of RNN, then a layer of linear (to project to dimension 1 again). Learn more about RNN at https://docs.pytorch.org/docs/stable/generated/torch.nn.RNN.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f611ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_layer=nn.RNN(input_size=32,hidden_size=32,num_layers=1,nonlinearity=\"tanh\",batch_first=True,dropout=0)\n",
    "linear_end=nn.Linear(32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "207568f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_out=RNN_layer(ts_feature_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc91386",
   "metadata": {},
   "source": [
    "As a reminder, since no training is done, the RNN basically just applies the initial weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f31dfe8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e423255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_proj=linear_end(RNN_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ba4ee6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_proj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22784470",
   "metadata": {},
   "source": [
    "We will use sum, but we may change this to other functions, according to context or just feeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e293bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_out=torch.sum(out_proj,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b35c7bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2557]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b9f52c",
   "metadata": {},
   "source": [
    "## Creating the actual NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4d007bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created 07/02/25\n",
    "#07/02/25: Moved to training.py \n",
    "#07/08/25: Moved from training.py\n",
    "class RV_RNN_conv(nn.Module):        \n",
    "    #Created 07/02/25 see RNN_with_frozen_conv.ipynb for documentation. \n",
    "    #Modified 07/08/25 Added LSTM and GRU options\n",
    "    def __init__(self,n_diff,rnn_num_layer,rnn_drop_out,rnn_type=\"rnn\",rnn_act=\"tanh\",proj_dim=32,rnn_hidden_size=32,input_scaler=10000):\n",
    "        \"\"\"\n",
    "        :param n_diff: Decides how many derivative features is wanted in the time series. \n",
    "        :param rnn_num_layer: num_layer parameter for rnn. \n",
    "        :param rnn_drop_out: dropout parameter for rnn. \n",
    "        :param rnn_act: Defaulted to \"tanh\". Nonlinearity parameter for rnn. \n",
    "        :param proj_dim: Defaulted to 32. Decided the dimension of projection before feeding into rnn. \n",
    "        :param rnn_hidden_size: Defaulted to 32. The hidden_size parameter for rnn. \n",
    "        :param input_scaler: Defaulted to 10000. Set a scaling to input, a lot of timeseries values of our data are extremely close to zero. \n",
    "        :param rnn_type: 'rnn', 'lstm', or 'gru'\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_scaler=input_scaler\n",
    "        self.frozen_conv=frozen_diff_conv(n_diff=n_diff)\n",
    "        self.linear_proj_input=nn.Linear(n_diff+1,proj_dim)\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "\n",
    "        if rnn_type == \"rnn\":\n",
    "            self.RNN_layer=nn.RNN(input_size=proj_dim,\n",
    "                                  hidden_size=rnn_hidden_size,\n",
    "                                  num_layers=rnn_num_layer,\n",
    "                                  nonlinearity=rnn_act,\n",
    "                                  batch_first=True,\n",
    "                                  dropout=rnn_drop_out)\n",
    "        elif rnn_type == \"lstm\":\n",
    "            if rnn_act is not None:\n",
    "                print(f\"Warning: rnn_act='{rnn_act}' is ignored when using rnn_type='lstm'\")\n",
    "            self.RNN_layer = nn.LSTM(input_size=proj_dim,\n",
    "                                     hidden_size=rnn_hidden_size,\n",
    "                                     num_layers=rnn_num_layer,\n",
    "                                     batch_first=True,\n",
    "                                     dropout=rnn_drop_out)\n",
    "        elif rnn_type == \"gru\":\n",
    "            if rnn_act is not None:\n",
    "                print(f\"Warning: rnn_act='{rnn_act}' is ignored when using rnn_type='gru'\")\n",
    "            self.RNN_layer = nn.GRU(input_size=proj_dim,\n",
    "                                    hidden_size=rnn_hidden_size,\n",
    "                                    num_layers=rnn_num_layer,\n",
    "                                    batch_first=True,\n",
    "                                    dropout=rnn_drop_out)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported rnn_type: {rnn_type}\")\n",
    "        \n",
    "        self.linear_post_rnn=nn.Linear(rnn_hidden_size,1)\n",
    "        self.frozen_list=[\"frozen_conv\"] \n",
    "        \n",
    "    def forward(self,x):\n",
    "        #First, scale the input, and unsqueese to add in one dimension in dim 1 as channel. This is needed for convolution. \n",
    "        x*=self.input_scaler\n",
    "        x=torch.unsqueeze(x,dim=1)\n",
    "        x=self.frozen_conv(x)\n",
    "        x=x.permute(0,2,1)\n",
    "        x=self.linear_proj_input(x)\n",
    "        x=self.RNN_layer(x)[0]\n",
    "        x=self.linear_post_rnn(x)\n",
    "        \n",
    "        return torch.sum(x,dim=1)/self.input_scaler\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71432b31",
   "metadata": {},
   "source": [
    "## Basic testing on the RNN with frozen convolution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9583750",
   "metadata": {},
   "source": [
    "Test it first. As a reminder, the expected input dimensions are (Batch Size, Time Series Length), this is distinct from the example above in that the channel dimension is not present. The channel dimension is added with unsqueeze at dimension 1 so that the first convolution layer can be utilized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df3d8c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_feature=torch.randn(10,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a33fd643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.9971e-01, -1.3001e-01, -1.1403e+00, -7.7236e-01,  1.8599e+00,\n",
       "         -6.9808e-01,  1.5106e+00, -1.4802e+00, -3.9169e-01, -3.1802e-02,\n",
       "         -1.1092e+00,  4.7330e-01,  7.7057e-02, -6.1030e-02,  4.4273e-02,\n",
       "          1.1545e+00,  1.6664e+00, -2.5811e-01, -1.0196e+00,  3.4227e-01,\n",
       "          9.0611e-02, -7.1442e-01, -5.1483e-01,  6.6749e-01,  1.6236e+00,\n",
       "         -1.5389e+00, -7.6098e-01, -6.0926e-01,  1.5119e+00,  1.4623e+00,\n",
       "         -1.8738e+00, -1.0195e+00,  5.1206e-01,  6.5966e-01,  2.5789e-02,\n",
       "         -1.6673e-01, -3.5891e-01, -1.8669e+00, -2.8837e-01,  7.1051e-01,\n",
       "          8.5181e-01,  1.8687e-01,  6.3762e-01, -2.0904e-01, -1.0262e+00,\n",
       "         -6.2161e-01,  1.8408e+00, -1.6856e+00,  5.2398e-01, -5.6024e-01,\n",
       "          1.3300e-01,  1.2988e+00,  7.8794e-02,  4.5463e-02, -3.4238e-01,\n",
       "         -9.0760e-01, -1.3707e+00, -4.4723e-01, -2.9356e-01, -6.8926e-01],\n",
       "        [ 1.4308e+00,  5.3982e-01, -5.7762e-02,  7.6088e-01, -4.5305e-01,\n",
       "          3.6230e-01,  2.3692e-01,  1.2783e+00, -3.0438e-01,  4.8155e-01,\n",
       "         -9.4604e-02, -5.2999e-02,  7.0097e-01, -1.3007e+00, -8.7723e-01,\n",
       "          7.4288e-02, -2.6345e-01,  5.9917e-02, -1.4569e-01,  1.7438e+00,\n",
       "         -7.0533e-01,  1.8248e-01,  6.2562e-01, -1.1259e-01, -6.2901e-01,\n",
       "          4.4033e-01, -4.3137e-01,  1.1272e-02, -2.5805e-01, -4.9702e-01,\n",
       "          1.3716e+00, -3.2789e-01,  3.0504e-01, -8.9711e-01,  2.3774e+00,\n",
       "          1.6353e+00, -1.2243e+00,  1.6841e-01,  7.3736e-01, -1.0567e+00,\n",
       "         -1.0988e+00, -8.9903e-01,  1.6964e-01, -1.3469e+00,  6.7174e-02,\n",
       "         -1.0021e+00,  3.9571e-01,  8.8042e-01, -1.5078e+00,  3.5894e-01,\n",
       "          3.3802e-01,  3.0487e-01,  3.4259e-01, -3.8630e-01, -2.4155e-02,\n",
       "          7.3312e-01,  8.7817e-01, -8.2768e-01, -2.9355e-01,  3.3061e-01],\n",
       "        [ 2.5318e-01,  3.8102e-01,  2.6876e+00, -3.9484e-01, -2.3881e-01,\n",
       "          6.8641e-02,  5.9486e-01, -1.4737e+00,  7.0669e-01,  1.5046e+00,\n",
       "          5.9085e-01,  1.4933e+00, -2.1005e-01,  1.3130e+00, -9.1704e-01,\n",
       "         -1.1039e+00,  1.4833e+00,  4.7081e-02,  2.2842e-01,  4.6167e-01,\n",
       "         -1.0363e-01,  6.6925e-01, -1.5840e+00,  6.5668e-02, -1.4168e+00,\n",
       "         -1.2486e+00, -1.8272e+00,  1.8112e+00,  6.1650e-01, -1.1103e-01,\n",
       "         -1.8234e-01,  5.7363e-02,  8.6665e-01, -2.0815e+00,  4.1343e-01,\n",
       "         -4.2743e-01,  2.8909e-01,  9.4002e-01,  5.8888e-01,  1.6420e-02,\n",
       "         -8.4871e-02,  3.4691e-01, -9.5851e-01, -1.0034e+00, -1.3980e-01,\n",
       "         -4.1359e-01, -1.7873e+00, -9.6459e-01,  3.7664e-01,  1.8563e+00,\n",
       "          1.9582e+00,  8.4362e-01,  1.0092e+00,  1.4458e-03, -8.9394e-02,\n",
       "         -2.7246e+00, -6.4128e-01, -1.9199e+00, -3.2695e-01, -5.1117e-02],\n",
       "        [-1.2159e-01, -9.3231e-01, -9.6076e-01,  1.6190e+00,  1.5291e+00,\n",
       "         -4.0395e-01,  7.7714e-01,  1.8677e+00,  7.4954e-01, -1.0456e+00,\n",
       "         -1.4263e+00, -3.0523e-01,  6.0739e-01, -7.2510e-01, -1.8583e+00,\n",
       "         -1.3546e+00, -2.8826e-01,  1.0497e+00,  9.0350e-01, -1.5834e+00,\n",
       "         -1.6264e-01, -2.9454e-01, -1.1195e+00,  8.4818e-01, -6.9007e-01,\n",
       "         -7.8531e-01,  5.0420e-01, -8.7133e-01, -6.6761e-02, -1.1322e+00,\n",
       "          1.3554e+00, -1.2367e-01,  1.7541e+00, -4.7034e-01,  1.3373e+00,\n",
       "          2.4652e-01, -1.1514e+00,  5.9967e-01, -1.0854e+00, -4.6820e-01,\n",
       "          1.1397e+00, -9.3558e-02, -6.7728e-01, -1.7160e+00,  1.4537e+00,\n",
       "          9.9533e-01,  1.7130e+00,  7.6425e-01, -2.5230e+00,  1.2070e+00,\n",
       "          1.0142e+00, -9.4738e-02, -1.1420e-01, -9.2427e-01,  2.3712e-01,\n",
       "          1.4228e-01,  4.5694e-01,  6.2191e-01,  1.8468e+00, -9.8112e-01],\n",
       "        [ 1.1306e+00,  8.3529e-01, -2.9954e-01, -4.7112e-01, -2.0877e-01,\n",
       "         -4.8950e-03, -7.8825e-01,  1.4376e+00,  8.9070e-01,  5.7410e-01,\n",
       "         -2.1297e+00,  2.0067e+00, -4.7687e-01, -1.6458e-02, -1.0851e+00,\n",
       "          1.0390e+00, -1.5669e+00,  5.4534e-01,  8.1195e-03,  7.4603e-01,\n",
       "          1.7752e+00, -2.3654e-02,  5.3764e-01,  7.7837e-01,  1.7001e-01,\n",
       "          5.3340e-01,  8.1639e-01,  5.8233e-02,  2.0643e+00,  9.8667e-01,\n",
       "          3.8659e-01, -1.8921e+00, -1.5634e+00, -1.3588e+00,  7.2107e-01,\n",
       "         -3.4673e-01,  1.0420e+00, -1.3223e+00, -2.3510e-01,  7.3066e-01,\n",
       "          1.4870e-01, -1.6533e+00, -5.8012e-01,  2.5478e+00, -2.4914e-01,\n",
       "          6.1622e-01, -3.0964e-01, -7.9378e-01,  6.9507e-01,  8.6993e-01,\n",
       "          2.0109e+00,  1.2179e+00, -1.4531e+00, -6.3152e-01, -1.0339e+00,\n",
       "          7.5825e-02,  7.8944e-01,  4.8174e-01,  1.1309e+00,  1.0797e+00],\n",
       "        [ 7.7379e-01, -1.0015e+00, -6.1293e-01, -4.6681e-01, -4.5193e-01,\n",
       "          2.1192e+00,  9.8311e-01,  7.3992e-01, -8.6174e-01,  8.6770e-01,\n",
       "         -3.8720e-01,  8.5517e-02, -8.4072e-01,  9.0587e-01, -5.6736e-01,\n",
       "          2.3657e-01, -5.1644e-01, -8.5824e-01,  1.0341e+00, -1.1768e+00,\n",
       "          9.0630e-01, -6.1566e-02, -8.9221e-02, -4.8559e-01, -1.4921e+00,\n",
       "          9.0793e-01,  7.9805e-01, -1.7393e+00, -3.4292e-02,  1.2818e+00,\n",
       "         -3.2004e+00,  9.9491e-02, -1.3688e+00, -1.2971e+00,  2.6267e-01,\n",
       "          9.5438e-01, -1.4132e+00,  1.8926e+00,  7.1759e-01, -1.9862e+00,\n",
       "         -9.0729e-01, -7.5776e-01, -7.7266e-01, -6.4274e-01, -1.7269e-01,\n",
       "          1.2985e-01,  4.4351e-02,  1.7689e-01,  7.7345e-01, -1.0645e+00,\n",
       "          6.4652e-01, -1.5979e+00,  6.0500e-01, -1.0385e+00, -2.3670e+00,\n",
       "         -4.2446e-01,  1.4906e+00, -7.9251e-01,  9.9229e-01, -1.5774e+00],\n",
       "        [ 5.0177e-01,  2.4106e-01, -6.5872e-01,  1.0902e-01,  5.8086e-01,\n",
       "          1.9186e+00, -2.1326e+00, -6.2231e-01, -2.3593e-01,  1.7025e-01,\n",
       "          1.4749e+00, -9.4292e-01,  1.4547e-01,  9.4311e-01, -8.5379e-01,\n",
       "         -2.2129e-01, -1.3732e+00,  1.3589e+00,  4.6782e-01, -8.9807e-01,\n",
       "          4.7402e-01,  9.1744e-01, -3.2876e-01,  5.9779e-02, -6.4242e-01,\n",
       "          6.8333e-01,  8.7154e-01, -2.3882e-01, -1.0712e+00,  3.9495e-01,\n",
       "          9.2707e-01, -3.0983e-01, -9.8542e-01, -3.6934e-02,  2.6743e+00,\n",
       "          1.0013e+00,  1.1709e-01,  1.5947e-02,  3.3760e-01, -3.6029e-01,\n",
       "         -9.8500e-01,  6.7139e-02, -1.4012e+00,  2.3760e+00,  9.4070e-01,\n",
       "          4.0330e-01,  7.5822e-01,  8.5953e-01,  2.1727e-03,  2.1302e+00,\n",
       "         -8.0883e-01, -6.9155e-01, -6.3846e-01,  3.0520e-01,  7.0363e-01,\n",
       "         -3.8721e-01, -7.9320e-02, -3.1789e-01,  1.6018e+00, -1.7475e-01],\n",
       "        [ 4.8490e-01, -1.3485e+00, -5.2845e-01,  5.3322e-02, -1.4477e+00,\n",
       "          9.9759e-01, -1.8074e+00,  5.3383e-01, -9.1542e-01,  1.7862e+00,\n",
       "          2.3016e-01,  8.7560e-02, -1.2497e+00,  6.4770e-01,  1.8212e-01,\n",
       "         -1.4018e+00,  8.9644e-01, -3.1460e-01, -2.0938e-01, -7.8133e-01,\n",
       "         -7.5440e-01,  1.2900e-01, -7.9421e-01, -3.7794e-01, -6.4391e-01,\n",
       "          1.0784e+00, -3.2008e-01,  1.4775e+00, -1.3190e+00, -1.1476e-01,\n",
       "          7.4479e-01, -3.8717e-01,  1.5714e+00, -1.8139e+00,  1.0767e+00,\n",
       "         -1.9131e-01, -3.9009e-01,  6.7437e-01,  1.9352e-01,  1.2796e+00,\n",
       "          8.4135e-01, -1.4779e-01,  1.2561e+00,  1.0188e+00, -2.6481e-01,\n",
       "         -8.8988e-01, -2.6440e-01,  3.8843e-01,  1.8583e+00,  6.6880e-01,\n",
       "         -3.5173e-01,  7.0168e-01,  6.8942e-03,  8.2315e-01, -5.4192e-01,\n",
       "          3.9011e-01, -2.0729e+00,  2.0115e-01, -1.0041e+00,  1.4397e+00],\n",
       "        [-5.4609e-01, -4.4945e-01,  8.4361e-01,  9.1256e-01, -2.1864e-01,\n",
       "          1.4071e+00,  9.5832e-01,  1.1638e+00,  4.8710e-01,  1.4185e+00,\n",
       "         -5.6033e-01,  5.4311e-01, -1.0688e+00, -6.0023e-02, -4.0872e-01,\n",
       "          7.2920e-01,  3.6835e-01,  1.2659e+00, -9.8012e-01,  1.3341e-01,\n",
       "          4.7883e-01, -3.3977e-01, -3.3112e-02,  1.7383e+00, -1.0779e-01,\n",
       "          6.0118e-01, -7.4359e-01,  2.2610e-02, -7.3870e-01,  8.4551e-01,\n",
       "          3.0700e-01, -1.1002e-01,  9.7740e-01, -1.0727e+00,  1.0603e-01,\n",
       "          4.6367e-01,  4.9650e-01, -1.1421e-01, -1.8990e-01, -3.7088e-01,\n",
       "         -1.0236e+00, -4.6599e-02, -1.7324e-01, -7.4255e-02,  6.5932e-01,\n",
       "          1.0170e+00,  1.3835e+00,  1.2800e+00, -3.1610e-01, -5.9489e-01,\n",
       "          8.0888e-01,  7.8598e-01,  2.4849e-01, -1.0180e+00,  7.3784e-01,\n",
       "          3.8891e-01, -4.3239e-01,  1.6123e+00,  1.9342e-01,  1.8111e+00],\n",
       "        [ 1.0528e+00,  1.5704e+00,  1.9603e-03, -1.4646e+00, -7.5266e-01,\n",
       "          1.3770e-01, -1.9638e-01, -2.8527e-01,  1.1037e+00, -1.8202e+00,\n",
       "         -5.3344e-01,  9.3706e-02, -1.7282e+00,  4.0101e-01,  1.5522e+00,\n",
       "         -7.6144e-01,  1.1975e+00,  1.1506e+00, -1.7320e+00,  3.1218e-01,\n",
       "         -5.2718e-01,  1.3342e-01,  4.5582e-01, -1.1597e+00, -6.2798e-01,\n",
       "          5.8446e-02,  2.7572e-01,  1.1971e+00,  1.5550e+00, -1.8516e+00,\n",
       "         -7.1024e-01,  4.1439e-01,  7.8271e-01,  1.0857e+00, -5.0055e-01,\n",
       "         -1.8306e+00,  6.7957e-02, -5.3453e-01, -1.3076e-01,  1.4755e+00,\n",
       "          5.7825e-01,  1.9042e+00,  3.1708e-01, -8.3081e-01,  1.7181e-01,\n",
       "          3.1793e-02,  1.8867e-01,  1.6538e+00,  3.2521e-02,  2.5793e-01,\n",
       "         -1.6234e-02, -8.3267e-01, -2.0775e+00, -8.5538e-01,  3.1289e-02,\n",
       "          4.3229e-01,  7.8150e-01, -1.9540e+00,  4.6232e-01,  1.4607e+00]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72cd7276",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.9971e-01, -1.3001e-01, -1.1403e+00, -7.7236e-01,  1.8599e+00,\n",
       "          -6.9808e-01,  1.5106e+00, -1.4802e+00, -3.9169e-01, -3.1802e-02,\n",
       "          -1.1092e+00,  4.7330e-01,  7.7057e-02, -6.1030e-02,  4.4273e-02,\n",
       "           1.1545e+00,  1.6664e+00, -2.5811e-01, -1.0196e+00,  3.4227e-01,\n",
       "           9.0611e-02, -7.1442e-01, -5.1483e-01,  6.6749e-01,  1.6236e+00,\n",
       "          -1.5389e+00, -7.6098e-01, -6.0926e-01,  1.5119e+00,  1.4623e+00,\n",
       "          -1.8738e+00, -1.0195e+00,  5.1206e-01,  6.5966e-01,  2.5789e-02,\n",
       "          -1.6673e-01, -3.5891e-01, -1.8669e+00, -2.8837e-01,  7.1051e-01,\n",
       "           8.5181e-01,  1.8687e-01,  6.3762e-01, -2.0904e-01, -1.0262e+00,\n",
       "          -6.2161e-01,  1.8408e+00, -1.6856e+00,  5.2398e-01, -5.6024e-01,\n",
       "           1.3300e-01,  1.2988e+00,  7.8794e-02,  4.5463e-02, -3.4238e-01,\n",
       "          -9.0760e-01, -1.3707e+00, -4.4723e-01, -2.9356e-01, -6.8926e-01]],\n",
       "\n",
       "        [[ 1.4308e+00,  5.3982e-01, -5.7762e-02,  7.6088e-01, -4.5305e-01,\n",
       "           3.6230e-01,  2.3692e-01,  1.2783e+00, -3.0438e-01,  4.8155e-01,\n",
       "          -9.4604e-02, -5.2999e-02,  7.0097e-01, -1.3007e+00, -8.7723e-01,\n",
       "           7.4288e-02, -2.6345e-01,  5.9917e-02, -1.4569e-01,  1.7438e+00,\n",
       "          -7.0533e-01,  1.8248e-01,  6.2562e-01, -1.1259e-01, -6.2901e-01,\n",
       "           4.4033e-01, -4.3137e-01,  1.1272e-02, -2.5805e-01, -4.9702e-01,\n",
       "           1.3716e+00, -3.2789e-01,  3.0504e-01, -8.9711e-01,  2.3774e+00,\n",
       "           1.6353e+00, -1.2243e+00,  1.6841e-01,  7.3736e-01, -1.0567e+00,\n",
       "          -1.0988e+00, -8.9903e-01,  1.6964e-01, -1.3469e+00,  6.7174e-02,\n",
       "          -1.0021e+00,  3.9571e-01,  8.8042e-01, -1.5078e+00,  3.5894e-01,\n",
       "           3.3802e-01,  3.0487e-01,  3.4259e-01, -3.8630e-01, -2.4155e-02,\n",
       "           7.3312e-01,  8.7817e-01, -8.2768e-01, -2.9355e-01,  3.3061e-01]],\n",
       "\n",
       "        [[ 2.5318e-01,  3.8102e-01,  2.6876e+00, -3.9484e-01, -2.3881e-01,\n",
       "           6.8641e-02,  5.9486e-01, -1.4737e+00,  7.0669e-01,  1.5046e+00,\n",
       "           5.9085e-01,  1.4933e+00, -2.1005e-01,  1.3130e+00, -9.1704e-01,\n",
       "          -1.1039e+00,  1.4833e+00,  4.7081e-02,  2.2842e-01,  4.6167e-01,\n",
       "          -1.0363e-01,  6.6925e-01, -1.5840e+00,  6.5668e-02, -1.4168e+00,\n",
       "          -1.2486e+00, -1.8272e+00,  1.8112e+00,  6.1650e-01, -1.1103e-01,\n",
       "          -1.8234e-01,  5.7363e-02,  8.6665e-01, -2.0815e+00,  4.1343e-01,\n",
       "          -4.2743e-01,  2.8909e-01,  9.4002e-01,  5.8888e-01,  1.6420e-02,\n",
       "          -8.4871e-02,  3.4691e-01, -9.5851e-01, -1.0034e+00, -1.3980e-01,\n",
       "          -4.1359e-01, -1.7873e+00, -9.6459e-01,  3.7664e-01,  1.8563e+00,\n",
       "           1.9582e+00,  8.4362e-01,  1.0092e+00,  1.4458e-03, -8.9394e-02,\n",
       "          -2.7246e+00, -6.4128e-01, -1.9199e+00, -3.2695e-01, -5.1117e-02]],\n",
       "\n",
       "        [[-1.2159e-01, -9.3231e-01, -9.6076e-01,  1.6190e+00,  1.5291e+00,\n",
       "          -4.0395e-01,  7.7714e-01,  1.8677e+00,  7.4954e-01, -1.0456e+00,\n",
       "          -1.4263e+00, -3.0523e-01,  6.0739e-01, -7.2510e-01, -1.8583e+00,\n",
       "          -1.3546e+00, -2.8826e-01,  1.0497e+00,  9.0350e-01, -1.5834e+00,\n",
       "          -1.6264e-01, -2.9454e-01, -1.1195e+00,  8.4818e-01, -6.9007e-01,\n",
       "          -7.8531e-01,  5.0420e-01, -8.7133e-01, -6.6761e-02, -1.1322e+00,\n",
       "           1.3554e+00, -1.2367e-01,  1.7541e+00, -4.7034e-01,  1.3373e+00,\n",
       "           2.4652e-01, -1.1514e+00,  5.9967e-01, -1.0854e+00, -4.6820e-01,\n",
       "           1.1397e+00, -9.3558e-02, -6.7728e-01, -1.7160e+00,  1.4537e+00,\n",
       "           9.9533e-01,  1.7130e+00,  7.6425e-01, -2.5230e+00,  1.2070e+00,\n",
       "           1.0142e+00, -9.4738e-02, -1.1420e-01, -9.2427e-01,  2.3712e-01,\n",
       "           1.4228e-01,  4.5694e-01,  6.2191e-01,  1.8468e+00, -9.8112e-01]],\n",
       "\n",
       "        [[ 1.1306e+00,  8.3529e-01, -2.9954e-01, -4.7112e-01, -2.0877e-01,\n",
       "          -4.8950e-03, -7.8825e-01,  1.4376e+00,  8.9070e-01,  5.7410e-01,\n",
       "          -2.1297e+00,  2.0067e+00, -4.7687e-01, -1.6458e-02, -1.0851e+00,\n",
       "           1.0390e+00, -1.5669e+00,  5.4534e-01,  8.1195e-03,  7.4603e-01,\n",
       "           1.7752e+00, -2.3654e-02,  5.3764e-01,  7.7837e-01,  1.7001e-01,\n",
       "           5.3340e-01,  8.1639e-01,  5.8233e-02,  2.0643e+00,  9.8667e-01,\n",
       "           3.8659e-01, -1.8921e+00, -1.5634e+00, -1.3588e+00,  7.2107e-01,\n",
       "          -3.4673e-01,  1.0420e+00, -1.3223e+00, -2.3510e-01,  7.3066e-01,\n",
       "           1.4870e-01, -1.6533e+00, -5.8012e-01,  2.5478e+00, -2.4914e-01,\n",
       "           6.1622e-01, -3.0964e-01, -7.9378e-01,  6.9507e-01,  8.6993e-01,\n",
       "           2.0109e+00,  1.2179e+00, -1.4531e+00, -6.3152e-01, -1.0339e+00,\n",
       "           7.5825e-02,  7.8944e-01,  4.8174e-01,  1.1309e+00,  1.0797e+00]],\n",
       "\n",
       "        [[ 7.7379e-01, -1.0015e+00, -6.1293e-01, -4.6681e-01, -4.5193e-01,\n",
       "           2.1192e+00,  9.8311e-01,  7.3992e-01, -8.6174e-01,  8.6770e-01,\n",
       "          -3.8720e-01,  8.5517e-02, -8.4072e-01,  9.0587e-01, -5.6736e-01,\n",
       "           2.3657e-01, -5.1644e-01, -8.5824e-01,  1.0341e+00, -1.1768e+00,\n",
       "           9.0630e-01, -6.1566e-02, -8.9221e-02, -4.8559e-01, -1.4921e+00,\n",
       "           9.0793e-01,  7.9805e-01, -1.7393e+00, -3.4292e-02,  1.2818e+00,\n",
       "          -3.2004e+00,  9.9491e-02, -1.3688e+00, -1.2971e+00,  2.6267e-01,\n",
       "           9.5438e-01, -1.4132e+00,  1.8926e+00,  7.1759e-01, -1.9862e+00,\n",
       "          -9.0729e-01, -7.5776e-01, -7.7266e-01, -6.4274e-01, -1.7269e-01,\n",
       "           1.2985e-01,  4.4351e-02,  1.7689e-01,  7.7345e-01, -1.0645e+00,\n",
       "           6.4652e-01, -1.5979e+00,  6.0500e-01, -1.0385e+00, -2.3670e+00,\n",
       "          -4.2446e-01,  1.4906e+00, -7.9251e-01,  9.9229e-01, -1.5774e+00]],\n",
       "\n",
       "        [[ 5.0177e-01,  2.4106e-01, -6.5872e-01,  1.0902e-01,  5.8086e-01,\n",
       "           1.9186e+00, -2.1326e+00, -6.2231e-01, -2.3593e-01,  1.7025e-01,\n",
       "           1.4749e+00, -9.4292e-01,  1.4547e-01,  9.4311e-01, -8.5379e-01,\n",
       "          -2.2129e-01, -1.3732e+00,  1.3589e+00,  4.6782e-01, -8.9807e-01,\n",
       "           4.7402e-01,  9.1744e-01, -3.2876e-01,  5.9779e-02, -6.4242e-01,\n",
       "           6.8333e-01,  8.7154e-01, -2.3882e-01, -1.0712e+00,  3.9495e-01,\n",
       "           9.2707e-01, -3.0983e-01, -9.8542e-01, -3.6934e-02,  2.6743e+00,\n",
       "           1.0013e+00,  1.1709e-01,  1.5947e-02,  3.3760e-01, -3.6029e-01,\n",
       "          -9.8500e-01,  6.7139e-02, -1.4012e+00,  2.3760e+00,  9.4070e-01,\n",
       "           4.0330e-01,  7.5822e-01,  8.5953e-01,  2.1727e-03,  2.1302e+00,\n",
       "          -8.0883e-01, -6.9155e-01, -6.3846e-01,  3.0520e-01,  7.0363e-01,\n",
       "          -3.8721e-01, -7.9320e-02, -3.1789e-01,  1.6018e+00, -1.7475e-01]],\n",
       "\n",
       "        [[ 4.8490e-01, -1.3485e+00, -5.2845e-01,  5.3322e-02, -1.4477e+00,\n",
       "           9.9759e-01, -1.8074e+00,  5.3383e-01, -9.1542e-01,  1.7862e+00,\n",
       "           2.3016e-01,  8.7560e-02, -1.2497e+00,  6.4770e-01,  1.8212e-01,\n",
       "          -1.4018e+00,  8.9644e-01, -3.1460e-01, -2.0938e-01, -7.8133e-01,\n",
       "          -7.5440e-01,  1.2900e-01, -7.9421e-01, -3.7794e-01, -6.4391e-01,\n",
       "           1.0784e+00, -3.2008e-01,  1.4775e+00, -1.3190e+00, -1.1476e-01,\n",
       "           7.4479e-01, -3.8717e-01,  1.5714e+00, -1.8139e+00,  1.0767e+00,\n",
       "          -1.9131e-01, -3.9009e-01,  6.7437e-01,  1.9352e-01,  1.2796e+00,\n",
       "           8.4135e-01, -1.4779e-01,  1.2561e+00,  1.0188e+00, -2.6481e-01,\n",
       "          -8.8988e-01, -2.6440e-01,  3.8843e-01,  1.8583e+00,  6.6880e-01,\n",
       "          -3.5173e-01,  7.0168e-01,  6.8942e-03,  8.2315e-01, -5.4192e-01,\n",
       "           3.9011e-01, -2.0729e+00,  2.0115e-01, -1.0041e+00,  1.4397e+00]],\n",
       "\n",
       "        [[-5.4609e-01, -4.4945e-01,  8.4361e-01,  9.1256e-01, -2.1864e-01,\n",
       "           1.4071e+00,  9.5832e-01,  1.1638e+00,  4.8710e-01,  1.4185e+00,\n",
       "          -5.6033e-01,  5.4311e-01, -1.0688e+00, -6.0023e-02, -4.0872e-01,\n",
       "           7.2920e-01,  3.6835e-01,  1.2659e+00, -9.8012e-01,  1.3341e-01,\n",
       "           4.7883e-01, -3.3977e-01, -3.3112e-02,  1.7383e+00, -1.0779e-01,\n",
       "           6.0118e-01, -7.4359e-01,  2.2610e-02, -7.3870e-01,  8.4551e-01,\n",
       "           3.0700e-01, -1.1002e-01,  9.7740e-01, -1.0727e+00,  1.0603e-01,\n",
       "           4.6367e-01,  4.9650e-01, -1.1421e-01, -1.8990e-01, -3.7088e-01,\n",
       "          -1.0236e+00, -4.6599e-02, -1.7324e-01, -7.4255e-02,  6.5932e-01,\n",
       "           1.0170e+00,  1.3835e+00,  1.2800e+00, -3.1610e-01, -5.9489e-01,\n",
       "           8.0888e-01,  7.8598e-01,  2.4849e-01, -1.0180e+00,  7.3784e-01,\n",
       "           3.8891e-01, -4.3239e-01,  1.6123e+00,  1.9342e-01,  1.8111e+00]],\n",
       "\n",
       "        [[ 1.0528e+00,  1.5704e+00,  1.9603e-03, -1.4646e+00, -7.5266e-01,\n",
       "           1.3770e-01, -1.9638e-01, -2.8527e-01,  1.1037e+00, -1.8202e+00,\n",
       "          -5.3344e-01,  9.3706e-02, -1.7282e+00,  4.0101e-01,  1.5522e+00,\n",
       "          -7.6144e-01,  1.1975e+00,  1.1506e+00, -1.7320e+00,  3.1218e-01,\n",
       "          -5.2718e-01,  1.3342e-01,  4.5582e-01, -1.1597e+00, -6.2798e-01,\n",
       "           5.8446e-02,  2.7572e-01,  1.1971e+00,  1.5550e+00, -1.8516e+00,\n",
       "          -7.1024e-01,  4.1439e-01,  7.8271e-01,  1.0857e+00, -5.0055e-01,\n",
       "          -1.8306e+00,  6.7957e-02, -5.3453e-01, -1.3076e-01,  1.4755e+00,\n",
       "           5.7825e-01,  1.9042e+00,  3.1708e-01, -8.3081e-01,  1.7181e-01,\n",
       "           3.1793e-02,  1.8867e-01,  1.6538e+00,  3.2521e-02,  2.5793e-01,\n",
       "          -1.6234e-02, -8.3267e-01, -2.0775e+00, -8.5538e-01,  3.1289e-02,\n",
       "           4.3229e-01,  7.8150e-01, -1.9540e+00,  4.6232e-01,  1.4607e+00]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(ts_feature,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "455ed170",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=training.RV_RNN_conv(n_diff=4,rnn_act=\"tanh\",rnn_num_layer=2,rnn_drop_out=0.3,rnn_hidden_size=32,proj_dim=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85bf9cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=model(ts_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc35034a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3662e-05],\n",
       "        [ 2.1474e-04],\n",
       "        [-1.5604e-04],\n",
       "        [ 4.3390e-04],\n",
       "        [ 1.9061e-04],\n",
       "        [ 1.2641e-04],\n",
       "        [ 1.4729e-04],\n",
       "        [ 2.5284e-04],\n",
       "        [ 2.1373e-04],\n",
       "        [ 1.3819e-04]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bfbac7",
   "metadata": {},
   "source": [
    "## Training loop (basic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06d4fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_time=np.load(\"../processed_data/recovered_time_id_order.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "739d9a32-e68b-4f66-bd6b-0fda83803f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4294 31984 31570 ... 29316 32195 10890]\n"
     ]
    }
   ],
   "source": [
    "print(list_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "825838c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In fold 0 :\n",
      "\n",
      "Train set end at 8117 .\n",
      "\n",
      "Test set start at 15516 end at 10890 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_split_list=data_processing.time_cross_val_split(list_time=list_time,n_split=1,percent_val_size=10,list_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87ca970a-b88b-4b85-8337-6cf6a957e5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4294, 31984, 31570, ...,  5629, 10421,  8117])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_split_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7ba8aa2-a446-4389-8d49-bca021ceb63f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15516, 30276, 16402, 27182, 24497, 13529,   373,  4219, 20323,\n",
       "        9160, 28983, 17820, 22678,  7460, 29676, 32048, 22405, 31380,\n",
       "        1816, 14079, 29944, 21990, 26804, 28210, 18142, 11682, 32597,\n",
       "       13513, 32690, 27120, 27427,  7418,  1213,  9822, 29692, 24523,\n",
       "       25318,  6274, 25569, 12713,   169, 20732, 15906, 28877, 25551,\n",
       "       10745, 31320, 31714,  6076, 23656,   424,   309, 17604, 28963,\n",
       "       23144, 11872, 29219, 25357, 22828, 17569, 17955, 11920, 18509,\n",
       "       19626, 16149,  5392,  7200, 10929,  4774, 27278, 23639, 10633,\n",
       "          72, 32534, 26944, 31018, 26494,  6648,   709,  6823, 21239,\n",
       "       11995, 23265, 31883,  2711,  1350,  1321, 16282,  5046, 29875,\n",
       "        7133, 15823, 25463,  9064,  3333, 11440, 16831,  6815, 19580,\n",
       "       30620, 24014, 17193, 10708, 30597,  4367, 27962, 13010, 32254,\n",
       "       23226, 22903,  5929, 30327,  1866, 14629,  1205,  9352, 10619,\n",
       "       14234, 15276,  4091, 22752, 18653, 11453, 26708, 30183, 13986,\n",
       "           5,  7864,  9889, 31471, 26868, 10672, 31347, 15418, 30430,\n",
       "       26568, 28267,  3955,  1392, 27014, 22081, 15845, 18728,  9936,\n",
       "        5232,  2366, 26886, 30272, 11393, 30750,  7572, 21601,  2331,\n",
       "       13207, 12073,  2058, 18502, 25429, 12532, 27496,  5932,   536,\n",
       "       27595, 23185, 26752,  2683,  6585, 15131,  6144, 27042,  7743,\n",
       "       22249, 32611,  3758, 19271, 13614, 31572, 17570,  9367, 11263,\n",
       "       14285, 12981,   146,  2643, 31266, 23490,  2109, 29906, 30303,\n",
       "       12102, 32649,  8721, 26606, 32012, 16511, 30908, 19871,  3513,\n",
       "        3001, 24127, 29974, 27752, 16504,  6631,  8750,  6493, 29819,\n",
       "       12147, 13503, 11264, 31236,  8365, 23486, 13294,  1292, 17265,\n",
       "       16594, 20928, 18205,  6316,  8459, 19955,  7369, 26763, 13560,\n",
       "        3211, 31254, 13720,   152,  4844, 14738, 22548, 27886,  4131,\n",
       "        6657, 13699, 25639,  2000, 26788, 21103, 11577, 29037,  9947,\n",
       "       32134, 30341, 17112,  7548, 20265, 12533, 10262, 10616,  7512,\n",
       "       28354, 25879,  2440, 21614, 32255, 15584,  9735, 31874, 30366,\n",
       "       31047, 16507,  6906,  9396,  6217,  1521, 17378, 26091,  3318,\n",
       "       32746,  8744, 26889,  1468,  6965, 17117,   817,  3130, 14928,\n",
       "       21373, 13980, 28634,   103, 27543, 26849,  7909, 18077, 30569,\n",
       "       10105, 12178, 20491, 32704, 12923, 15393, 14976, 26168,  2867,\n",
       "       12182, 27524, 30339, 18285, 28474, 27981, 13928, 10892, 14909,\n",
       "       21024, 25971,  9266, 25277,  5425, 17454,  3962, 14449, 31389,\n",
       "       17672,  9887, 20669,  4089, 19512, 30212, 11151, 22912, 25359,\n",
       "       29947, 31348, 16731,  1948,  6730, 14176,  2656, 15728,  8573,\n",
       "       21762,  6359,  5846, 12521, 26578,  8623,  9096, 23423, 22513,\n",
       "       23539, 17528,  5663, 24021, 32240, 28635,  2553, 13791, 22427,\n",
       "       19647, 26170,  2718, 28192, 19065,  2136, 29679,  9028, 17120,\n",
       "       25312,   618, 18184, 21658, 13627, 25338, 31402, 24406, 31331,\n",
       "        7759,  3123,  2027, 18703, 28837, 11718, 13579, 10455, 10604,\n",
       "       24913, 15365, 29316, 32195, 10890])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_split_list[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72aedca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_id,test_time_id=time_split_list[0][0],time_split_list[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3338fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RV_ts=pd.read_parquet(\"../processed_data/book_RV_ts_60_si.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62e2f34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b9cf070",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e42729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RV_ts[\"sub_int_RV_norm\"]=scalar.fit_transform(df_RV_ts[[\"sub_int_RV\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "995d9083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>sub_int_RV</th>\n",
       "      <th>sub_int_num</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>sub_int_RV_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-5</td>\n",
       "      <td>-0.208285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-11</td>\n",
       "      <td>-0.453866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-16</td>\n",
       "      <td>-0.569259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-31</td>\n",
       "      <td>-0.428690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-62</td>\n",
       "      <td>-0.540259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735915</th>\n",
       "      <td>32686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32686</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735916</th>\n",
       "      <td>32690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32690</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735917</th>\n",
       "      <td>32712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32712</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735918</th>\n",
       "      <td>32746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32746</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735919</th>\n",
       "      <td>32758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32758</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25735920 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          time_id  sub_int_RV  sub_int_num  stock_id     row_id  \\\n",
       "0               5    0.000329            1        93       93-5   \n",
       "1              11    0.000191            1        93      93-11   \n",
       "2              16    0.000126            1        93      93-16   \n",
       "3              31    0.000205            1        93      93-31   \n",
       "4              62    0.000142            1        93      93-62   \n",
       "...           ...         ...          ...       ...        ...   \n",
       "25735915    32686    0.000000           60       104  104-32686   \n",
       "25735916    32690    0.000000           60       104  104-32690   \n",
       "25735917    32712    0.000000           60       104  104-32712   \n",
       "25735918    32746    0.000000           60       104  104-32746   \n",
       "25735919    32758    0.000000           60       104  104-32758   \n",
       "\n",
       "          sub_int_RV_norm  \n",
       "0               -0.208285  \n",
       "1               -0.453866  \n",
       "2               -0.569259  \n",
       "3               -0.428690  \n",
       "4               -0.540259  \n",
       "...                   ...  \n",
       "25735915        -0.793956  \n",
       "25735916        -0.793956  \n",
       "25735917        -0.793956  \n",
       "25735918        -0.793956  \n",
       "25735919        -0.793956  \n",
       "\n",
       "[25735920 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RV_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de450e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"21\" halign=\"left\">sub_int_RV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_int_num</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-1000</th>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>3.818799e-07</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>2.313288e-04</td>\n",
       "      <td>1.060893e-05</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10000</th>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>3.154886e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>3.777703e-08</td>\n",
       "      <td>3.777703e-08</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10005</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>4.375100e-04</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>2.552987e-03</td>\n",
       "      <td>5.364106e-04</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10017</th>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>6.771948e-05</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>3.104404e-03</td>\n",
       "      <td>1.224910e-03</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.003287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10030</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>2.586782e-04</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>4.842470e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9972</th>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>2.503467e-04</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>9.916624e-05</td>\n",
       "      <td>1.809852e-04</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9973</th>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>9.650211e-04</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>1.862600e-03</td>\n",
       "      <td>7.668418e-04</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.002115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9976</th>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>7.203531e-04</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>5.946683e-04</td>\n",
       "      <td>1.509652e-04</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9988</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.957402e-04</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.440137e-04</td>\n",
       "      <td>3.200939e-05</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9993</th>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>1.798617e-04</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>2.728767e-04</td>\n",
       "      <td>2.108380e-04</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows  60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sub_int_RV                                                        \\\n",
       "sub_int_num         1         2         3         4         5             6    \n",
       "row_id                                                                         \n",
       "0-1000        0.000341  0.000000  0.000023  0.000000  0.000170  3.818799e-07   \n",
       "0-10000       0.000290  0.000191  0.000087  0.000193  0.000241  3.154886e-04   \n",
       "0-10005       0.000000  0.000000  0.001554  0.002177  0.002303  4.375100e-04   \n",
       "0-10017       0.000142  0.000142  0.001464  0.001086  0.000068  6.771948e-05   \n",
       "0-10030       0.000327  0.000058  0.000293  0.000842  0.000120  2.586782e-04   \n",
       "...                ...       ...       ...       ...       ...           ...   \n",
       "99-9972       0.000197  0.000181  0.000171  0.000172  0.000369  2.503467e-04   \n",
       "99-9973       0.000821  0.000346  0.000691  0.001591  0.000863  9.650211e-04   \n",
       "99-9976       0.000569  0.001101  0.001002  0.000430  0.000797  7.203531e-04   \n",
       "99-9988       0.000040  0.000069  0.000123  0.000056  0.000016  1.957402e-04   \n",
       "99-9993       0.000249  0.000179  0.000155  0.000025  0.000325  1.798617e-04   \n",
       "\n",
       "                                                     ...                      \\\n",
       "sub_int_num        7         8         9         10  ...        51        52   \n",
       "row_id                                               ...                       \n",
       "0-1000       0.000089  0.000552  0.000012  0.000000  ...  0.000265  0.000000   \n",
       "0-10000      0.000000  0.000247  0.000265  0.000000  ...  0.000202  0.000375   \n",
       "0-10005      0.000617  0.001199  0.002306  0.001215  ...  0.000000  0.000486   \n",
       "0-10017      0.000899  0.000064  0.000593  0.000451  ...  0.000029  0.000000   \n",
       "0-10030      0.000221  0.000436  0.000099  0.000008  ...  0.000410  0.000437   \n",
       "...               ...       ...       ...       ...  ...       ...       ...   \n",
       "99-9972      0.000349  0.000356  0.000390  0.000050  ...  0.000075  0.000185   \n",
       "99-9973      0.000504  0.001925  0.000641  0.000382  ...  0.001081  0.001095   \n",
       "99-9976      0.000586  0.000538  0.000570  0.000781  ...  0.000508  0.000406   \n",
       "99-9988      0.000071  0.000095  0.000063  0.000030  ...  0.000034  0.000176   \n",
       "99-9993      0.000080  0.000125  0.000126  0.000205  ...  0.000099  0.000370   \n",
       "\n",
       "                                                                   \\\n",
       "sub_int_num        53        54        55        56            57   \n",
       "row_id                                                              \n",
       "0-1000       0.000214  0.000003  0.000000  0.000118  2.313288e-04   \n",
       "0-10000      0.000616  0.000564  0.000000  0.000023  3.777703e-08   \n",
       "0-10005      0.000050  0.001761  0.001617  0.001801  2.552987e-03   \n",
       "0-10017      0.001293  0.002092  0.000994  0.000848  3.104404e-03   \n",
       "0-10030      0.000004  0.000215  0.000457  0.000183  4.842470e-04   \n",
       "...               ...       ...       ...       ...           ...   \n",
       "99-9972      0.000314  0.000318  0.000115  0.000143  9.916624e-05   \n",
       "99-9973      0.000425  0.000789  0.001295  0.000596  1.862600e-03   \n",
       "99-9976      0.000662  0.000338  0.000710  0.000179  5.946683e-04   \n",
       "99-9988      0.000140  0.000129  0.000175  0.000019  1.440137e-04   \n",
       "99-9993      0.000929  0.000328  0.000251  0.000204  2.728767e-04   \n",
       "\n",
       "                                               \n",
       "sub_int_num            58        59        60  \n",
       "row_id                                         \n",
       "0-1000       1.060893e-05  0.000111  0.000288  \n",
       "0-10000      3.777703e-08  0.000020  0.000310  \n",
       "0-10005      5.364106e-04  0.000872  0.000000  \n",
       "0-10017      1.224910e-03  0.001316  0.003287  \n",
       "0-10030      0.000000e+00  0.000756  0.000005  \n",
       "...                   ...       ...       ...  \n",
       "99-9972      1.809852e-04  0.000334  0.000089  \n",
       "99-9973      7.668418e-04  0.001035  0.002115  \n",
       "99-9976      1.509652e-04  0.000388  0.000403  \n",
       "99-9988      3.200939e-05  0.000041  0.000007  \n",
       "99-9993      2.108380e-04  0.000126  0.000353  \n",
       "\n",
       "[428932 rows x 60 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RV_ts.pivot(index=\"row_id\",columns=[\"sub_int_num\"],values=[\"sub_int_RV\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "677c1b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target=pd.read_csv(\"../raw_data/kaggle_ORVP/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "252d6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target[\"row_id\"]=df_target[\"stock_id\"].astype(int).astype(str)+\"-\"+df_target[\"time_id\"].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fdb28caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0-62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>126</td>\n",
       "      <td>32751</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>126-32751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>126</td>\n",
       "      <td>32753</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>126-32753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>126</td>\n",
       "      <td>32758</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>126-32758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>126</td>\n",
       "      <td>32763</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>126-32763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>126</td>\n",
       "      <td>32767</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>126-32767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stock_id  time_id    target     row_id\n",
       "0              0        5  0.004136        0-5\n",
       "1              0       11  0.001445       0-11\n",
       "2              0       16  0.002168       0-16\n",
       "3              0       31  0.002195       0-31\n",
       "4              0       62  0.001747       0-62\n",
       "...          ...      ...       ...        ...\n",
       "428927       126    32751  0.003461  126-32751\n",
       "428928       126    32753  0.003113  126-32753\n",
       "428929       126    32758  0.004070  126-32758\n",
       "428930       126    32763  0.003357  126-32763\n",
       "428931       126    32767  0.002090  126-32767\n",
       "\n",
       "[428932 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b2a07cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy.loc[:,\"sub_int_num\"]=np.nan\n",
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy.loc[:,\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7c432cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([386036, 60])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07885f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([386036, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0056627",
   "metadata": {},
   "source": [
    "Not entirely sure what the error code is about, I am literally doing exactly as suggested by the warning. https://stackoverflow.com/questions/23688307/settingwithcopywarning-even-when-using-loc says this is a false positive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596532d4-3c50-4a8e-bbda-8448b8f02b4d",
   "metadata": {},
   "source": [
    "## Experiment: RNN (with some fine tuning) and LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a44c92-9ff1-4909-808f-0a05b6aa2a14",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2721fdfa-a2d2-4461-8a99-0fe183fcbfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In fold 0 :\n",
      "\n",
      "Train set end at 8117 .\n",
      "\n",
      "Test set start at 15516 end at 10890 .\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy.loc[:,\"sub_int_num\"]=np.nan\n",
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy.loc[:,\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "time_split_list=data_processing.time_cross_val_split(list_time=list_time,n_split=1,percent_val_size=10,list_output=True)\n",
    "train_time_id,test_time_id=time_split_list[0][0],time_split_list[0][1]\n",
    "\n",
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "33aa773d-89d5-4ea3-ac88-868bdb7e34b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(time_split_list[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "00de91c2-12af-4f4b-953c-8fa907c945c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  1.1088676452636719  epoch  1 has training loss  tensor(0.2925, device='cuda:0')  and validation loss  tensor(0.2404, device='cuda:0') .\n",
      "\n",
      "At  6.541226863861084  epoch  5 has training loss  tensor(0.2545, device='cuda:0')  and validation loss  tensor(0.2365, device='cuda:0') .\n",
      "\n",
      "At  13.19153118133545  epoch  10 has training loss  tensor(0.2536, device='cuda:0')  and validation loss  tensor(0.2366, device='cuda:0') .\n",
      "\n",
      "At  19.56281328201294  epoch  15 has training loss  tensor(0.2530, device='cuda:0')  and validation loss  tensor(0.2375, device='cuda:0') .\n",
      "\n",
      "At  25.89854907989502  epoch  20 has training loss  tensor(0.2529, device='cuda:0')  and validation loss  tensor(0.2359, device='cuda:0') .\n",
      "\n",
      "At  32.967039823532104  epoch  25 has training loss  tensor(0.2524, device='cuda:0')  and validation loss  tensor(0.2347, device='cuda:0') .\n",
      "\n",
      "At  39.60832858085632  epoch  30 has training loss  tensor(0.2520, device='cuda:0')  and validation loss  tensor(0.2349, device='cuda:0') .\n",
      "\n",
      "At  45.91442036628723  epoch  35 has training loss  tensor(0.2515, device='cuda:0')  and validation loss  tensor(0.2363, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  10  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 25  with validation loss:  tensor(0.2347, device='cuda:0') .\n",
      " The total number of epoch trained is  35 .\n",
      " Training completed in:  45.91442036628723 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[-0.3690, -0.5289,  0.3664],\n",
       "                      [ 0.0351,  0.4498,  0.0285],\n",
       "                      [ 0.2442,  0.4853,  0.0733],\n",
       "                      [-0.1412, -0.4786,  0.1432],\n",
       "                      [-0.2056,  0.3497, -0.3446],\n",
       "                      [ 0.3274, -0.0278, -0.1515],\n",
       "                      [-0.0496,  0.2992, -0.2315],\n",
       "                      [-0.0268,  0.0758,  0.0491],\n",
       "                      [ 0.5566,  0.6183, -0.0490],\n",
       "                      [-0.0015, -0.2596, -0.1624],\n",
       "                      [-0.0395,  0.4914,  0.2983],\n",
       "                      [ 0.4089,  0.2943, -0.2403],\n",
       "                      [-0.4960, -0.7400, -0.5504],\n",
       "                      [ 0.0947, -0.4801, -0.1741],\n",
       "                      [ 0.1984, -0.5265, -0.0383],\n",
       "                      [ 0.0322,  0.3203,  0.1626],\n",
       "                      [ 0.3455,  0.6971,  0.3884],\n",
       "                      [ 0.4169,  0.0594, -0.0421],\n",
       "                      [ 0.0309, -0.0142,  0.0051],\n",
       "                      [ 0.1569, -0.2477, -0.3229],\n",
       "                      [ 0.0389, -0.2792, -0.1458],\n",
       "                      [ 0.1261, -0.4738, -0.4007],\n",
       "                      [-0.0249,  0.4720,  0.3061],\n",
       "                      [-0.0497, -0.5792, -0.4048],\n",
       "                      [ 0.1656,  0.2565, -0.0747],\n",
       "                      [ 0.0085, -0.6709, -0.5144],\n",
       "                      [ 0.0179,  0.0332,  0.1856],\n",
       "                      [ 0.3132, -0.5140,  0.4145],\n",
       "                      [ 0.4020, -0.5658, -0.3029],\n",
       "                      [-0.0695,  0.4012,  0.3130],\n",
       "                      [-0.0449, -0.1756, -0.3344],\n",
       "                      [ 0.1961, -0.4025, -0.0979]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([ 0.3413,  0.0259, -0.4105,  0.3386,  0.1391, -0.2868, -0.0821,  0.0405,\n",
       "                       0.0230,  0.0253,  0.0180,  0.2545,  0.4509, -0.0464, -0.1288, -0.1239,\n",
       "                       0.1915, -0.1158, -0.0572,  0.0611, -0.1222, -0.2282, -0.0594,  0.1133,\n",
       "                       0.1730, -0.3693, -0.0304,  0.2619, -0.3762, -0.2199,  0.0578, -0.3044],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[-0.1379, -0.0814,  0.0906,  ..., -0.0190,  0.2608,  0.0800],\n",
       "                      [-0.0632, -0.0329, -0.0014,  ...,  0.2176, -0.1292, -0.1506],\n",
       "                      [ 0.1028, -0.2786,  0.0527,  ...,  0.2169, -0.0286,  0.2193],\n",
       "                      ...,\n",
       "                      [ 0.0326,  0.1237,  0.1740,  ...,  0.1568, -0.0305, -0.0427],\n",
       "                      [-0.0667, -0.0616,  0.0807,  ...,  0.1487,  0.0305,  0.0693],\n",
       "                      [-0.0902,  0.0814, -0.1035,  ..., -0.0494, -0.0372,  0.1034]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[-0.1098,  0.1771, -0.0800,  ...,  0.2532, -0.3420, -0.0753],\n",
       "                      [ 0.0218,  0.0562, -0.0590,  ...,  0.1082, -0.0397, -0.1132],\n",
       "                      [ 0.2659,  0.0777,  0.3043,  ...,  0.1516, -0.0619, -0.2658],\n",
       "                      ...,\n",
       "                      [-0.0371,  0.0668,  0.0531,  ..., -0.0700,  0.1364,  0.1470],\n",
       "                      [-0.1642,  0.1640,  0.1111,  ..., -0.0691,  0.1058,  0.0884],\n",
       "                      [-0.0949, -0.3193,  0.0031,  ..., -0.1205,  0.1276,  0.3306]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([-0.0466, -0.2223, -0.0284, -0.0453,  0.0960,  0.0243, -0.0244, -0.1915,\n",
       "                      -0.1167, -0.0070,  0.0707, -0.0234, -0.0328, -0.1749, -0.0966,  0.0451,\n",
       "                      -0.0904,  0.0873,  0.1211, -0.0393,  0.0444,  0.1265,  0.0946,  0.0058,\n",
       "                       0.0049, -0.0272,  0.0185,  0.0832,  0.0406,  0.0662,  0.0319,  0.1088],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([-5.1708e-05, -2.6769e-01, -2.8386e-01, -9.6623e-02,  9.3427e-02,\n",
       "                      -1.4468e-01, -6.6568e-02, -2.1758e-01,  1.5014e-01, -6.7334e-02,\n",
       "                      -8.8265e-02, -1.6933e-01,  1.4724e-01, -1.6858e-01,  2.5654e-03,\n",
       "                       1.7048e-01,  1.4090e-01,  1.5227e-01, -6.5412e-02,  1.6008e-01,\n",
       "                       2.0340e-01, -1.4227e-03, -1.3888e-01,  1.5759e-01,  1.1735e-01,\n",
       "                      -1.8610e-02,  8.0570e-02,  1.7217e-01,  1.0782e-01, -1.2096e-01,\n",
       "                      -1.5552e-01,  1.0525e-01], device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[ 0.1089, -0.1229, -0.1768, -0.2459,  0.1094, -0.1377,  0.2060, -0.0933,\n",
       "                       -0.1326, -0.0547,  0.0224,  0.1916, -0.0390, -0.0626, -0.1011, -0.0404,\n",
       "                        0.1209, -0.0482, -0.2015, -0.1450,  0.0864,  0.1082, -0.2130, -0.1405,\n",
       "                       -0.0052, -0.1639,  0.1558, -0.0116, -0.0700, -0.1108,  0.0788,  0.1460]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([-0.0962], device='cuda:0'))])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_model=training.RV_RNN_conv(n_diff=2, rnn_type=\"rnn\",rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=10000).to(device=device)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer=optim.Adam(RNN_model.parameters(),lr=1e-3)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)\n",
    "\n",
    "train_loss=[]\n",
    "val_loss=[]\n",
    "\n",
    "training.reg_training_loop_rmspe(optimizer=optimizer,model=RNN_model,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=100,ot_steps=10,report_interval=5,eps=0,scaler=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fb1f55fb-a478-4bee-bf57-12189db4383a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff728f87220>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.arange(len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b608cb1-05a8-417d-8a2a-8816518de943",
   "metadata": {},
   "source": [
    "LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "cf7afa75-8e8c-4318-9c75-4e4029fdc57d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: rnn_act='tanh' is ignored when using rnn_type='lstm'\n",
      "At  1.3160498142242432  epoch  1 has training loss  tensor(0.2946, device='cuda:0')  and validation loss  tensor(0.2380, device='cuda:0') .\n",
      "\n",
      "At  7.0563132762908936  epoch  5 has training loss  tensor(0.2515, device='cuda:0')  and validation loss  tensor(0.2435, device='cuda:0') .\n",
      "\n",
      "At  13.919213056564331  epoch  10 has training loss  tensor(0.2480, device='cuda:0')  and validation loss  tensor(0.2333, device='cuda:0') .\n",
      "\n",
      "At  21.059534311294556  epoch  15 has training loss  tensor(0.2467, device='cuda:0')  and validation loss  tensor(0.2317, device='cuda:0') .\n",
      "\n",
      "At  27.933840036392212  epoch  20 has training loss  tensor(0.2456, device='cuda:0')  and validation loss  tensor(0.2305, device='cuda:0') .\n",
      "\n",
      "At  34.766276359558105  epoch  25 has training loss  tensor(0.2450, device='cuda:0')  and validation loss  tensor(0.2319, device='cuda:0') .\n",
      "\n",
      "At  41.926653146743774  epoch  30 has training loss  tensor(0.2456, device='cuda:0')  and validation loss  tensor(0.2317, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  10  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 20  with validation loss:  tensor(0.2305, device='cuda:0') .\n",
      " The total number of epoch trained is  30 .\n",
      " Training completed in:  41.926653146743774 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[ 2.8287e-01, -1.2812e-01, -1.9540e-01],\n",
       "                      [ 7.6169e-02,  8.2936e-02,  1.6934e-01],\n",
       "                      [ 8.4557e-02,  1.1125e-01, -4.9658e-02],\n",
       "                      [ 2.3866e-01,  4.2292e-01, -1.4144e-01],\n",
       "                      [ 2.5859e-01,  3.8769e-01,  1.6039e-01],\n",
       "                      [-1.3353e-01, -1.0613e-01,  1.5888e-01],\n",
       "                      [-9.4303e-02,  4.4136e-01,  4.5364e-01],\n",
       "                      [-1.2019e-01, -3.0865e-01, -1.2840e-01],\n",
       "                      [-3.6024e-01, -2.2654e-01, -4.2460e-02],\n",
       "                      [-1.2951e-01,  4.0940e-01, -3.1637e-01],\n",
       "                      [ 2.9412e-02, -2.4630e-01,  1.8425e-01],\n",
       "                      [-1.1579e-01,  9.2390e-02, -3.0648e-01],\n",
       "                      [ 4.4675e-01,  5.8284e-01,  9.3860e-02],\n",
       "                      [ 2.9786e-01, -3.6340e-01, -4.0888e-01],\n",
       "                      [-1.9269e-01, -2.2923e-01, -1.9861e-01],\n",
       "                      [-3.6934e-01,  3.0802e-01,  1.3600e-01],\n",
       "                      [ 1.3577e-01,  2.4975e-01,  2.4985e-01],\n",
       "                      [ 1.9766e-02,  5.2280e-02, -5.8723e-02],\n",
       "                      [ 1.4205e-01, -1.0376e-01, -2.7897e-01],\n",
       "                      [-4.1767e-01,  4.2013e-01, -7.8533e-02],\n",
       "                      [-7.2344e-02,  2.0965e-01,  1.9213e-01],\n",
       "                      [ 2.7601e-01,  3.3062e-01,  2.2457e-02],\n",
       "                      [-2.6737e-03,  2.6045e-01, -4.8382e-02],\n",
       "                      [ 8.6824e-02,  4.7444e-02, -2.5511e-01],\n",
       "                      [-1.2724e-01, -1.7309e-01, -2.6903e-01],\n",
       "                      [-1.6493e-01,  3.7189e-01, -1.9371e-01],\n",
       "                      [ 4.1152e-02,  3.6700e-01,  3.0662e-01],\n",
       "                      [ 1.7308e-01,  4.9467e-01, -7.6316e-02],\n",
       "                      [ 2.8380e-02,  4.5984e-01,  2.8179e-01],\n",
       "                      [ 8.4289e-02, -3.6588e-02,  5.7256e-03],\n",
       "                      [-4.1221e-04,  4.7418e-01,  1.7140e-01],\n",
       "                      [ 7.0668e-02,  4.7931e-01,  3.2046e-01]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([-0.2983, -0.1900, -0.2540, -0.2469, -0.5523,  0.2452, -0.1389, -0.3495,\n",
       "                       0.3158,  0.1968, -0.0741, -0.4061, -0.2949, -0.0117, -0.2292,  0.0847,\n",
       "                      -0.2570,  0.3851, -0.4787, -0.1112,  0.2315, -0.2033,  0.1461,  0.1206,\n",
       "                       0.3610,  0.2838, -0.0439, -0.0175, -0.2979, -0.2187,  0.4394,  0.4289],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[-0.1302,  0.0306,  0.1278,  ..., -0.0159, -0.2059, -0.0626],\n",
       "                      [-0.1780, -0.0298,  0.0826,  ..., -0.1116,  0.1321, -0.0280],\n",
       "                      [ 0.2559, -0.1207,  0.1252,  ...,  0.1487, -0.0985, -0.3161],\n",
       "                      ...,\n",
       "                      [ 0.0318, -0.1098, -0.0774,  ..., -0.3043,  0.3783,  0.2680],\n",
       "                      [ 0.2067, -0.2865,  0.1590,  ..., -0.1575, -0.2147, -0.1338],\n",
       "                      [-0.0373,  0.0044,  0.2288,  ...,  0.1337,  0.1402,  0.2360]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[ 4.3170e-01,  6.2768e-05, -1.6631e-01,  ..., -3.9386e-01,\n",
       "                        4.0146e-02, -2.6923e-01],\n",
       "                      [ 1.6718e-01,  3.0029e-02, -3.5764e-01,  ..., -5.8933e-02,\n",
       "                       -8.0800e-02, -2.8373e-01],\n",
       "                      [ 1.2000e-01,  1.4232e-01, -2.8669e-02,  ..., -2.7607e-01,\n",
       "                        2.6044e-01, -3.9581e-01],\n",
       "                      ...,\n",
       "                      [-7.5897e-01, -8.8791e-03,  3.4001e-01,  ..., -7.7025e-01,\n",
       "                       -5.4125e-03,  2.7048e-01],\n",
       "                      [ 3.0025e-01,  6.3299e-01,  1.3490e-02,  ...,  4.5537e-01,\n",
       "                       -1.1574e-01, -1.8971e-01],\n",
       "                      [ 6.3166e-02, -2.5839e-02,  1.3114e-01,  ..., -7.8299e-01,\n",
       "                        9.9837e-02, -2.0265e-01]], device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([-0.4938, -0.2677, -0.1083, -0.1267,  0.1184, -0.5709, -0.0937,  0.1480,\n",
       "                      -0.3691,  0.0629, -0.2898, -0.0205, -0.4146,  0.1555, -0.1239, -0.2336,\n",
       "                      -0.0042, -0.1201, -0.4351, -0.2019, -0.0112, -0.0164, -0.2845, -0.0906,\n",
       "                       0.1414, -0.0078, -0.0382,  0.1062, -0.2026, -0.6243,  0.0657,  0.1646,\n",
       "                       0.4150, -0.0509, -0.0890, -0.0664,  0.1950,  0.0259, -0.0726,  0.0330,\n",
       "                       0.4827, -0.1783, -0.0879,  0.1549, -0.4941, -0.0483,  0.0864,  0.1655,\n",
       "                      -0.2236, -0.1031,  0.3385,  0.1159,  0.3644, -0.0486, -0.0374,  0.2406,\n",
       "                       0.0616, -0.1644,  0.0086,  0.0880, -0.1338,  0.3830,  0.0269,  0.1815,\n",
       "                      -0.0203, -0.0719,  0.1459,  0.1237, -0.2315,  0.0912, -0.0028,  0.0012,\n",
       "                       0.0030,  0.0704, -0.0049, -0.1124, -0.1562,  0.0261,  0.0173,  0.0719,\n",
       "                       0.0114, -0.1360, -0.0924, -0.0868,  0.0977,  0.0385, -0.0797,  0.0062,\n",
       "                       0.0223,  0.0442, -0.0495, -0.0977, -0.1472,  0.2238,  0.0094, -0.1477,\n",
       "                       0.1381, -0.2422,  0.1109, -0.1225,  0.0124, -0.0261, -0.1858,  0.0349,\n",
       "                       0.0992, -0.1370, -0.1795,  0.1219, -0.6650,  0.0365, -0.4488,  0.0020,\n",
       "                       0.0108, -0.2535, -0.0453, -0.0139, -0.0034, -0.2134, -0.1345, -0.1528,\n",
       "                      -0.0756, -0.3250,  0.0862,  0.1196, -0.0274,  0.3972, -0.0365, -0.1682],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([-0.3876, -0.2218, -0.0016,  0.0718, -0.1357, -0.5576, -0.2660,  0.0416,\n",
       "                      -0.4279, -0.0884, -0.2587, -0.2049, -0.3352, -0.0780,  0.0269, -0.1108,\n",
       "                      -0.0823, -0.3417, -0.4297,  0.0739, -0.2420, -0.1294, -0.3609,  0.1001,\n",
       "                      -0.1129,  0.0335, -0.2348, -0.0859, -0.2399, -0.6554,  0.0296,  0.0122,\n",
       "                       0.2893, -0.3290, -0.1613,  0.0526,  0.1214,  0.0397, -0.2420,  0.1235,\n",
       "                       0.2657, -0.0858,  0.1642,  0.2007, -0.2517,  0.0983, -0.1783,  0.3025,\n",
       "                      -0.0849,  0.0182,  0.1420,  0.0705,  0.1836,  0.0451,  0.1148,  0.2419,\n",
       "                       0.3495,  0.0256, -0.0721, -0.1726, -0.2092,  0.2427,  0.0896,  0.1569,\n",
       "                      -0.1029,  0.1029,  0.1405,  0.1496, -0.2720,  0.0941,  0.1371, -0.3311,\n",
       "                       0.0019, -0.1920, -0.0989, -0.0573, -0.1488,  0.0354, -0.0782,  0.0748,\n",
       "                       0.0541,  0.1308, -0.1617,  0.0368,  0.1072, -0.0883,  0.1133,  0.0426,\n",
       "                       0.0415,  0.0324,  0.0934, -0.1891, -0.0834, -0.0170, -0.0410, -0.1194,\n",
       "                       0.1962, -0.0747, -0.1705,  0.0594, -0.0857, -0.0354,  0.0855,  0.1224,\n",
       "                       0.1827, -0.2131,  0.0654,  0.0422, -0.4033, -0.0885, -0.2362, -0.0168,\n",
       "                      -0.1178, -0.1081, -0.1814,  0.0382,  0.0984, -0.1232, -0.2019, -0.1462,\n",
       "                       0.0299, -0.3844, -0.1802,  0.1078, -0.2487,  0.2704, -0.0377, -0.1184],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[-0.1061, -0.2874,  0.0858,  0.0568, -0.1293, -0.2087,  0.1499, -0.1795,\n",
       "                        0.0724, -0.2038, -0.1536, -0.0927,  0.6361, -0.1503,  0.3629, -0.1354,\n",
       "                        0.2004, -0.0782,  0.0727, -0.1520, -0.1786, -0.0288, -0.1435,  0.1596,\n",
       "                       -0.0098, -0.1415,  0.1112, -0.1463, -0.2588, -0.1183,  0.0861,  0.0849]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([-0.1002], device='cuda:0'))])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_model=training.RV_RNN_conv(n_diff=2, rnn_type=\"lstm\",rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=10000).to(device=device)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer=optim.Adam(RNN_model.parameters(),lr=1e-3)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)\n",
    "\n",
    "train_loss=[]\n",
    "val_loss=[]\n",
    "\n",
    "training.reg_training_loop_rmspe(optimizer=optimizer,model=RNN_model,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=100,ot_steps=10,report_interval=5,eps=0,scaler=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5aa699c1-a918-4831-9f1b-8697e25bd98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff7288565f0>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.arange(len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c408726",
   "metadata": {},
   "source": [
    "## Training with native values, with a 10000 times scaler on input. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc50c5",
   "metadata": {},
   "source": [
    "A key issue with our input timeseries is that all values are extremely close to zero, so a 10000 times scaler can help with expanding them a little. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2efd16ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device=(torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b95e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model=training.RV_RNN_conv(n_diff=4,rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=10000).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3846a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer=optim.Adam(RNN_model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "55dd6fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=256,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=256,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "292fcf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "810267b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  2.841204881668091  epoch  1 has training loss  tensor(0.2701, device='cuda:0')  and validation loss  tensor(0.2366, device='cuda:0') .\n",
      "\n",
      "At  12.692814350128174  epoch  5 has training loss  tensor(0.2536, device='cuda:0')  and validation loss  tensor(0.2370, device='cuda:0') .\n",
      "\n",
      "At  24.804923057556152  epoch  10 has training loss  tensor(0.2527, device='cuda:0')  and validation loss  tensor(0.2350, device='cuda:0') .\n",
      "\n",
      "At  36.860355615615845  epoch  15 has training loss  tensor(0.2519, device='cuda:0')  and validation loss  tensor(0.2352, device='cuda:0') .\n",
      "\n",
      "At  49.09467816352844  epoch  20 has training loss  tensor(0.2518, device='cuda:0')  and validation loss  tensor(0.2364, device='cuda:0') .\n",
      "\n",
      "At  61.199227809906006  epoch  25 has training loss  tensor(0.2510, device='cuda:0')  and validation loss  tensor(0.2349, device='cuda:0') .\n",
      "\n",
      "At  73.4724633693695  epoch  30 has training loss  tensor(0.2506, device='cuda:0')  and validation loss  tensor(0.2344, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  10  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 23  with validation loss:  tensor(0.2343, device='cuda:0') .\n",
      " The total number of epoch trained is  33 .\n",
      " Training completed in:  80.75830578804016 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[-1.3013e-02,  3.8937e-01,  2.7331e-01, -7.7134e-02, -6.5391e-02],\n",
       "                      [-2.4403e-02, -3.2814e-02, -2.7695e-02,  1.0576e-01,  8.8450e-02],\n",
       "                      [ 2.5078e-02,  4.2850e-01,  1.4450e-01, -2.3749e-01, -1.4540e-01],\n",
       "                      [-1.5259e-02,  2.8654e-02, -2.5478e-01, -2.4515e-01, -7.4321e-02],\n",
       "                      [-2.5169e-02, -1.9296e-01, -4.6623e-02, -1.3934e-01,  2.0372e-01],\n",
       "                      [ 1.4997e-03,  3.1609e-01,  4.8015e-01,  3.6515e-01,  1.2458e-01],\n",
       "                      [-3.5017e-01, -3.9541e-01,  1.0655e-01,  1.0083e-01,  3.1811e-02],\n",
       "                      [ 3.9903e-01,  8.1790e-02,  3.0594e-01, -2.8731e-01, -2.2762e-01],\n",
       "                      [ 1.1225e-01,  5.7909e-01,  5.4034e-01, -4.9363e-02, -1.6414e-01],\n",
       "                      [-1.4101e-01, -3.6283e-01, -4.2917e-01, -2.6336e-01, -6.1351e-02],\n",
       "                      [ 2.1715e-01,  5.1638e-01, -1.4776e-01, -1.6922e-01, -1.0258e-01],\n",
       "                      [ 2.6874e-01,  2.5141e-01,  9.6520e-02, -1.4923e-01, -9.9994e-02],\n",
       "                      [-6.7987e-02,  7.4953e-01,  3.8641e-01,  2.3234e-01,  1.4717e-01],\n",
       "                      [ 3.8860e-02, -2.0319e-01, -4.3208e-01, -2.7799e-01, -6.5091e-02],\n",
       "                      [ 5.1128e-01,  6.1839e-01,  1.1226e-01, -1.0994e-01, -6.8997e-02],\n",
       "                      [-3.0949e-05, -2.7831e-02, -9.8439e-02, -5.5426e-02,  1.6215e-01],\n",
       "                      [-3.1145e-01, -6.1889e-01,  1.5116e-01, -1.3925e-03, -2.1665e-02],\n",
       "                      [ 9.4889e-03, -2.3916e-01,  3.0081e-01,  3.9099e-01,  1.0649e-01],\n",
       "                      [-8.7631e-02, -3.7799e-01, -5.4040e-01, -3.2803e-01, -9.8980e-02],\n",
       "                      [-2.5052e-02,  3.5925e-01,  1.3044e-01, -6.9229e-02, -1.0065e-02],\n",
       "                      [ 3.4754e-03, -4.0523e-02,  2.8313e-02,  1.1535e-01,  7.7040e-02],\n",
       "                      [-2.2990e-02, -6.9230e-02, -1.2776e-01, -1.1016e-01, -4.8677e-02],\n",
       "                      [ 2.5398e-01, -1.5076e-01,  9.2794e-02, -1.7250e-01,  1.4736e-02],\n",
       "                      [-3.8122e-02, -3.0778e-01, -4.4675e-01, -1.4981e-01,  8.1686e-02],\n",
       "                      [ 2.6809e-01, -4.9744e-01, -2.6351e-01,  2.3446e-01,  1.2846e-01],\n",
       "                      [ 2.7063e-02,  1.3496e-01, -1.3191e-01, -4.4728e-02,  7.4260e-02],\n",
       "                      [-4.9552e-03, -1.7302e-02, -1.3783e-01, -1.6517e-01, -8.2923e-02],\n",
       "                      [ 1.9944e-04,  8.0016e-02,  4.0945e-02, -1.2355e-01, -9.3174e-02],\n",
       "                      [ 2.1459e-02, -3.3950e-01,  9.8456e-02,  2.0546e-01,  4.4724e-02],\n",
       "                      [ 9.6839e-03,  8.9200e-03,  1.7458e-01,  2.4485e-01,  1.0483e-01],\n",
       "                      [ 1.8363e-01,  5.7163e-01,  6.0951e-01,  2.6567e-01,  1.8908e-02],\n",
       "                      [ 4.2079e-01,  7.3438e-02, -1.3992e-01,  4.8925e-02,  3.1248e-01]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([ 1.2628e-02,  2.6932e-02, -1.4197e-01,  2.5670e-02,  7.9795e-02,\n",
       "                       9.7121e-04,  1.9222e-01, -5.3905e-03,  2.0546e-01,  2.5116e-02,\n",
       "                       3.2769e-02, -5.7999e-02,  3.2334e-02, -5.3210e-02, -8.8886e-02,\n",
       "                       2.0458e-02, -1.4031e-02,  1.3967e-02,  3.6471e-02, -1.0130e-02,\n",
       "                      -4.0863e-05,  3.5490e-02,  1.2664e-02, -5.2900e-02, -9.5596e-02,\n",
       "                      -4.3202e-03,  7.3360e-03,  2.5692e-03, -4.0112e-03, -1.1612e-02,\n",
       "                      -2.5158e-01, -2.1998e-02], device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[ 0.3098, -0.0379, -0.0749,  ...,  0.0092,  0.0700,  0.5764],\n",
       "                      [-0.0177, -0.0479,  0.1101,  ..., -0.0484, -0.0547,  0.0155],\n",
       "                      [ 0.1967,  0.1626,  0.1815,  ..., -0.1098,  0.2899,  0.0953],\n",
       "                      ...,\n",
       "                      [-0.1386, -0.1555,  0.0913,  ..., -0.2777, -0.0866, -0.1767],\n",
       "                      [ 0.0174, -0.2074, -0.0237,  ..., -0.1728,  0.1267,  0.0314],\n",
       "                      [-0.0817,  0.0737, -0.0603,  ..., -0.0139,  0.0928,  0.1602]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[ 0.3250, -0.0508, -0.1123,  ..., -0.5073,  0.0732, -0.1378],\n",
       "                      [ 0.6863,  0.0797,  0.4058,  ..., -0.3456, -0.5240, -0.1203],\n",
       "                      [ 0.1124,  0.2424,  0.0326,  ..., -0.3729, -0.2419,  0.0278],\n",
       "                      ...,\n",
       "                      [ 0.1746, -0.0447,  0.0181,  ..., -0.2048,  0.1816,  0.0188],\n",
       "                      [ 0.1996,  0.6002,  0.1919,  ...,  0.2364,  0.1710, -0.4626],\n",
       "                      [-0.0490, -0.1574, -0.2917,  ..., -0.6026,  0.3585, -0.3754]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([-0.1178, -0.0024, -0.2019,  0.1001,  0.1473, -0.0491, -0.1332, -0.0582,\n",
       "                       0.1112,  0.0852,  0.0917,  0.0846, -0.0644, -0.0925, -0.1094, -0.0322,\n",
       "                      -0.2289, -0.0290,  0.0346, -0.1418,  0.0221,  0.0553,  0.0716,  0.2255,\n",
       "                       0.0076, -0.0589,  0.1047, -0.1326, -0.0157, -0.0875, -0.1506,  0.1891],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([ 3.2828e-02, -2.6533e-01, -6.7540e-02,  5.3128e-02,  1.3619e-01,\n",
       "                       8.7140e-02,  7.9682e-02, -1.9066e-01,  1.1935e-01,  6.2576e-02,\n",
       "                      -1.3442e-01,  1.0371e-02,  7.3204e-02, -1.6927e-01,  4.8571e-02,\n",
       "                      -1.3515e-01, -1.3753e-01,  5.4045e-02, -1.0209e-01, -4.2235e-03,\n",
       "                       1.6207e-01,  6.6100e-02, -1.9344e-01, -7.8733e-02, -4.8117e-02,\n",
       "                       2.7672e-01, -7.6910e-02,  1.7189e-01,  5.6509e-02,  8.6780e-03,\n",
       "                       2.5435e-02, -5.3751e-05], device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[-0.0499, -0.1899,  0.0255, -0.0264,  0.0046, -0.1370,  0.0507, -0.2109,\n",
       "                        0.3328, -0.0019,  0.0520, -0.2140, -0.1467, -0.3020,  0.0137,  0.0473,\n",
       "                        0.0489, -0.1000,  0.2518,  0.1416,  0.0663, -0.1541,  0.0913,  0.3280,\n",
       "                       -0.0199, -0.2331,  0.2933, -0.0358,  0.1127,  0.0526,  0.0145,  0.2203]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([0.1783], device='cuda:0'))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.reg_training_loop_rmspe(optimizer=optimizer,model=RNN_model,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=100,ot_steps=10,report_interval=5,eps=0,scaler=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66a81f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen_conv.frozen_conv.weight False\n",
      "linear_proj_input.weight True\n",
      "linear_proj_input.bias True\n",
      "RNN_layer.weight_ih_l0 True\n",
      "RNN_layer.weight_hh_l0 True\n",
      "RNN_layer.bias_ih_l0 True\n",
      "RNN_layer.bias_hh_l0 True\n",
      "linear_post_rnn.weight True\n",
      "linear_post_rnn.bias True\n"
     ]
    }
   ],
   "source": [
    "for name,param in RNN_model.named_parameters():\n",
    "    print(name,param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e88bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c4ccf4",
   "metadata": {},
   "source": [
    "Above is an example of the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "05ee5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.arange(len(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ebe3da0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff63811f6a0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b72925",
   "metadata": {},
   "source": [
    "## Try to normalize only the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2324a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model_norm_ts=training.RV_RNN_conv(n_diff=4,rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=1).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68516afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_norm_ts=optim.Adam(RNN_model_norm_ts.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae9de7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy.loc[:,\"sub_int_num\"]=np.nan\n",
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy.loc[:,\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV_norm\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV_norm\"],df_ts_feat=df_RV_ts,df_target=df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "509b7bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=256,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=256,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4056c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0a66b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  2.522658109664917  epoch  1 has training loss  tensor(283.0392, device='cuda:0')  and validation loss  tensor(43.5655, device='cuda:0') .\n",
      "\n",
      "At  12.718735694885254  epoch  5 has training loss  tensor(17.9191, device='cuda:0')  and validation loss  tensor(37.9335, device='cuda:0') .\n",
      "\n",
      "At  26.009549140930176  epoch  10 has training loss  tensor(7.6101, device='cuda:0')  and validation loss  tensor(3.5446, device='cuda:0') .\n",
      "\n",
      "At  39.161351442337036  epoch  15 has training loss  tensor(2.6315, device='cuda:0')  and validation loss  tensor(1.4925, device='cuda:0') .\n",
      "\n",
      "At  52.47147059440613  epoch  20 has training loss  tensor(2.2603, device='cuda:0')  and validation loss  tensor(1.0233, device='cuda:0') .\n",
      "\n",
      "At  65.79581642150879  epoch  25 has training loss  tensor(2.3343, device='cuda:0')  and validation loss  tensor(1.7118, device='cuda:0') .\n",
      "\n",
      "At  79.334139585495  epoch  30 has training loss  tensor(2.6137, device='cuda:0')  and validation loss  tensor(1.8254, device='cuda:0') .\n",
      "\n",
      "At  92.26322913169861  epoch  35 has training loss  tensor(2.3198, device='cuda:0')  and validation loss  tensor(3.5959, device='cuda:0') .\n",
      "\n",
      "At  105.20642518997192  epoch  40 has training loss  tensor(2.4839, device='cuda:0')  and validation loss  tensor(1.4842, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  20  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 21  with validation loss:  tensor(0.5534, device='cuda:0') .\n",
      " The total number of epoch trained is  41 .\n",
      " Training completed in:  107.89736342430115 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[-0.0045, -0.0901,  0.1132, -0.2228, -0.1803],\n",
       "                      [-0.1997, -0.3297,  0.1452,  0.3443, -0.0067],\n",
       "                      [-0.0107, -0.2273,  0.4138,  0.0233, -0.1586],\n",
       "                      [-0.0889,  0.3350, -0.1367, -0.1448, -0.4007],\n",
       "                      [ 0.2829, -0.0629,  0.1113, -0.0430,  0.1067],\n",
       "                      [ 0.3070,  0.1270,  0.4153,  0.1222,  0.0056],\n",
       "                      [ 0.1668, -0.4291, -0.0132, -0.2160,  0.2345],\n",
       "                      [ 0.1613, -0.3407,  0.0467,  0.4288,  0.0861],\n",
       "                      [ 0.0653, -0.0928, -0.0263, -0.2540, -0.0603],\n",
       "                      [ 0.0812, -0.2569, -0.0038,  0.1708, -0.1246],\n",
       "                      [ 0.3743,  0.4313, -0.1810, -0.2795,  0.0187],\n",
       "                      [ 0.0401,  0.0395,  0.0658, -0.1657, -0.1592],\n",
       "                      [-0.0402,  0.3869,  0.3598,  0.2136,  0.0075],\n",
       "                      [-0.0650, -0.0289,  0.2271,  0.3552,  0.2315],\n",
       "                      [ 0.3678,  0.1282, -0.2009,  0.3654,  0.2514],\n",
       "                      [-0.0062, -0.3464, -0.3324, -0.0290, -0.0126],\n",
       "                      [-0.0944,  0.2014,  0.1281,  0.3473,  0.0057],\n",
       "                      [ 0.3253, -0.0096, -0.2627,  0.0400,  0.1282],\n",
       "                      [ 0.4956, -0.1440,  0.1999, -0.2800, -0.1951],\n",
       "                      [ 0.0501,  0.2608,  0.1987,  0.1601, -0.1392],\n",
       "                      [-0.0112, -0.1569,  0.1500, -0.0583, -0.1004],\n",
       "                      [ 0.3107,  0.2088, -0.0550,  0.1293,  0.1153],\n",
       "                      [-0.2866,  0.2308, -0.2633, -0.0656,  0.0422],\n",
       "                      [ 0.3230,  0.0646, -0.2153, -0.2714, -0.1071],\n",
       "                      [ 0.2060,  0.1244, -0.3153, -0.2981,  0.5972],\n",
       "                      [-0.1061,  0.0378, -0.1545, -0.4512, -0.2370],\n",
       "                      [ 0.3597, -0.0376,  0.3642, -0.0549, -0.1750],\n",
       "                      [-0.0804, -0.3709,  0.0436, -0.5300,  0.4364],\n",
       "                      [-0.1882, -0.1901, -0.0169,  0.0589, -0.0450],\n",
       "                      [ 0.0748,  0.4169, -0.3247, -0.0675, -0.7775],\n",
       "                      [-0.1283, -0.1630,  0.2123, -0.1098, -0.1756],\n",
       "                      [-0.1097,  0.2151, -0.0023, -0.3765,  0.0132]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([-0.0057, -0.1013, -0.0074,  0.2599,  0.1890,  0.1345, -0.2150,  0.0712,\n",
       "                       0.0300,  0.3206,  0.1795,  0.0153,  0.1227,  0.0018,  0.1638, -0.0037,\n",
       "                       0.1344,  0.2068,  0.2299,  0.0294, -0.0055,  0.1430, -0.1299,  0.1851,\n",
       "                       0.1075, -0.0477,  0.1969,  0.1196, -0.0974,  0.0150, -0.0363, -0.0491],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[ 3.7883e-02, -7.4390e-02,  8.1796e-02,  ...,  1.3746e-02,\n",
       "                       -7.0671e-02,  1.1298e-01],\n",
       "                      [-1.7003e-01, -7.9825e-02,  1.1533e-01,  ..., -3.2246e-02,\n",
       "                        6.0445e-02, -2.1969e-03],\n",
       "                      [-1.2022e-01, -7.2477e-02,  4.6330e-02,  ..., -7.7177e-02,\n",
       "                        1.2686e-01, -1.2398e-01],\n",
       "                      ...,\n",
       "                      [ 1.4775e-01, -1.2599e-01,  4.8405e-02,  ..., -9.3319e-02,\n",
       "                       -1.7944e-02,  1.0043e-01],\n",
       "                      [ 1.9351e-01, -4.2060e-02, -1.4521e-02,  ..., -2.4227e-04,\n",
       "                        5.4732e-02,  5.0702e-02],\n",
       "                      [-1.7626e-01,  1.4203e-01, -7.9240e-02,  ..., -1.5068e-04,\n",
       "                        1.0361e-01, -2.5569e-01]], device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[-0.4502, -0.0572, -0.2031,  ..., -0.1551,  0.0523, -0.1695],\n",
       "                      [-0.0814, -0.4613, -0.1111,  ..., -0.0268, -0.0094, -0.2520],\n",
       "                      [ 0.0196, -0.0430, -0.1224,  ...,  0.3012, -0.0557, -0.1092],\n",
       "                      ...,\n",
       "                      [ 0.0309, -0.0523,  0.3242,  ..., -0.3381, -0.2077,  0.0575],\n",
       "                      [-0.0524,  0.1094,  0.1877,  ...,  0.1321, -0.1839, -0.0140],\n",
       "                      [ 0.0234, -0.1200, -0.0735,  ...,  0.1487,  0.0068, -0.1879]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([-0.0868, -0.1199, -0.0193,  0.0328, -0.0508, -0.1069,  0.0045,  0.0335,\n",
       "                       0.1042,  0.0911, -0.1099,  0.0213,  0.0692, -0.0064, -0.0378,  0.1201,\n",
       "                       0.0012, -0.0127, -0.0158,  0.0450,  0.0414,  0.0459, -0.1204,  0.0210,\n",
       "                       0.1474, -0.0206,  0.0538, -0.1286, -0.0392, -0.0545,  0.0740,  0.0011],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([ 0.0416,  0.0699, -0.0982,  0.0742,  0.0536,  0.1397, -0.1213, -0.0425,\n",
       "                      -0.0891,  0.0819, -0.0114, -0.0097,  0.0637,  0.0775,  0.0467, -0.0504,\n",
       "                      -0.0148, -0.0131,  0.0554, -0.0901,  0.0738,  0.0375,  0.1045,  0.0359,\n",
       "                      -0.1340,  0.0005, -0.0602,  0.0842,  0.0283, -0.0201, -0.0855,  0.0435],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[ 3.1699e-05,  1.8070e-05, -2.9846e-04, -2.0921e-04, -2.3639e-05,\n",
       "                        1.6927e-04,  8.7622e-04, -7.0414e-07,  2.3696e-04,  6.3952e-06,\n",
       "                        1.4242e-04,  6.8951e-06,  1.3125e-03, -6.4379e-05,  4.0132e-05,\n",
       "                        1.1604e-05, -5.0481e-05, -1.5871e-04,  4.1738e-04, -1.9004e-04,\n",
       "                        3.3420e-04,  1.4637e-04, -1.8485e-04,  7.9809e-05, -1.3285e-04,\n",
       "                       -1.1879e-04,  1.7192e-04,  4.4917e-04,  4.9060e-05, -1.2610e-04,\n",
       "                        8.2578e-05,  2.0158e-04]], device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([0.0001], device='cuda:0'))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.reg_training_loop_rmspe(optimizer=optimizer_norm_ts,model=RNN_model_norm_ts,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=200,ot_steps=20,report_interval=5,eps=0,scaler=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d7684d",
   "metadata": {},
   "source": [
    "As a remark, I ran above loop twice, the keep learning to same model after the fact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef1351bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen_conv.frozen_conv.weight False\n",
      "linear_proj_input.weight True\n",
      "linear_proj_input.bias True\n",
      "RNN_layer.weight_ih_l0 True\n",
      "RNN_layer.weight_hh_l0 True\n",
      "RNN_layer.bias_ih_l0 True\n",
      "RNN_layer.bias_hh_l0 True\n",
      "linear_post_rnn.weight True\n",
      "linear_post_rnn.bias True\n"
     ]
    }
   ],
   "source": [
    "for name,param in RNN_model_norm_ts.named_parameters():\n",
    "    print(name,param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2bb082d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1802af02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b022072c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd07d2c3b20>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.arange(len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb605a91",
   "metadata": {},
   "source": [
    "It appears that only normalizing input ts is not a good idea. I should consider normalizing both the input and the target. Plus, in above, I fit transformed on both the training and the test set together, that is technically a data leak. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef78913",
   "metadata": {},
   "source": [
    "## Training with normalization on both input and target "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64325299",
   "metadata": {},
   "source": [
    "I have added normalization functionality to dataset creation function, so not we can create the train and test datasets without dataleaking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c3ffa765",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model_norm_ts=training.RV_RNN_conv(n_diff=4,rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=1).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1190590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_norm_ts=optim.Adam(RNN_model_norm_ts.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2a6245db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:324: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_whole_pv_dna=pd.merge(df_ts_pv,df_tab_pv,on=\"row_id\").dropna(axis=\"rows\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice: sub_int_RV has been normalized.\n",
      "The mean and std of this feature has been stored in feat_norm_dict\n",
      "Notice: target has been normalized.\n",
      "The mean and std of this feature has been stored in feat_norm_dict\n"
     ]
    }
   ],
   "source": [
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target,norm_feature_dict={\"sub_int_RV\":None,\"target\":None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4d97d6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sub_int_RV': (np.float64(0.0004411965933048684),\n",
       "  np.float64(0.0005610956509180131)),\n",
       " 'target': (np.float64(0.0038471398027541486),\n",
       "  np.float64(0.0029489987966883967))}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.feat_norm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8b790b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_norm_feat_dict=copy.deepcopy(train_dataset.feat_norm_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "40163bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.0038471398027541486), np.float64(0.0029489987966883967))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_norm_feat_dict.pop(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "630660e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sub_int_RV': (np.float64(0.0004411965933048684),\n",
       "  np.float64(0.0005610956509180131)),\n",
       " 'target': (np.float64(0.0038471398027541486),\n",
       "  np.float64(0.0029489987966883967))}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.feat_norm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ee121136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sub_int_RV': (np.float64(0.0004411965933048684),\n",
       "  np.float64(0.0005610956509180131))}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_norm_feat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9622afc7",
   "metadata": {},
   "source": [
    "As a reminder, do not apply normalization to target of test set. I am choosing to force the target input features to share the same mean and std as the test dataset's corresponding features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "de12b187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice: sub_int_RV has been normalized.\n",
      "The mean and std of this feature has been stored in feat_norm_dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:324: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_whole_pv_dna=pd.merge(df_ts_pv,df_tab_pv,on=\"row_id\").dropna(axis=\"rows\")\n"
     ]
    }
   ],
   "source": [
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target,norm_feature_dict=test_norm_feat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "0f6a5622",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=256,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=256,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8c799fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8f5ab2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  2.6898677349090576  epoch  1 has training loss  tensor(0.5225, device='cuda:0')  and validation loss  tensor(0.2701, device='cuda:0') .\n",
      "\n",
      "At  13.334021091461182  epoch  5 has training loss  tensor(0.2698, device='cuda:0')  and validation loss  tensor(0.2405, device='cuda:0') .\n",
      "\n",
      "At  27.14174461364746  epoch  10 has training loss  tensor(0.2601, device='cuda:0')  and validation loss  tensor(0.2378, device='cuda:0') .\n",
      "\n",
      "At  40.86601209640503  epoch  15 has training loss  tensor(0.2571, device='cuda:0')  and validation loss  tensor(0.2376, device='cuda:0') .\n",
      "\n",
      "At  54.34972524642944  epoch  20 has training loss  tensor(0.2563, device='cuda:0')  and validation loss  tensor(0.2367, device='cuda:0') .\n",
      "\n",
      "At  68.93456530570984  epoch  25 has training loss  tensor(0.2565, device='cuda:0')  and validation loss  tensor(0.2374, device='cuda:0') .\n",
      "\n",
      "At  82.71377658843994  epoch  30 has training loss  tensor(0.2558, device='cuda:0')  and validation loss  tensor(0.2372, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  20  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 11  with validation loss:  tensor(0.2356, device='cuda:0') .\n",
      " The total number of epoch trained is  31 .\n",
      " Training completed in:  85.40374302864075 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[ 0.2627, -0.2206,  0.5197,  0.2868,  0.2761],\n",
       "                      [ 0.0648, -0.1319, -0.3829, -0.2078, -0.0508],\n",
       "                      [ 0.1711, -0.4481, -0.4151, -0.0360,  0.1213],\n",
       "                      [ 0.3005,  0.7172,  0.1621,  0.3056, -0.3716],\n",
       "                      [ 0.2696, -0.7922, -0.0776,  0.1457, -0.3060],\n",
       "                      [ 0.1616,  0.5800,  0.5489, -0.0974, -0.1805],\n",
       "                      [ 0.2192, -0.6146, -0.5099,  0.1171,  0.0296],\n",
       "                      [ 0.1563, -0.4378,  0.0431,  0.2210, -0.3875],\n",
       "                      [ 0.0191, -0.1619, -0.1135, -0.0143, -0.0737],\n",
       "                      [-0.0346,  0.0979, -0.3353, -0.1638, -0.0153],\n",
       "                      [-0.1278, -0.0767,  0.1895, -0.0360, -0.1317],\n",
       "                      [-0.0106, -0.4260,  0.0853, -0.1074, -0.1160],\n",
       "                      [ 0.2242,  0.0838,  0.2800,  0.1939, -0.0882],\n",
       "                      [-0.0151,  0.2627, -0.0807,  0.1391,  0.1945],\n",
       "                      [-0.1204, -0.4106, -0.0698,  0.4132,  0.2422],\n",
       "                      [ 0.0014, -0.0197, -0.0586, -0.0371, -0.0117],\n",
       "                      [-0.4407, -0.8041,  0.1079, -0.0097, -0.1569],\n",
       "                      [ 0.1369,  0.7717,  0.1749, -0.0880,  0.0141],\n",
       "                      [-0.2244, -0.5144, -0.3802,  0.0841,  0.2931],\n",
       "                      [-0.0177,  0.6688, -0.1303, -0.1975,  0.0780],\n",
       "                      [ 0.3691,  0.3933, -0.0165, -0.0347,  0.0015],\n",
       "                      [-0.1067, -0.0119,  0.0709, -0.2542, -0.3250],\n",
       "                      [ 0.3248, -0.0178,  0.4446, -0.4324, -0.0296],\n",
       "                      [ 0.0640, -0.1950, -0.2156,  0.2956,  0.2932],\n",
       "                      [-0.2894, -0.0806,  0.0479,  0.2667, -0.2006],\n",
       "                      [-0.2902,  0.1691,  0.4975,  0.3598, -0.1383],\n",
       "                      [-0.0593, -0.0494, -0.2019, -0.3801, -0.2338],\n",
       "                      [ 0.3579,  0.4490,  0.4561,  0.2170, -0.0604],\n",
       "                      [-0.0941, -0.1384,  0.0632, -0.3969,  0.0851],\n",
       "                      [-0.0189,  0.0916,  0.2350,  0.3435,  0.1484],\n",
       "                      [-0.0025, -0.3809, -0.4149, -0.0897,  0.0078],\n",
       "                      [-0.1204, -0.6309, -0.4735,  0.0243, -0.2124]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([-0.1184,  0.0286,  0.0943, -0.0719,  0.1210, -0.1309,  0.1087,  0.0460,\n",
       "                       0.0035, -0.0199, -0.0728,  0.0781,  0.1526, -0.0034, -0.0619, -0.0009,\n",
       "                      -0.2076,  0.0470, -0.1594, -0.3214,  0.2005, -0.0664, -0.1967,  0.0397,\n",
       "                      -0.1671, -0.1662, -0.0363, -0.1583,  0.0601, -0.0075, -0.0015,  0.0690],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[-0.0737, -0.0286, -0.0282,  ...,  0.1204,  0.0017, -0.1161],\n",
       "                      [ 0.1474,  0.1602, -0.2286,  ..., -0.0724, -0.0498, -0.1034],\n",
       "                      [ 0.0612,  0.0237,  0.1189,  ...,  0.0276,  0.0360,  0.0412],\n",
       "                      ...,\n",
       "                      [ 0.1249, -0.3130, -0.1970,  ...,  0.0495, -0.1351, -0.1423],\n",
       "                      [-0.0886, -0.0322, -0.1906,  ...,  0.1398, -0.0983,  0.0665],\n",
       "                      [-0.0043,  0.1341,  0.0765,  ...,  0.0741, -0.0293, -0.1369]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[-0.1895, -0.0594, -0.0215,  ..., -0.2617,  0.2027,  0.0856],\n",
       "                      [-0.0672, -0.3342, -0.1581,  ...,  0.1365,  0.1601, -0.0197],\n",
       "                      [ 0.0601, -0.1033, -0.3444,  ...,  0.1922, -0.0840,  0.2269],\n",
       "                      ...,\n",
       "                      [-0.0961, -0.0212, -0.0008,  ..., -0.3447,  0.1249,  0.1260],\n",
       "                      [-0.0278, -0.2637,  0.0896,  ...,  0.0788,  0.6341,  0.0218],\n",
       "                      [-0.0851,  0.0073, -0.2826,  ..., -0.0943,  0.1422, -0.3483]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([ 0.1257,  0.1285,  0.0056,  0.0072,  0.0981, -0.0419, -0.0503, -0.0593,\n",
       "                      -0.0561, -0.1627, -0.0562, -0.0970,  0.0416,  0.1311,  0.1716, -0.0104,\n",
       "                       0.0958, -0.0908, -0.0258, -0.0615, -0.0663,  0.1170,  0.1220,  0.0765,\n",
       "                      -0.0244, -0.0866,  0.0323,  0.0243, -0.0364, -0.0223, -0.1194,  0.0786],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([-0.1000,  0.0082, -0.1038,  0.0070, -0.0460, -0.0015, -0.0904, -0.0403,\n",
       "                       0.0361, -0.0229,  0.0154,  0.0835, -0.0775,  0.1120, -0.1352,  0.0151,\n",
       "                      -0.0686, -0.0858, -0.0893,  0.0849, -0.0679, -0.1626, -0.1585, -0.0967,\n",
       "                       0.0153,  0.0543,  0.0920, -0.0517,  0.0156, -0.0064,  0.0820, -0.0590],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[-0.0074,  0.0067,  0.0007, -0.0105, -0.0001,  0.0014,  0.0036,  0.0019,\n",
       "                       -0.0045,  0.0272,  0.0021, -0.0205, -0.0012, -0.0250, -0.0017, -0.0031,\n",
       "                       -0.0158,  0.0583, -0.0011,  0.0134, -0.0030, -0.0029, -0.0053,  0.0043,\n",
       "                       -0.0129,  0.0281, -0.0078,  0.0022,  0.0098, -0.0047, -0.0021, -0.0034]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([0.0122], device='cuda:0'))])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.reg_training_loop_rmspe(optimizer=optimizer_norm_ts,model=RNN_model_norm_ts,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=200,ot_steps=20,report_interval=5,eps=0,scaler=1,norm_train_target=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea81cbbb",
   "metadata": {},
   "source": [
    "Oh this over trained quickly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0703dbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen_conv.frozen_conv.weight False\n",
      "linear_proj_input.weight True\n",
      "linear_proj_input.bias True\n",
      "RNN_layer.weight_ih_l0 True\n",
      "RNN_layer.weight_hh_l0 True\n",
      "RNN_layer.bias_ih_l0 True\n",
      "RNN_layer.bias_hh_l0 True\n",
      "linear_post_rnn.weight True\n",
      "linear_post_rnn.bias True\n"
     ]
    }
   ],
   "source": [
    "for name,param in RNN_model_norm_ts.named_parameters():\n",
    "    print(name,param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "20ecaf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b859c9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff63819d960>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.linspace(1,len(train_loss),len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e44b27b",
   "metadata": {},
   "source": [
    "As of now, the best outcome comes with \"scaling\" the input timeseries by 10000. Maybe adjust the NN a bit? add some linear and conv layers after the RNN? Multiple layers of RNN? We will see. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
