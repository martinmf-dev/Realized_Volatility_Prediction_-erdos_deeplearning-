{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77e9ebe",
   "metadata": {},
   "source": [
    "## RNN with frozen convolution layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6b854e",
   "metadata": {},
   "source": [
    "The idea is inspired by an application of RNN in predicting if an online review (say, for a product) is positive or negative (1 or 0). Each word in the review sentence is first projected to a large dimension vector space and then sent into an RNN network sequentially. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f6b66b",
   "metadata": {},
   "source": [
    "We will make use of frozen convolution layer to create derivative like features for our time series features. Then, we use the derivative values of a certain time as if a \"word\" in a \"review\", the target RV as if the \"score\" of the \"review\" to train an RNN network that predicts the target RV with the time series features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bd88f7",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "907e47ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from proj_mod import training, data_processing\n",
    "importlib.reload(training);\n",
    "importlib.reload(data_processing);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ef8d13b-6c6f-4cac-b98c-105c0941a447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12efccd",
   "metadata": {},
   "source": [
    "Below is what Yuan needed to get his gpu working, do not run if you do not need it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd83d5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"../dotenv_env/deep_learning.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd9ea17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.3.0\n"
     ]
    }
   ],
   "source": [
    "print(os.environ.get(\"HSA_OVERRIDE_GFX_VERSION\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cb26cd",
   "metadata": {},
   "source": [
    "Let's say, we have following timeseries feature (created randomly), we will create the derivative features first. As a reminder, the zero dimension is the batch size, the dimension one is channel (needed for the first convolution layer, not really a \"thing\" for time series like features). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3d0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_feature=torch.randn(1,1,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b28d5ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6195, -0.6389, -0.1555, -0.3383,  0.0798, -1.6650,  1.1695,\n",
       "          -0.2593,  1.7058,  0.2396,  0.4143, -2.1079, -0.7786,  0.8063,\n",
       "          -1.2070,  0.1275, -1.1544, -1.7544,  0.6644, -0.6037, -0.3678,\n",
       "           0.1948, -1.8461,  0.4062,  0.4913,  0.3940,  1.2150, -1.6215,\n",
       "           0.2274, -1.1374, -0.2868,  0.5215, -1.2731, -0.7222,  2.1310,\n",
       "           0.0263, -0.4286, -1.1935,  2.1196, -0.3426,  0.5490, -0.7507,\n",
       "          -0.2163,  0.7056,  0.3744, -2.0829,  0.8318,  0.5373,  0.6641,\n",
       "          -1.2179, -0.4955, -0.5833, -0.0965,  0.4021,  0.2072, -0.6592,\n",
       "          -0.1757, -1.8129, -0.4105, -0.4676]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "739b2fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_create_diff=training.frozen_diff_conv(n_diff=4)\n",
    "ts_diff_feature=conv_create_diff(ts_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c48f9ca2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6195e+00, -6.3887e-01, -1.5554e-01, -3.3828e-01,  7.9807e-02,\n",
       "          -1.6650e+00,  1.1695e+00, -2.5925e-01,  1.7058e+00,  2.3961e-01,\n",
       "           4.1431e-01, -2.1079e+00, -7.7858e-01,  8.0633e-01, -1.2070e+00,\n",
       "           1.2753e-01, -1.1544e+00, -1.7544e+00,  6.6437e-01, -6.0370e-01,\n",
       "          -3.6780e-01,  1.9476e-01, -1.8461e+00,  4.0624e-01,  4.9125e-01,\n",
       "           3.9399e-01,  1.2150e+00, -1.6215e+00,  2.2744e-01, -1.1374e+00,\n",
       "          -2.8682e-01,  5.2154e-01, -1.2731e+00, -7.2217e-01,  2.1310e+00,\n",
       "           2.6333e-02, -4.2858e-01, -1.1935e+00,  2.1196e+00, -3.4262e-01,\n",
       "           5.4896e-01, -7.5067e-01, -2.1627e-01,  7.0559e-01,  3.7443e-01,\n",
       "          -2.0829e+00,  8.3176e-01,  5.3735e-01,  6.6414e-01, -1.2179e+00,\n",
       "          -4.9555e-01, -5.8328e-01, -9.6545e-02,  4.0210e-01,  2.0719e-01,\n",
       "          -6.5925e-01, -1.7569e-01, -1.8129e+00, -4.1051e-01, -4.6761e-01],\n",
       "         [-2.2584e+00,  4.8334e-01, -1.8275e-01,  4.1809e-01, -1.7448e+00,\n",
       "           2.8345e+00, -1.4288e+00,  1.9651e+00, -1.4662e+00,  1.7470e-01,\n",
       "          -2.5222e+00,  1.3293e+00,  1.5849e+00, -2.0134e+00,  1.3346e+00,\n",
       "          -1.2819e+00, -5.9996e-01,  2.4187e+00, -1.2681e+00,  2.3589e-01,\n",
       "           5.6257e-01, -2.0409e+00,  2.2524e+00,  8.5012e-02, -9.7262e-02,\n",
       "           8.2102e-01, -2.8365e+00,  1.8489e+00, -1.3649e+00,  8.5060e-01,\n",
       "           8.0836e-01, -1.7947e+00,  5.5097e-01,  2.8532e+00, -2.1047e+00,\n",
       "          -4.5491e-01, -7.6488e-01,  3.3130e+00, -2.4622e+00,  8.9158e-01,\n",
       "          -1.2996e+00,  5.3440e-01,  9.2187e-01, -3.3116e-01, -2.4573e+00,\n",
       "           2.9146e+00, -2.9441e-01,  1.2680e-01, -1.8821e+00,  7.2238e-01,\n",
       "          -8.7733e-02,  4.8674e-01,  4.9864e-01, -1.9491e-01, -8.6643e-01,\n",
       "           4.8356e-01, -1.6372e+00,  1.4024e+00, -5.7104e-02,  0.0000e+00],\n",
       "         [ 2.7417e+00, -6.6608e-01,  6.0083e-01, -2.1629e+00,  4.5793e+00,\n",
       "          -4.2633e+00,  3.3938e+00, -3.4313e+00,  1.6409e+00, -2.6969e+00,\n",
       "           3.8515e+00,  2.5562e-01, -3.5983e+00,  3.3479e+00, -2.6165e+00,\n",
       "           6.8196e-01,  3.0187e+00, -3.6868e+00,  1.5040e+00,  3.2667e-01,\n",
       "          -2.6035e+00,  4.2932e+00, -2.1674e+00, -1.8227e-01,  9.1828e-01,\n",
       "          -3.6575e+00,  4.6854e+00, -3.2138e+00,  2.2155e+00, -4.2240e-02,\n",
       "          -2.6030e+00,  2.3457e+00,  2.3022e+00, -4.9578e+00,  1.6498e+00,\n",
       "          -3.0997e-01,  4.0779e+00, -5.7752e+00,  3.3538e+00, -2.1912e+00,\n",
       "           1.8340e+00,  3.8747e-01, -1.2530e+00, -2.1261e+00,  5.3719e+00,\n",
       "          -3.2090e+00,  4.2121e-01, -2.0089e+00,  2.6044e+00, -8.1011e-01,\n",
       "           5.7447e-01,  1.1906e-02, -6.9355e-01, -6.7152e-01,  1.3500e+00,\n",
       "          -2.1208e+00,  3.0396e+00, -1.4595e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-3.4078e+00,  1.2669e+00, -2.7637e+00,  6.7423e+00, -8.8426e+00,\n",
       "           7.6571e+00, -6.8251e+00,  5.0722e+00, -4.3378e+00,  6.5483e+00,\n",
       "          -3.5958e+00, -3.8539e+00,  6.9462e+00, -5.9644e+00,  3.2984e+00,\n",
       "           2.3367e+00, -6.7055e+00,  5.1907e+00, -1.1773e+00, -2.9301e+00,\n",
       "           6.8967e+00, -6.4606e+00,  1.9851e+00,  1.1006e+00, -4.5758e+00,\n",
       "           8.3429e+00, -7.8992e+00,  5.4292e+00, -2.2577e+00, -2.5608e+00,\n",
       "           4.9487e+00, -4.3453e-02, -7.2600e+00,  6.6076e+00, -1.9597e+00,\n",
       "           4.3879e+00, -9.8532e+00,  9.1290e+00, -5.5450e+00,  4.0252e+00,\n",
       "          -1.4466e+00, -1.6405e+00, -8.7309e-01,  7.4980e+00, -8.5809e+00,\n",
       "           3.6302e+00, -2.4301e+00,  4.6133e+00, -3.4146e+00,  1.3846e+00,\n",
       "          -5.6256e-01, -7.0546e-01,  2.2026e-02,  2.0215e+00, -3.4708e+00,\n",
       "           5.1604e+00, -4.4991e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 4.6747e+00, -4.0307e+00,  9.5060e+00, -1.5585e+01,  1.6500e+01,\n",
       "          -1.4482e+01,  1.1897e+01, -9.4100e+00,  1.0886e+01, -1.0144e+01,\n",
       "          -2.5807e-01,  1.0800e+01, -1.2911e+01,  9.2629e+00, -9.6171e-01,\n",
       "          -9.0422e+00,  1.1896e+01, -6.3680e+00, -1.7528e+00,  9.8268e+00,\n",
       "          -1.3357e+01,  8.4457e+00, -8.8452e-01, -5.6763e+00,  1.2919e+01,\n",
       "          -1.6242e+01,  1.3328e+01, -7.6869e+00, -3.0310e-01,  7.5095e+00,\n",
       "          -4.9921e+00, -7.2166e+00,  1.3868e+01, -8.5673e+00,  6.3476e+00,\n",
       "          -1.4241e+01,  1.8982e+01, -1.4674e+01,  9.5702e+00, -5.4718e+00,\n",
       "          -1.9394e-01,  7.6741e-01,  8.3711e+00, -1.6079e+01,  1.2211e+01,\n",
       "          -6.0603e+00,  7.0434e+00, -8.0279e+00,  4.7991e+00, -1.9471e+00,\n",
       "          -1.4289e-01,  7.2748e-01,  1.9995e+00, -5.4923e+00,  8.6311e+00,\n",
       "          -9.6594e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_diff_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79075913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 60])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_diff_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3354b4",
   "metadata": {},
   "source": [
    "We now permute the last two dimensions, essentially, this is just a transposition of the last two dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76682d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_diff_feature=ts_diff_feature.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed4b060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_diff_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cff150",
   "metadata": {},
   "source": [
    "Now, this is a batch (of size 1) of timeseries feature with 60 time steps, and 5 features in each step. We then expand the 5 features, say, to 32 by projection. As a reminder, nn.Linear automatically apply to the last dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b7d96c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_proj=nn.Linear(5,32)\n",
    "ts_feature_proj=linear_proj(ts_diff_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33f82b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_feature_proj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e40c151",
   "metadata": {},
   "source": [
    "In this example, we will not go into too much detail, so let's make the most simple version. We then pass through a layer of RNN, then a layer of linear (to project to dimension 1 again). Learn more about RNN at https://docs.pytorch.org/docs/stable/generated/torch.nn.RNN.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f611ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_layer=nn.RNN(input_size=32,hidden_size=32,num_layers=1,nonlinearity=\"tanh\",batch_first=True,dropout=0)\n",
    "linear_end=nn.Linear(32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "207568f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_out=RNN_layer(ts_feature_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc91386",
   "metadata": {},
   "source": [
    "As a reminder, since no training is done, the RNN basically just applies the initial weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f31dfe8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e423255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_proj=linear_end(RNN_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ba4ee6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_proj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22784470",
   "metadata": {},
   "source": [
    "We will use sum, but we may change this to other functions, according to context or just feeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e293bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_out=torch.sum(out_proj,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b35c7bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2557]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b9f52c",
   "metadata": {},
   "source": [
    "## Creating the actual NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4d007bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created 07/02/25\n",
    "#07/02/25: Moved to training.py \n",
    "#07/08/25: Moved from training.py\n",
    "class RV_RNN_conv(nn.Module):        \n",
    "    #Created 07/02/25 see RNN_with_frozen_conv.ipynb for documentation. \n",
    "    #Modified 07/08/25 Added LSTM and GRU options\n",
    "    def __init__(self,n_diff,rnn_num_layer,rnn_drop_out,rnn_type=\"rnn\",rnn_act=\"tanh\",proj_dim=32,rnn_hidden_size=32,input_scaler=10000):\n",
    "        \"\"\"\n",
    "        :param n_diff: Decides how many derivative features is wanted in the time series. \n",
    "        :param rnn_num_layer: num_layer parameter for rnn. \n",
    "        :param rnn_drop_out: dropout parameter for rnn. \n",
    "        :param rnn_act: Defaulted to \"tanh\". Nonlinearity parameter for rnn. \n",
    "        :param proj_dim: Defaulted to 32. Decided the dimension of projection before feeding into rnn. \n",
    "        :param rnn_hidden_size: Defaulted to 32. The hidden_size parameter for rnn. \n",
    "        :param input_scaler: Defaulted to 10000. Set a scaling to input, a lot of timeseries values of our data are extremely close to zero. \n",
    "        :param rnn_type: 'rnn', 'lstm', or 'gru'\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_scaler=input_scaler\n",
    "        self.frozen_conv=frozen_diff_conv(n_diff=n_diff)\n",
    "        self.linear_proj_input=nn.Linear(n_diff+1,proj_dim)\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "\n",
    "        if rnn_type == \"rnn\":\n",
    "            self.RNN_layer=nn.RNN(input_size=proj_dim,\n",
    "                                  hidden_size=rnn_hidden_size,\n",
    "                                  num_layers=rnn_num_layer,\n",
    "                                  nonlinearity=rnn_act,\n",
    "                                  batch_first=True,\n",
    "                                  dropout=rnn_drop_out)\n",
    "        elif rnn_type == \"lstm\":\n",
    "            if rnn_act is not None:\n",
    "                print(f\"Warning: rnn_act='{rnn_act}' is ignored when using rnn_type='lstm'\")\n",
    "            self.RNN_layer = nn.LSTM(input_size=proj_dim,\n",
    "                                     hidden_size=rnn_hidden_size,\n",
    "                                     num_layers=rnn_num_layer,\n",
    "                                     batch_first=True,\n",
    "                                     dropout=rnn_drop_out)\n",
    "        elif rnn_type == \"gru\":\n",
    "            if rnn_act is not None:\n",
    "                print(f\"Warning: rnn_act='{rnn_act}' is ignored when using rnn_type='gru'\")\n",
    "            self.RNN_layer = nn.GRU(input_size=proj_dim,\n",
    "                                    hidden_size=rnn_hidden_size,\n",
    "                                    num_layers=rnn_num_layer,\n",
    "                                    batch_first=True,\n",
    "                                    dropout=rnn_drop_out)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported rnn_type: {rnn_type}\")\n",
    "        \n",
    "        self.linear_post_rnn=nn.Linear(rnn_hidden_size,1)\n",
    "        self.frozen_list=[\"frozen_conv\"] \n",
    "        \n",
    "    def forward(self,x):\n",
    "        #First, scale the input, and unsqueese to add in one dimension in dim 1 as channel. This is needed for convolution. \n",
    "        x*=self.input_scaler\n",
    "        x=torch.unsqueeze(x,dim=1)\n",
    "        x=self.frozen_conv(x)\n",
    "        x=x.permute(0,2,1)\n",
    "        x=self.linear_proj_input(x)\n",
    "        x=self.RNN_layer(x)[0]\n",
    "        x=self.linear_post_rnn(x)\n",
    "        \n",
    "        return torch.sum(x,dim=1)/self.input_scaler\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71432b31",
   "metadata": {},
   "source": [
    "## Basic testing on the RNN with frozen convolution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9583750",
   "metadata": {},
   "source": [
    "Test it first. As a reminder, the expected input dimensions are (Batch Size, Time Series Length), this is distinct from the example above in that the channel dimension is not present. The channel dimension is added with unsqueeze at dimension 1 so that the first convolution layer can be utilized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df3d8c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_feature=torch.randn(10,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a33fd643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.9971e-01, -1.3001e-01, -1.1403e+00, -7.7236e-01,  1.8599e+00,\n",
       "         -6.9808e-01,  1.5106e+00, -1.4802e+00, -3.9169e-01, -3.1802e-02,\n",
       "         -1.1092e+00,  4.7330e-01,  7.7057e-02, -6.1030e-02,  4.4273e-02,\n",
       "          1.1545e+00,  1.6664e+00, -2.5811e-01, -1.0196e+00,  3.4227e-01,\n",
       "          9.0611e-02, -7.1442e-01, -5.1483e-01,  6.6749e-01,  1.6236e+00,\n",
       "         -1.5389e+00, -7.6098e-01, -6.0926e-01,  1.5119e+00,  1.4623e+00,\n",
       "         -1.8738e+00, -1.0195e+00,  5.1206e-01,  6.5966e-01,  2.5789e-02,\n",
       "         -1.6673e-01, -3.5891e-01, -1.8669e+00, -2.8837e-01,  7.1051e-01,\n",
       "          8.5181e-01,  1.8687e-01,  6.3762e-01, -2.0904e-01, -1.0262e+00,\n",
       "         -6.2161e-01,  1.8408e+00, -1.6856e+00,  5.2398e-01, -5.6024e-01,\n",
       "          1.3300e-01,  1.2988e+00,  7.8794e-02,  4.5463e-02, -3.4238e-01,\n",
       "         -9.0760e-01, -1.3707e+00, -4.4723e-01, -2.9356e-01, -6.8926e-01],\n",
       "        [ 1.4308e+00,  5.3982e-01, -5.7762e-02,  7.6088e-01, -4.5305e-01,\n",
       "          3.6230e-01,  2.3692e-01,  1.2783e+00, -3.0438e-01,  4.8155e-01,\n",
       "         -9.4604e-02, -5.2999e-02,  7.0097e-01, -1.3007e+00, -8.7723e-01,\n",
       "          7.4288e-02, -2.6345e-01,  5.9917e-02, -1.4569e-01,  1.7438e+00,\n",
       "         -7.0533e-01,  1.8248e-01,  6.2562e-01, -1.1259e-01, -6.2901e-01,\n",
       "          4.4033e-01, -4.3137e-01,  1.1272e-02, -2.5805e-01, -4.9702e-01,\n",
       "          1.3716e+00, -3.2789e-01,  3.0504e-01, -8.9711e-01,  2.3774e+00,\n",
       "          1.6353e+00, -1.2243e+00,  1.6841e-01,  7.3736e-01, -1.0567e+00,\n",
       "         -1.0988e+00, -8.9903e-01,  1.6964e-01, -1.3469e+00,  6.7174e-02,\n",
       "         -1.0021e+00,  3.9571e-01,  8.8042e-01, -1.5078e+00,  3.5894e-01,\n",
       "          3.3802e-01,  3.0487e-01,  3.4259e-01, -3.8630e-01, -2.4155e-02,\n",
       "          7.3312e-01,  8.7817e-01, -8.2768e-01, -2.9355e-01,  3.3061e-01],\n",
       "        [ 2.5318e-01,  3.8102e-01,  2.6876e+00, -3.9484e-01, -2.3881e-01,\n",
       "          6.8641e-02,  5.9486e-01, -1.4737e+00,  7.0669e-01,  1.5046e+00,\n",
       "          5.9085e-01,  1.4933e+00, -2.1005e-01,  1.3130e+00, -9.1704e-01,\n",
       "         -1.1039e+00,  1.4833e+00,  4.7081e-02,  2.2842e-01,  4.6167e-01,\n",
       "         -1.0363e-01,  6.6925e-01, -1.5840e+00,  6.5668e-02, -1.4168e+00,\n",
       "         -1.2486e+00, -1.8272e+00,  1.8112e+00,  6.1650e-01, -1.1103e-01,\n",
       "         -1.8234e-01,  5.7363e-02,  8.6665e-01, -2.0815e+00,  4.1343e-01,\n",
       "         -4.2743e-01,  2.8909e-01,  9.4002e-01,  5.8888e-01,  1.6420e-02,\n",
       "         -8.4871e-02,  3.4691e-01, -9.5851e-01, -1.0034e+00, -1.3980e-01,\n",
       "         -4.1359e-01, -1.7873e+00, -9.6459e-01,  3.7664e-01,  1.8563e+00,\n",
       "          1.9582e+00,  8.4362e-01,  1.0092e+00,  1.4458e-03, -8.9394e-02,\n",
       "         -2.7246e+00, -6.4128e-01, -1.9199e+00, -3.2695e-01, -5.1117e-02],\n",
       "        [-1.2159e-01, -9.3231e-01, -9.6076e-01,  1.6190e+00,  1.5291e+00,\n",
       "         -4.0395e-01,  7.7714e-01,  1.8677e+00,  7.4954e-01, -1.0456e+00,\n",
       "         -1.4263e+00, -3.0523e-01,  6.0739e-01, -7.2510e-01, -1.8583e+00,\n",
       "         -1.3546e+00, -2.8826e-01,  1.0497e+00,  9.0350e-01, -1.5834e+00,\n",
       "         -1.6264e-01, -2.9454e-01, -1.1195e+00,  8.4818e-01, -6.9007e-01,\n",
       "         -7.8531e-01,  5.0420e-01, -8.7133e-01, -6.6761e-02, -1.1322e+00,\n",
       "          1.3554e+00, -1.2367e-01,  1.7541e+00, -4.7034e-01,  1.3373e+00,\n",
       "          2.4652e-01, -1.1514e+00,  5.9967e-01, -1.0854e+00, -4.6820e-01,\n",
       "          1.1397e+00, -9.3558e-02, -6.7728e-01, -1.7160e+00,  1.4537e+00,\n",
       "          9.9533e-01,  1.7130e+00,  7.6425e-01, -2.5230e+00,  1.2070e+00,\n",
       "          1.0142e+00, -9.4738e-02, -1.1420e-01, -9.2427e-01,  2.3712e-01,\n",
       "          1.4228e-01,  4.5694e-01,  6.2191e-01,  1.8468e+00, -9.8112e-01],\n",
       "        [ 1.1306e+00,  8.3529e-01, -2.9954e-01, -4.7112e-01, -2.0877e-01,\n",
       "         -4.8950e-03, -7.8825e-01,  1.4376e+00,  8.9070e-01,  5.7410e-01,\n",
       "         -2.1297e+00,  2.0067e+00, -4.7687e-01, -1.6458e-02, -1.0851e+00,\n",
       "          1.0390e+00, -1.5669e+00,  5.4534e-01,  8.1195e-03,  7.4603e-01,\n",
       "          1.7752e+00, -2.3654e-02,  5.3764e-01,  7.7837e-01,  1.7001e-01,\n",
       "          5.3340e-01,  8.1639e-01,  5.8233e-02,  2.0643e+00,  9.8667e-01,\n",
       "          3.8659e-01, -1.8921e+00, -1.5634e+00, -1.3588e+00,  7.2107e-01,\n",
       "         -3.4673e-01,  1.0420e+00, -1.3223e+00, -2.3510e-01,  7.3066e-01,\n",
       "          1.4870e-01, -1.6533e+00, -5.8012e-01,  2.5478e+00, -2.4914e-01,\n",
       "          6.1622e-01, -3.0964e-01, -7.9378e-01,  6.9507e-01,  8.6993e-01,\n",
       "          2.0109e+00,  1.2179e+00, -1.4531e+00, -6.3152e-01, -1.0339e+00,\n",
       "          7.5825e-02,  7.8944e-01,  4.8174e-01,  1.1309e+00,  1.0797e+00],\n",
       "        [ 7.7379e-01, -1.0015e+00, -6.1293e-01, -4.6681e-01, -4.5193e-01,\n",
       "          2.1192e+00,  9.8311e-01,  7.3992e-01, -8.6174e-01,  8.6770e-01,\n",
       "         -3.8720e-01,  8.5517e-02, -8.4072e-01,  9.0587e-01, -5.6736e-01,\n",
       "          2.3657e-01, -5.1644e-01, -8.5824e-01,  1.0341e+00, -1.1768e+00,\n",
       "          9.0630e-01, -6.1566e-02, -8.9221e-02, -4.8559e-01, -1.4921e+00,\n",
       "          9.0793e-01,  7.9805e-01, -1.7393e+00, -3.4292e-02,  1.2818e+00,\n",
       "         -3.2004e+00,  9.9491e-02, -1.3688e+00, -1.2971e+00,  2.6267e-01,\n",
       "          9.5438e-01, -1.4132e+00,  1.8926e+00,  7.1759e-01, -1.9862e+00,\n",
       "         -9.0729e-01, -7.5776e-01, -7.7266e-01, -6.4274e-01, -1.7269e-01,\n",
       "          1.2985e-01,  4.4351e-02,  1.7689e-01,  7.7345e-01, -1.0645e+00,\n",
       "          6.4652e-01, -1.5979e+00,  6.0500e-01, -1.0385e+00, -2.3670e+00,\n",
       "         -4.2446e-01,  1.4906e+00, -7.9251e-01,  9.9229e-01, -1.5774e+00],\n",
       "        [ 5.0177e-01,  2.4106e-01, -6.5872e-01,  1.0902e-01,  5.8086e-01,\n",
       "          1.9186e+00, -2.1326e+00, -6.2231e-01, -2.3593e-01,  1.7025e-01,\n",
       "          1.4749e+00, -9.4292e-01,  1.4547e-01,  9.4311e-01, -8.5379e-01,\n",
       "         -2.2129e-01, -1.3732e+00,  1.3589e+00,  4.6782e-01, -8.9807e-01,\n",
       "          4.7402e-01,  9.1744e-01, -3.2876e-01,  5.9779e-02, -6.4242e-01,\n",
       "          6.8333e-01,  8.7154e-01, -2.3882e-01, -1.0712e+00,  3.9495e-01,\n",
       "          9.2707e-01, -3.0983e-01, -9.8542e-01, -3.6934e-02,  2.6743e+00,\n",
       "          1.0013e+00,  1.1709e-01,  1.5947e-02,  3.3760e-01, -3.6029e-01,\n",
       "         -9.8500e-01,  6.7139e-02, -1.4012e+00,  2.3760e+00,  9.4070e-01,\n",
       "          4.0330e-01,  7.5822e-01,  8.5953e-01,  2.1727e-03,  2.1302e+00,\n",
       "         -8.0883e-01, -6.9155e-01, -6.3846e-01,  3.0520e-01,  7.0363e-01,\n",
       "         -3.8721e-01, -7.9320e-02, -3.1789e-01,  1.6018e+00, -1.7475e-01],\n",
       "        [ 4.8490e-01, -1.3485e+00, -5.2845e-01,  5.3322e-02, -1.4477e+00,\n",
       "          9.9759e-01, -1.8074e+00,  5.3383e-01, -9.1542e-01,  1.7862e+00,\n",
       "          2.3016e-01,  8.7560e-02, -1.2497e+00,  6.4770e-01,  1.8212e-01,\n",
       "         -1.4018e+00,  8.9644e-01, -3.1460e-01, -2.0938e-01, -7.8133e-01,\n",
       "         -7.5440e-01,  1.2900e-01, -7.9421e-01, -3.7794e-01, -6.4391e-01,\n",
       "          1.0784e+00, -3.2008e-01,  1.4775e+00, -1.3190e+00, -1.1476e-01,\n",
       "          7.4479e-01, -3.8717e-01,  1.5714e+00, -1.8139e+00,  1.0767e+00,\n",
       "         -1.9131e-01, -3.9009e-01,  6.7437e-01,  1.9352e-01,  1.2796e+00,\n",
       "          8.4135e-01, -1.4779e-01,  1.2561e+00,  1.0188e+00, -2.6481e-01,\n",
       "         -8.8988e-01, -2.6440e-01,  3.8843e-01,  1.8583e+00,  6.6880e-01,\n",
       "         -3.5173e-01,  7.0168e-01,  6.8942e-03,  8.2315e-01, -5.4192e-01,\n",
       "          3.9011e-01, -2.0729e+00,  2.0115e-01, -1.0041e+00,  1.4397e+00],\n",
       "        [-5.4609e-01, -4.4945e-01,  8.4361e-01,  9.1256e-01, -2.1864e-01,\n",
       "          1.4071e+00,  9.5832e-01,  1.1638e+00,  4.8710e-01,  1.4185e+00,\n",
       "         -5.6033e-01,  5.4311e-01, -1.0688e+00, -6.0023e-02, -4.0872e-01,\n",
       "          7.2920e-01,  3.6835e-01,  1.2659e+00, -9.8012e-01,  1.3341e-01,\n",
       "          4.7883e-01, -3.3977e-01, -3.3112e-02,  1.7383e+00, -1.0779e-01,\n",
       "          6.0118e-01, -7.4359e-01,  2.2610e-02, -7.3870e-01,  8.4551e-01,\n",
       "          3.0700e-01, -1.1002e-01,  9.7740e-01, -1.0727e+00,  1.0603e-01,\n",
       "          4.6367e-01,  4.9650e-01, -1.1421e-01, -1.8990e-01, -3.7088e-01,\n",
       "         -1.0236e+00, -4.6599e-02, -1.7324e-01, -7.4255e-02,  6.5932e-01,\n",
       "          1.0170e+00,  1.3835e+00,  1.2800e+00, -3.1610e-01, -5.9489e-01,\n",
       "          8.0888e-01,  7.8598e-01,  2.4849e-01, -1.0180e+00,  7.3784e-01,\n",
       "          3.8891e-01, -4.3239e-01,  1.6123e+00,  1.9342e-01,  1.8111e+00],\n",
       "        [ 1.0528e+00,  1.5704e+00,  1.9603e-03, -1.4646e+00, -7.5266e-01,\n",
       "          1.3770e-01, -1.9638e-01, -2.8527e-01,  1.1037e+00, -1.8202e+00,\n",
       "         -5.3344e-01,  9.3706e-02, -1.7282e+00,  4.0101e-01,  1.5522e+00,\n",
       "         -7.6144e-01,  1.1975e+00,  1.1506e+00, -1.7320e+00,  3.1218e-01,\n",
       "         -5.2718e-01,  1.3342e-01,  4.5582e-01, -1.1597e+00, -6.2798e-01,\n",
       "          5.8446e-02,  2.7572e-01,  1.1971e+00,  1.5550e+00, -1.8516e+00,\n",
       "         -7.1024e-01,  4.1439e-01,  7.8271e-01,  1.0857e+00, -5.0055e-01,\n",
       "         -1.8306e+00,  6.7957e-02, -5.3453e-01, -1.3076e-01,  1.4755e+00,\n",
       "          5.7825e-01,  1.9042e+00,  3.1708e-01, -8.3081e-01,  1.7181e-01,\n",
       "          3.1793e-02,  1.8867e-01,  1.6538e+00,  3.2521e-02,  2.5793e-01,\n",
       "         -1.6234e-02, -8.3267e-01, -2.0775e+00, -8.5538e-01,  3.1289e-02,\n",
       "          4.3229e-01,  7.8150e-01, -1.9540e+00,  4.6232e-01,  1.4607e+00]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72cd7276",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.9971e-01, -1.3001e-01, -1.1403e+00, -7.7236e-01,  1.8599e+00,\n",
       "          -6.9808e-01,  1.5106e+00, -1.4802e+00, -3.9169e-01, -3.1802e-02,\n",
       "          -1.1092e+00,  4.7330e-01,  7.7057e-02, -6.1030e-02,  4.4273e-02,\n",
       "           1.1545e+00,  1.6664e+00, -2.5811e-01, -1.0196e+00,  3.4227e-01,\n",
       "           9.0611e-02, -7.1442e-01, -5.1483e-01,  6.6749e-01,  1.6236e+00,\n",
       "          -1.5389e+00, -7.6098e-01, -6.0926e-01,  1.5119e+00,  1.4623e+00,\n",
       "          -1.8738e+00, -1.0195e+00,  5.1206e-01,  6.5966e-01,  2.5789e-02,\n",
       "          -1.6673e-01, -3.5891e-01, -1.8669e+00, -2.8837e-01,  7.1051e-01,\n",
       "           8.5181e-01,  1.8687e-01,  6.3762e-01, -2.0904e-01, -1.0262e+00,\n",
       "          -6.2161e-01,  1.8408e+00, -1.6856e+00,  5.2398e-01, -5.6024e-01,\n",
       "           1.3300e-01,  1.2988e+00,  7.8794e-02,  4.5463e-02, -3.4238e-01,\n",
       "          -9.0760e-01, -1.3707e+00, -4.4723e-01, -2.9356e-01, -6.8926e-01]],\n",
       "\n",
       "        [[ 1.4308e+00,  5.3982e-01, -5.7762e-02,  7.6088e-01, -4.5305e-01,\n",
       "           3.6230e-01,  2.3692e-01,  1.2783e+00, -3.0438e-01,  4.8155e-01,\n",
       "          -9.4604e-02, -5.2999e-02,  7.0097e-01, -1.3007e+00, -8.7723e-01,\n",
       "           7.4288e-02, -2.6345e-01,  5.9917e-02, -1.4569e-01,  1.7438e+00,\n",
       "          -7.0533e-01,  1.8248e-01,  6.2562e-01, -1.1259e-01, -6.2901e-01,\n",
       "           4.4033e-01, -4.3137e-01,  1.1272e-02, -2.5805e-01, -4.9702e-01,\n",
       "           1.3716e+00, -3.2789e-01,  3.0504e-01, -8.9711e-01,  2.3774e+00,\n",
       "           1.6353e+00, -1.2243e+00,  1.6841e-01,  7.3736e-01, -1.0567e+00,\n",
       "          -1.0988e+00, -8.9903e-01,  1.6964e-01, -1.3469e+00,  6.7174e-02,\n",
       "          -1.0021e+00,  3.9571e-01,  8.8042e-01, -1.5078e+00,  3.5894e-01,\n",
       "           3.3802e-01,  3.0487e-01,  3.4259e-01, -3.8630e-01, -2.4155e-02,\n",
       "           7.3312e-01,  8.7817e-01, -8.2768e-01, -2.9355e-01,  3.3061e-01]],\n",
       "\n",
       "        [[ 2.5318e-01,  3.8102e-01,  2.6876e+00, -3.9484e-01, -2.3881e-01,\n",
       "           6.8641e-02,  5.9486e-01, -1.4737e+00,  7.0669e-01,  1.5046e+00,\n",
       "           5.9085e-01,  1.4933e+00, -2.1005e-01,  1.3130e+00, -9.1704e-01,\n",
       "          -1.1039e+00,  1.4833e+00,  4.7081e-02,  2.2842e-01,  4.6167e-01,\n",
       "          -1.0363e-01,  6.6925e-01, -1.5840e+00,  6.5668e-02, -1.4168e+00,\n",
       "          -1.2486e+00, -1.8272e+00,  1.8112e+00,  6.1650e-01, -1.1103e-01,\n",
       "          -1.8234e-01,  5.7363e-02,  8.6665e-01, -2.0815e+00,  4.1343e-01,\n",
       "          -4.2743e-01,  2.8909e-01,  9.4002e-01,  5.8888e-01,  1.6420e-02,\n",
       "          -8.4871e-02,  3.4691e-01, -9.5851e-01, -1.0034e+00, -1.3980e-01,\n",
       "          -4.1359e-01, -1.7873e+00, -9.6459e-01,  3.7664e-01,  1.8563e+00,\n",
       "           1.9582e+00,  8.4362e-01,  1.0092e+00,  1.4458e-03, -8.9394e-02,\n",
       "          -2.7246e+00, -6.4128e-01, -1.9199e+00, -3.2695e-01, -5.1117e-02]],\n",
       "\n",
       "        [[-1.2159e-01, -9.3231e-01, -9.6076e-01,  1.6190e+00,  1.5291e+00,\n",
       "          -4.0395e-01,  7.7714e-01,  1.8677e+00,  7.4954e-01, -1.0456e+00,\n",
       "          -1.4263e+00, -3.0523e-01,  6.0739e-01, -7.2510e-01, -1.8583e+00,\n",
       "          -1.3546e+00, -2.8826e-01,  1.0497e+00,  9.0350e-01, -1.5834e+00,\n",
       "          -1.6264e-01, -2.9454e-01, -1.1195e+00,  8.4818e-01, -6.9007e-01,\n",
       "          -7.8531e-01,  5.0420e-01, -8.7133e-01, -6.6761e-02, -1.1322e+00,\n",
       "           1.3554e+00, -1.2367e-01,  1.7541e+00, -4.7034e-01,  1.3373e+00,\n",
       "           2.4652e-01, -1.1514e+00,  5.9967e-01, -1.0854e+00, -4.6820e-01,\n",
       "           1.1397e+00, -9.3558e-02, -6.7728e-01, -1.7160e+00,  1.4537e+00,\n",
       "           9.9533e-01,  1.7130e+00,  7.6425e-01, -2.5230e+00,  1.2070e+00,\n",
       "           1.0142e+00, -9.4738e-02, -1.1420e-01, -9.2427e-01,  2.3712e-01,\n",
       "           1.4228e-01,  4.5694e-01,  6.2191e-01,  1.8468e+00, -9.8112e-01]],\n",
       "\n",
       "        [[ 1.1306e+00,  8.3529e-01, -2.9954e-01, -4.7112e-01, -2.0877e-01,\n",
       "          -4.8950e-03, -7.8825e-01,  1.4376e+00,  8.9070e-01,  5.7410e-01,\n",
       "          -2.1297e+00,  2.0067e+00, -4.7687e-01, -1.6458e-02, -1.0851e+00,\n",
       "           1.0390e+00, -1.5669e+00,  5.4534e-01,  8.1195e-03,  7.4603e-01,\n",
       "           1.7752e+00, -2.3654e-02,  5.3764e-01,  7.7837e-01,  1.7001e-01,\n",
       "           5.3340e-01,  8.1639e-01,  5.8233e-02,  2.0643e+00,  9.8667e-01,\n",
       "           3.8659e-01, -1.8921e+00, -1.5634e+00, -1.3588e+00,  7.2107e-01,\n",
       "          -3.4673e-01,  1.0420e+00, -1.3223e+00, -2.3510e-01,  7.3066e-01,\n",
       "           1.4870e-01, -1.6533e+00, -5.8012e-01,  2.5478e+00, -2.4914e-01,\n",
       "           6.1622e-01, -3.0964e-01, -7.9378e-01,  6.9507e-01,  8.6993e-01,\n",
       "           2.0109e+00,  1.2179e+00, -1.4531e+00, -6.3152e-01, -1.0339e+00,\n",
       "           7.5825e-02,  7.8944e-01,  4.8174e-01,  1.1309e+00,  1.0797e+00]],\n",
       "\n",
       "        [[ 7.7379e-01, -1.0015e+00, -6.1293e-01, -4.6681e-01, -4.5193e-01,\n",
       "           2.1192e+00,  9.8311e-01,  7.3992e-01, -8.6174e-01,  8.6770e-01,\n",
       "          -3.8720e-01,  8.5517e-02, -8.4072e-01,  9.0587e-01, -5.6736e-01,\n",
       "           2.3657e-01, -5.1644e-01, -8.5824e-01,  1.0341e+00, -1.1768e+00,\n",
       "           9.0630e-01, -6.1566e-02, -8.9221e-02, -4.8559e-01, -1.4921e+00,\n",
       "           9.0793e-01,  7.9805e-01, -1.7393e+00, -3.4292e-02,  1.2818e+00,\n",
       "          -3.2004e+00,  9.9491e-02, -1.3688e+00, -1.2971e+00,  2.6267e-01,\n",
       "           9.5438e-01, -1.4132e+00,  1.8926e+00,  7.1759e-01, -1.9862e+00,\n",
       "          -9.0729e-01, -7.5776e-01, -7.7266e-01, -6.4274e-01, -1.7269e-01,\n",
       "           1.2985e-01,  4.4351e-02,  1.7689e-01,  7.7345e-01, -1.0645e+00,\n",
       "           6.4652e-01, -1.5979e+00,  6.0500e-01, -1.0385e+00, -2.3670e+00,\n",
       "          -4.2446e-01,  1.4906e+00, -7.9251e-01,  9.9229e-01, -1.5774e+00]],\n",
       "\n",
       "        [[ 5.0177e-01,  2.4106e-01, -6.5872e-01,  1.0902e-01,  5.8086e-01,\n",
       "           1.9186e+00, -2.1326e+00, -6.2231e-01, -2.3593e-01,  1.7025e-01,\n",
       "           1.4749e+00, -9.4292e-01,  1.4547e-01,  9.4311e-01, -8.5379e-01,\n",
       "          -2.2129e-01, -1.3732e+00,  1.3589e+00,  4.6782e-01, -8.9807e-01,\n",
       "           4.7402e-01,  9.1744e-01, -3.2876e-01,  5.9779e-02, -6.4242e-01,\n",
       "           6.8333e-01,  8.7154e-01, -2.3882e-01, -1.0712e+00,  3.9495e-01,\n",
       "           9.2707e-01, -3.0983e-01, -9.8542e-01, -3.6934e-02,  2.6743e+00,\n",
       "           1.0013e+00,  1.1709e-01,  1.5947e-02,  3.3760e-01, -3.6029e-01,\n",
       "          -9.8500e-01,  6.7139e-02, -1.4012e+00,  2.3760e+00,  9.4070e-01,\n",
       "           4.0330e-01,  7.5822e-01,  8.5953e-01,  2.1727e-03,  2.1302e+00,\n",
       "          -8.0883e-01, -6.9155e-01, -6.3846e-01,  3.0520e-01,  7.0363e-01,\n",
       "          -3.8721e-01, -7.9320e-02, -3.1789e-01,  1.6018e+00, -1.7475e-01]],\n",
       "\n",
       "        [[ 4.8490e-01, -1.3485e+00, -5.2845e-01,  5.3322e-02, -1.4477e+00,\n",
       "           9.9759e-01, -1.8074e+00,  5.3383e-01, -9.1542e-01,  1.7862e+00,\n",
       "           2.3016e-01,  8.7560e-02, -1.2497e+00,  6.4770e-01,  1.8212e-01,\n",
       "          -1.4018e+00,  8.9644e-01, -3.1460e-01, -2.0938e-01, -7.8133e-01,\n",
       "          -7.5440e-01,  1.2900e-01, -7.9421e-01, -3.7794e-01, -6.4391e-01,\n",
       "           1.0784e+00, -3.2008e-01,  1.4775e+00, -1.3190e+00, -1.1476e-01,\n",
       "           7.4479e-01, -3.8717e-01,  1.5714e+00, -1.8139e+00,  1.0767e+00,\n",
       "          -1.9131e-01, -3.9009e-01,  6.7437e-01,  1.9352e-01,  1.2796e+00,\n",
       "           8.4135e-01, -1.4779e-01,  1.2561e+00,  1.0188e+00, -2.6481e-01,\n",
       "          -8.8988e-01, -2.6440e-01,  3.8843e-01,  1.8583e+00,  6.6880e-01,\n",
       "          -3.5173e-01,  7.0168e-01,  6.8942e-03,  8.2315e-01, -5.4192e-01,\n",
       "           3.9011e-01, -2.0729e+00,  2.0115e-01, -1.0041e+00,  1.4397e+00]],\n",
       "\n",
       "        [[-5.4609e-01, -4.4945e-01,  8.4361e-01,  9.1256e-01, -2.1864e-01,\n",
       "           1.4071e+00,  9.5832e-01,  1.1638e+00,  4.8710e-01,  1.4185e+00,\n",
       "          -5.6033e-01,  5.4311e-01, -1.0688e+00, -6.0023e-02, -4.0872e-01,\n",
       "           7.2920e-01,  3.6835e-01,  1.2659e+00, -9.8012e-01,  1.3341e-01,\n",
       "           4.7883e-01, -3.3977e-01, -3.3112e-02,  1.7383e+00, -1.0779e-01,\n",
       "           6.0118e-01, -7.4359e-01,  2.2610e-02, -7.3870e-01,  8.4551e-01,\n",
       "           3.0700e-01, -1.1002e-01,  9.7740e-01, -1.0727e+00,  1.0603e-01,\n",
       "           4.6367e-01,  4.9650e-01, -1.1421e-01, -1.8990e-01, -3.7088e-01,\n",
       "          -1.0236e+00, -4.6599e-02, -1.7324e-01, -7.4255e-02,  6.5932e-01,\n",
       "           1.0170e+00,  1.3835e+00,  1.2800e+00, -3.1610e-01, -5.9489e-01,\n",
       "           8.0888e-01,  7.8598e-01,  2.4849e-01, -1.0180e+00,  7.3784e-01,\n",
       "           3.8891e-01, -4.3239e-01,  1.6123e+00,  1.9342e-01,  1.8111e+00]],\n",
       "\n",
       "        [[ 1.0528e+00,  1.5704e+00,  1.9603e-03, -1.4646e+00, -7.5266e-01,\n",
       "           1.3770e-01, -1.9638e-01, -2.8527e-01,  1.1037e+00, -1.8202e+00,\n",
       "          -5.3344e-01,  9.3706e-02, -1.7282e+00,  4.0101e-01,  1.5522e+00,\n",
       "          -7.6144e-01,  1.1975e+00,  1.1506e+00, -1.7320e+00,  3.1218e-01,\n",
       "          -5.2718e-01,  1.3342e-01,  4.5582e-01, -1.1597e+00, -6.2798e-01,\n",
       "           5.8446e-02,  2.7572e-01,  1.1971e+00,  1.5550e+00, -1.8516e+00,\n",
       "          -7.1024e-01,  4.1439e-01,  7.8271e-01,  1.0857e+00, -5.0055e-01,\n",
       "          -1.8306e+00,  6.7957e-02, -5.3453e-01, -1.3076e-01,  1.4755e+00,\n",
       "           5.7825e-01,  1.9042e+00,  3.1708e-01, -8.3081e-01,  1.7181e-01,\n",
       "           3.1793e-02,  1.8867e-01,  1.6538e+00,  3.2521e-02,  2.5793e-01,\n",
       "          -1.6234e-02, -8.3267e-01, -2.0775e+00, -8.5538e-01,  3.1289e-02,\n",
       "           4.3229e-01,  7.8150e-01, -1.9540e+00,  4.6232e-01,  1.4607e+00]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(ts_feature,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "455ed170",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=training.RV_RNN_conv(n_diff=4,rnn_act=\"tanh\",rnn_num_layer=2,rnn_drop_out=0.3,rnn_hidden_size=32,proj_dim=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85bf9cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=model(ts_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc35034a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3662e-05],\n",
       "        [ 2.1474e-04],\n",
       "        [-1.5604e-04],\n",
       "        [ 4.3390e-04],\n",
       "        [ 1.9061e-04],\n",
       "        [ 1.2641e-04],\n",
       "        [ 1.4729e-04],\n",
       "        [ 2.5284e-04],\n",
       "        [ 2.1373e-04],\n",
       "        [ 1.3819e-04]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bfbac7",
   "metadata": {},
   "source": [
    "## Training loop (basic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06d4fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_time=np.load(\"../processed_data/recovered_time_id_order.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "739d9a32-e68b-4f66-bd6b-0fda83803f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4294 31984 31570 ... 29316 32195 10890]\n"
     ]
    }
   ],
   "source": [
    "print(list_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "825838c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In fold 0 :\n",
      "\n",
      "Train set end at 8117 .\n",
      "\n",
      "Test set start at 15516 end at 10890 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_split_list=data_processing.time_cross_val_split(list_time=list_time,n_split=1,percent_val_size=10,list_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87ca970a-b88b-4b85-8337-6cf6a957e5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4294, 31984, 31570, ...,  5629, 10421,  8117])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_split_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7ba8aa2-a446-4389-8d49-bca021ceb63f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15516, 30276, 16402, 27182, 24497, 13529,   373,  4219, 20323,\n",
       "        9160, 28983, 17820, 22678,  7460, 29676, 32048, 22405, 31380,\n",
       "        1816, 14079, 29944, 21990, 26804, 28210, 18142, 11682, 32597,\n",
       "       13513, 32690, 27120, 27427,  7418,  1213,  9822, 29692, 24523,\n",
       "       25318,  6274, 25569, 12713,   169, 20732, 15906, 28877, 25551,\n",
       "       10745, 31320, 31714,  6076, 23656,   424,   309, 17604, 28963,\n",
       "       23144, 11872, 29219, 25357, 22828, 17569, 17955, 11920, 18509,\n",
       "       19626, 16149,  5392,  7200, 10929,  4774, 27278, 23639, 10633,\n",
       "          72, 32534, 26944, 31018, 26494,  6648,   709,  6823, 21239,\n",
       "       11995, 23265, 31883,  2711,  1350,  1321, 16282,  5046, 29875,\n",
       "        7133, 15823, 25463,  9064,  3333, 11440, 16831,  6815, 19580,\n",
       "       30620, 24014, 17193, 10708, 30597,  4367, 27962, 13010, 32254,\n",
       "       23226, 22903,  5929, 30327,  1866, 14629,  1205,  9352, 10619,\n",
       "       14234, 15276,  4091, 22752, 18653, 11453, 26708, 30183, 13986,\n",
       "           5,  7864,  9889, 31471, 26868, 10672, 31347, 15418, 30430,\n",
       "       26568, 28267,  3955,  1392, 27014, 22081, 15845, 18728,  9936,\n",
       "        5232,  2366, 26886, 30272, 11393, 30750,  7572, 21601,  2331,\n",
       "       13207, 12073,  2058, 18502, 25429, 12532, 27496,  5932,   536,\n",
       "       27595, 23185, 26752,  2683,  6585, 15131,  6144, 27042,  7743,\n",
       "       22249, 32611,  3758, 19271, 13614, 31572, 17570,  9367, 11263,\n",
       "       14285, 12981,   146,  2643, 31266, 23490,  2109, 29906, 30303,\n",
       "       12102, 32649,  8721, 26606, 32012, 16511, 30908, 19871,  3513,\n",
       "        3001, 24127, 29974, 27752, 16504,  6631,  8750,  6493, 29819,\n",
       "       12147, 13503, 11264, 31236,  8365, 23486, 13294,  1292, 17265,\n",
       "       16594, 20928, 18205,  6316,  8459, 19955,  7369, 26763, 13560,\n",
       "        3211, 31254, 13720,   152,  4844, 14738, 22548, 27886,  4131,\n",
       "        6657, 13699, 25639,  2000, 26788, 21103, 11577, 29037,  9947,\n",
       "       32134, 30341, 17112,  7548, 20265, 12533, 10262, 10616,  7512,\n",
       "       28354, 25879,  2440, 21614, 32255, 15584,  9735, 31874, 30366,\n",
       "       31047, 16507,  6906,  9396,  6217,  1521, 17378, 26091,  3318,\n",
       "       32746,  8744, 26889,  1468,  6965, 17117,   817,  3130, 14928,\n",
       "       21373, 13980, 28634,   103, 27543, 26849,  7909, 18077, 30569,\n",
       "       10105, 12178, 20491, 32704, 12923, 15393, 14976, 26168,  2867,\n",
       "       12182, 27524, 30339, 18285, 28474, 27981, 13928, 10892, 14909,\n",
       "       21024, 25971,  9266, 25277,  5425, 17454,  3962, 14449, 31389,\n",
       "       17672,  9887, 20669,  4089, 19512, 30212, 11151, 22912, 25359,\n",
       "       29947, 31348, 16731,  1948,  6730, 14176,  2656, 15728,  8573,\n",
       "       21762,  6359,  5846, 12521, 26578,  8623,  9096, 23423, 22513,\n",
       "       23539, 17528,  5663, 24021, 32240, 28635,  2553, 13791, 22427,\n",
       "       19647, 26170,  2718, 28192, 19065,  2136, 29679,  9028, 17120,\n",
       "       25312,   618, 18184, 21658, 13627, 25338, 31402, 24406, 31331,\n",
       "        7759,  3123,  2027, 18703, 28837, 11718, 13579, 10455, 10604,\n",
       "       24913, 15365, 29316, 32195, 10890])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_split_list[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72aedca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_id,test_time_id=time_split_list[0][0],time_split_list[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3338fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RV_ts=pd.read_parquet(\"../processed_data/book_RV_ts_60_si.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62e2f34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b9cf070",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e42729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RV_ts[\"sub_int_RV_norm\"]=scalar.fit_transform(df_RV_ts[[\"sub_int_RV\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "995d9083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>sub_int_RV</th>\n",
       "      <th>sub_int_num</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>sub_int_RV_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-5</td>\n",
       "      <td>-0.208285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-11</td>\n",
       "      <td>-0.453866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-16</td>\n",
       "      <td>-0.569259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-31</td>\n",
       "      <td>-0.428690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-62</td>\n",
       "      <td>-0.540259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735915</th>\n",
       "      <td>32686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32686</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735916</th>\n",
       "      <td>32690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32690</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735917</th>\n",
       "      <td>32712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32712</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735918</th>\n",
       "      <td>32746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32746</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735919</th>\n",
       "      <td>32758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32758</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25735920 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          time_id  sub_int_RV  sub_int_num  stock_id     row_id  \\\n",
       "0               5    0.000329            1        93       93-5   \n",
       "1              11    0.000191            1        93      93-11   \n",
       "2              16    0.000126            1        93      93-16   \n",
       "3              31    0.000205            1        93      93-31   \n",
       "4              62    0.000142            1        93      93-62   \n",
       "...           ...         ...          ...       ...        ...   \n",
       "25735915    32686    0.000000           60       104  104-32686   \n",
       "25735916    32690    0.000000           60       104  104-32690   \n",
       "25735917    32712    0.000000           60       104  104-32712   \n",
       "25735918    32746    0.000000           60       104  104-32746   \n",
       "25735919    32758    0.000000           60       104  104-32758   \n",
       "\n",
       "          sub_int_RV_norm  \n",
       "0               -0.208285  \n",
       "1               -0.453866  \n",
       "2               -0.569259  \n",
       "3               -0.428690  \n",
       "4               -0.540259  \n",
       "...                   ...  \n",
       "25735915        -0.793956  \n",
       "25735916        -0.793956  \n",
       "25735917        -0.793956  \n",
       "25735918        -0.793956  \n",
       "25735919        -0.793956  \n",
       "\n",
       "[25735920 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RV_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de450e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"21\" halign=\"left\">sub_int_RV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_int_num</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-1000</th>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>3.818799e-07</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>2.313288e-04</td>\n",
       "      <td>1.060893e-05</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10000</th>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>3.154886e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>3.777703e-08</td>\n",
       "      <td>3.777703e-08</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10005</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>4.375100e-04</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>2.552987e-03</td>\n",
       "      <td>5.364106e-04</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10017</th>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>6.771948e-05</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>3.104404e-03</td>\n",
       "      <td>1.224910e-03</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.003287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10030</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>2.586782e-04</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>4.842470e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9972</th>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>2.503467e-04</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>9.916624e-05</td>\n",
       "      <td>1.809852e-04</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9973</th>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>9.650211e-04</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>1.862600e-03</td>\n",
       "      <td>7.668418e-04</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.002115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9976</th>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>7.203531e-04</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>5.946683e-04</td>\n",
       "      <td>1.509652e-04</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9988</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.957402e-04</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.440137e-04</td>\n",
       "      <td>3.200939e-05</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9993</th>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>1.798617e-04</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>2.728767e-04</td>\n",
       "      <td>2.108380e-04</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows  60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sub_int_RV                                                        \\\n",
       "sub_int_num         1         2         3         4         5             6    \n",
       "row_id                                                                         \n",
       "0-1000        0.000341  0.000000  0.000023  0.000000  0.000170  3.818799e-07   \n",
       "0-10000       0.000290  0.000191  0.000087  0.000193  0.000241  3.154886e-04   \n",
       "0-10005       0.000000  0.000000  0.001554  0.002177  0.002303  4.375100e-04   \n",
       "0-10017       0.000142  0.000142  0.001464  0.001086  0.000068  6.771948e-05   \n",
       "0-10030       0.000327  0.000058  0.000293  0.000842  0.000120  2.586782e-04   \n",
       "...                ...       ...       ...       ...       ...           ...   \n",
       "99-9972       0.000197  0.000181  0.000171  0.000172  0.000369  2.503467e-04   \n",
       "99-9973       0.000821  0.000346  0.000691  0.001591  0.000863  9.650211e-04   \n",
       "99-9976       0.000569  0.001101  0.001002  0.000430  0.000797  7.203531e-04   \n",
       "99-9988       0.000040  0.000069  0.000123  0.000056  0.000016  1.957402e-04   \n",
       "99-9993       0.000249  0.000179  0.000155  0.000025  0.000325  1.798617e-04   \n",
       "\n",
       "                                                     ...                      \\\n",
       "sub_int_num        7         8         9         10  ...        51        52   \n",
       "row_id                                               ...                       \n",
       "0-1000       0.000089  0.000552  0.000012  0.000000  ...  0.000265  0.000000   \n",
       "0-10000      0.000000  0.000247  0.000265  0.000000  ...  0.000202  0.000375   \n",
       "0-10005      0.000617  0.001199  0.002306  0.001215  ...  0.000000  0.000486   \n",
       "0-10017      0.000899  0.000064  0.000593  0.000451  ...  0.000029  0.000000   \n",
       "0-10030      0.000221  0.000436  0.000099  0.000008  ...  0.000410  0.000437   \n",
       "...               ...       ...       ...       ...  ...       ...       ...   \n",
       "99-9972      0.000349  0.000356  0.000390  0.000050  ...  0.000075  0.000185   \n",
       "99-9973      0.000504  0.001925  0.000641  0.000382  ...  0.001081  0.001095   \n",
       "99-9976      0.000586  0.000538  0.000570  0.000781  ...  0.000508  0.000406   \n",
       "99-9988      0.000071  0.000095  0.000063  0.000030  ...  0.000034  0.000176   \n",
       "99-9993      0.000080  0.000125  0.000126  0.000205  ...  0.000099  0.000370   \n",
       "\n",
       "                                                                   \\\n",
       "sub_int_num        53        54        55        56            57   \n",
       "row_id                                                              \n",
       "0-1000       0.000214  0.000003  0.000000  0.000118  2.313288e-04   \n",
       "0-10000      0.000616  0.000564  0.000000  0.000023  3.777703e-08   \n",
       "0-10005      0.000050  0.001761  0.001617  0.001801  2.552987e-03   \n",
       "0-10017      0.001293  0.002092  0.000994  0.000848  3.104404e-03   \n",
       "0-10030      0.000004  0.000215  0.000457  0.000183  4.842470e-04   \n",
       "...               ...       ...       ...       ...           ...   \n",
       "99-9972      0.000314  0.000318  0.000115  0.000143  9.916624e-05   \n",
       "99-9973      0.000425  0.000789  0.001295  0.000596  1.862600e-03   \n",
       "99-9976      0.000662  0.000338  0.000710  0.000179  5.946683e-04   \n",
       "99-9988      0.000140  0.000129  0.000175  0.000019  1.440137e-04   \n",
       "99-9993      0.000929  0.000328  0.000251  0.000204  2.728767e-04   \n",
       "\n",
       "                                               \n",
       "sub_int_num            58        59        60  \n",
       "row_id                                         \n",
       "0-1000       1.060893e-05  0.000111  0.000288  \n",
       "0-10000      3.777703e-08  0.000020  0.000310  \n",
       "0-10005      5.364106e-04  0.000872  0.000000  \n",
       "0-10017      1.224910e-03  0.001316  0.003287  \n",
       "0-10030      0.000000e+00  0.000756  0.000005  \n",
       "...                   ...       ...       ...  \n",
       "99-9972      1.809852e-04  0.000334  0.000089  \n",
       "99-9973      7.668418e-04  0.001035  0.002115  \n",
       "99-9976      1.509652e-04  0.000388  0.000403  \n",
       "99-9988      3.200939e-05  0.000041  0.000007  \n",
       "99-9993      2.108380e-04  0.000126  0.000353  \n",
       "\n",
       "[428932 rows x 60 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RV_ts.pivot(index=\"row_id\",columns=[\"sub_int_num\"],values=[\"sub_int_RV\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "677c1b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target=pd.read_csv(\"../raw_data/kaggle_ORVP/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "252d6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target[\"row_id\"]=df_target[\"stock_id\"].astype(int).astype(str)+\"-\"+df_target[\"time_id\"].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdb28caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0-62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>126</td>\n",
       "      <td>32751</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>126-32751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>126</td>\n",
       "      <td>32753</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>126-32753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>126</td>\n",
       "      <td>32758</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>126-32758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>126</td>\n",
       "      <td>32763</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>126-32763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>126</td>\n",
       "      <td>32767</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>126-32767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stock_id  time_id    target     row_id\n",
       "0              0        5  0.004136        0-5\n",
       "1              0       11  0.001445       0-11\n",
       "2              0       16  0.002168       0-16\n",
       "3              0       31  0.002195       0-31\n",
       "4              0       62  0.001747       0-62\n",
       "...          ...      ...       ...        ...\n",
       "428927       126    32751  0.003461  126-32751\n",
       "428928       126    32753  0.003113  126-32753\n",
       "428929       126    32758  0.004070  126-32758\n",
       "428930       126    32763  0.003357  126-32763\n",
       "428931       126    32767  0.002090  126-32767\n",
       "\n",
       "[428932 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b2a07cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:324: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy.loc[:,\"sub_int_num\"]=np.nan\n",
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:324: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy.loc[:,\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7c432cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([386036, 60])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07885f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([386036, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0056627",
   "metadata": {},
   "source": [
    "Not entirely sure what the error code is about, I am literally doing exactly as suggested by the warning. https://stackoverflow.com/questions/23688307/settingwithcopywarning-even-when-using-loc says this is a false positive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596532d4-3c50-4a8e-bbda-8448b8f02b4d",
   "metadata": {},
   "source": [
    "## Experiment: RNN (with some fine tuning), LSTM, and linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2721fdfa-a2d2-4461-8a99-0fe183fcbfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In fold 0 :\n",
      "\n",
      "Train set end at 8117 .\n",
      "\n",
      "Test set start at 15516 end at 10890 .\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:324: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy.loc[:,\"sub_int_num\"]=np.nan\n",
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:324: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy.loc[:,\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "time_split_list=data_processing.time_cross_val_split(list_time=list_time,n_split=1,percent_val_size=10,list_output=True)\n",
    "train_time_id,test_time_id=time_split_list[0][0],time_split_list[0][1]\n",
    "\n",
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a44c92-9ff1-4909-808f-0a05b6aa2a14",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "00de91c2-12af-4f4b-953c-8fa907c945c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  0.9607927799224854  epoch  1 has training loss  tensor(0.2779, device='cuda:0')  and validation loss  tensor(0.2372, device='cuda:0') .\n",
      "\n",
      "At  5.388619899749756  epoch  5 has training loss  tensor(0.2545, device='cuda:0')  and validation loss  tensor(0.2357, device='cuda:0') .\n",
      "\n",
      "At  10.989859580993652  epoch  10 has training loss  tensor(0.2538, device='cuda:0')  and validation loss  tensor(0.2388, device='cuda:0') .\n",
      "\n",
      "At  16.626850843429565  epoch  15 has training loss  tensor(0.2532, device='cuda:0')  and validation loss  tensor(0.2360, device='cuda:0') .\n",
      "\n",
      "At  22.277040719985962  epoch  20 has training loss  tensor(0.2526, device='cuda:0')  and validation loss  tensor(0.2358, device='cuda:0') .\n",
      "\n",
      "At  27.854429721832275  epoch  25 has training loss  tensor(0.2522, device='cuda:0')  and validation loss  tensor(0.2355, device='cuda:0') .\n",
      "\n",
      "At  33.49538707733154  epoch  30 has training loss  tensor(0.2523, device='cuda:0')  and validation loss  tensor(0.2417, device='cuda:0') .\n",
      "\n",
      "At  39.162482261657715  epoch  35 has training loss  tensor(0.2520, device='cuda:0')  and validation loss  tensor(0.2361, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  10  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 27  with validation loss:  tensor(0.2346, device='cuda:0') .\n",
      " The total number of epoch trained is  37 .\n",
      " Training completed in:  41.33479070663452 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[ 0.3387,  0.0671,  0.3461],\n",
       "                      [ 0.0244,  0.5229,  0.3476],\n",
       "                      [-0.4138,  0.1078, -0.3695],\n",
       "                      [ 0.0591, -0.6271, -0.1062],\n",
       "                      [ 0.0508,  0.4345, -0.3999],\n",
       "                      [ 0.5004,  0.6822,  0.2860],\n",
       "                      [ 0.1769,  0.0406,  0.3269],\n",
       "                      [-0.2615, -0.5461, -0.3511],\n",
       "                      [ 0.2701, -0.2723,  0.1178],\n",
       "                      [ 0.4201,  0.3865, -0.0914],\n",
       "                      [-0.0072,  0.4579,  0.4084],\n",
       "                      [ 0.0131,  0.4992,  0.3043],\n",
       "                      [ 0.4214, -0.3000, -0.0872],\n",
       "                      [ 0.0636, -0.2718,  0.0598],\n",
       "                      [ 0.4330, -0.3874, -0.1801],\n",
       "                      [ 0.4858, -0.1835, -0.4414],\n",
       "                      [-0.3642, -0.1781, -0.0009],\n",
       "                      [-0.4791, -0.5999,  0.0319],\n",
       "                      [ 0.4162,  0.0050,  0.3013],\n",
       "                      [-0.0711, -0.3975,  0.2479],\n",
       "                      [-0.1099, -0.2815,  0.0859],\n",
       "                      [-0.0264, -0.2853,  0.0937],\n",
       "                      [ 0.4985, -0.2094,  0.3078],\n",
       "                      [ 0.0230,  0.1662,  0.1380],\n",
       "                      [-0.3539,  0.0086,  0.0760],\n",
       "                      [-0.3522,  0.6185,  0.4335],\n",
       "                      [-0.0986,  0.5000,  0.1727],\n",
       "                      [-0.0010,  0.0586, -0.2030],\n",
       "                      [-0.4905, -0.4731,  0.0208],\n",
       "                      [ 0.0925, -0.0217,  0.1427],\n",
       "                      [-0.2452, -0.4823, -0.3666],\n",
       "                      [-0.1520, -0.6668, -0.4203]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([ 0.1591, -0.1402, -0.3876,  0.0260,  0.1477, -0.3660,  0.0038,  0.1207,\n",
       "                      -0.2850, -0.5243, -0.0619,  0.0252,  0.3141, -0.1129,  0.0380,  0.0248,\n",
       "                       0.3352,  0.3947, -0.2245, -0.1091, -0.0455,  0.1436, -0.3619, -0.0218,\n",
       "                       0.0771, -0.3338,  0.0750, -0.0331, -0.1958, -0.0049,  0.4623,  0.1255],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[ 0.2701, -0.1238, -0.1215,  ...,  0.1673,  0.1819, -0.1432],\n",
       "                      [-0.1423,  0.0421,  0.0076,  ...,  0.0033, -0.1531,  0.0065],\n",
       "                      [-0.1304, -0.1335,  0.0633,  ...,  0.0901,  0.0605,  0.5394],\n",
       "                      ...,\n",
       "                      [ 0.0731, -0.0054,  0.0664,  ...,  0.0632, -0.1424, -0.1364],\n",
       "                      [ 0.1784, -0.3359,  0.0797,  ...,  0.1456,  0.3271,  0.3365],\n",
       "                      [-0.0476,  0.2370,  0.0056,  ...,  0.0468, -0.0613,  0.1358]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[ 0.1400, -0.2092,  0.0296,  ..., -0.1054,  0.0836, -0.1092],\n",
       "                      [-0.2566, -0.1340,  0.1394,  ..., -0.2476,  0.0270,  0.1540],\n",
       "                      [-0.1122,  0.0431,  0.1384,  ..., -0.3546,  0.4510, -0.0210],\n",
       "                      ...,\n",
       "                      [-0.1217, -0.0957, -0.0603,  ..., -0.2642,  0.1595, -0.1044],\n",
       "                      [ 0.1783, -0.0416,  0.1193,  ...,  0.0720, -0.0663, -0.0280],\n",
       "                      [-0.1576,  0.0879,  0.2386,  ..., -0.3235,  0.0365,  0.2240]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([ 0.2848, -0.1504, -0.1879,  0.0467,  0.0366,  0.1575, -0.1463,  0.2205,\n",
       "                       0.0889,  0.2379,  0.1277,  0.0289, -0.0536,  0.0133,  0.0546,  0.0360,\n",
       "                       0.0519,  0.1475, -0.0629, -0.0212, -0.1351,  0.1421, -0.1432,  0.0732,\n",
       "                      -0.0095, -0.0326,  0.0166, -0.0427,  0.1508,  0.1184, -0.0077, -0.1381],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([ 0.2236,  0.0357, -0.0670, -0.0937, -0.0190,  0.1135, -0.0140, -0.0141,\n",
       "                       0.0482, -0.0038, -0.0795, -0.1753, -0.0855, -0.2246, -0.1620, -0.2002,\n",
       "                       0.0844, -0.1029,  0.0113,  0.0138, -0.0764, -0.1059, -0.2030, -0.0472,\n",
       "                       0.1838, -0.0098, -0.0683, -0.0242,  0.1453,  0.1317,  0.1893, -0.1847],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[ 0.1940,  0.1753,  0.0421, -0.1014, -0.1305,  0.0634, -0.0972, -0.2576,\n",
       "                        0.0436,  0.1167, -0.0310,  0.0679, -0.1613, -0.1553,  0.0010, -0.1111,\n",
       "                       -0.1236,  0.1526, -0.0451,  0.1316,  0.0692, -0.2137, -0.1741, -0.0738,\n",
       "                        0.0451,  0.0924, -0.0951, -0.0496, -0.2140,  0.1595, -0.0281,  0.0973]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([0.2268], device='cuda:0'))])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_model=training.RV_RNN_conv(n_diff=2, rnn_type=\"rnn\",rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=10000).to(device=device)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer=optim.Adam(RNN_model.parameters(),lr=1e-3)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)\n",
    "\n",
    "train_loss=[]\n",
    "val_loss=[]\n",
    "\n",
    "training.reg_training_loop_rmspe(optimizer=optimizer,model=RNN_model,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=100,ot_steps=10,report_interval=5,eps=0,scaler=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fb1f55fb-a478-4bee-bf57-12189db4383a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f08413be950>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.arange(len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b608cb1-05a8-417d-8a2a-8816518de943",
   "metadata": {},
   "source": [
    "LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cf7afa75-8e8c-4318-9c75-4e4029fdc57d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: rnn_act='tanh' is ignored when using rnn_type='lstm'\n",
      "At  1.0817015171051025  epoch  1 has training loss  tensor(0.2584, device='cuda:0')  and validation loss  tensor(0.2387, device='cuda:0') .\n",
      "\n",
      "At  6.087613582611084  epoch  5 has training loss  tensor(0.2501, device='cuda:0')  and validation loss  tensor(0.2335, device='cuda:0') .\n",
      "\n",
      "At  12.317784309387207  epoch  10 has training loss  tensor(0.2467, device='cuda:0')  and validation loss  tensor(0.2317, device='cuda:0') .\n",
      "\n",
      "At  18.553734064102173  epoch  15 has training loss  tensor(0.2459, device='cuda:0')  and validation loss  tensor(0.2358, device='cuda:0') .\n",
      "\n",
      "At  24.699528455734253  epoch  20 has training loss  tensor(0.2463, device='cuda:0')  and validation loss  tensor(0.2327, device='cuda:0') .\n",
      "\n",
      "At  30.842156171798706  epoch  25 has training loss  tensor(0.2446, device='cuda:0')  and validation loss  tensor(0.2308, device='cuda:0') .\n",
      "\n",
      "At  37.18043398857117  epoch  30 has training loss  tensor(0.2439, device='cuda:0')  and validation loss  tensor(0.2336, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  10  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 21  with validation loss:  tensor(0.2305, device='cuda:0') .\n",
      " The total number of epoch trained is  31 .\n",
      " Training completed in:  38.42176413536072 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[-0.0090,  0.3253, -0.0705],\n",
       "                      [ 0.1799,  0.1043, -0.0523],\n",
       "                      [-0.0705,  0.2915,  0.1690],\n",
       "                      [ 0.1008, -0.1441,  0.1200],\n",
       "                      [-0.1357,  0.2765,  0.1536],\n",
       "                      [-0.1016,  0.2093,  0.0718],\n",
       "                      [ 0.2759,  0.0426, -0.0790],\n",
       "                      [-0.0447, -0.1475, -0.0158],\n",
       "                      [-0.1632, -0.3557, -0.3056],\n",
       "                      [-0.1593, -0.0544, -0.1201],\n",
       "                      [ 0.1975, -0.1380, -0.1985],\n",
       "                      [ 0.1388,  0.1556, -0.2084],\n",
       "                      [ 0.0122, -0.3432, -0.0550],\n",
       "                      [ 0.1164,  0.1293, -0.0362],\n",
       "                      [ 0.1991,  0.1413, -0.3497],\n",
       "                      [-0.2964, -0.0654,  0.2493],\n",
       "                      [ 0.2634, -0.0293, -0.0623],\n",
       "                      [ 0.3024, -0.1364, -0.1297],\n",
       "                      [-0.4256, -0.4645, -0.4902],\n",
       "                      [ 0.1080,  0.4053,  0.1022],\n",
       "                      [-0.0432, -0.3247, -0.3837],\n",
       "                      [-0.1473,  0.2214, -0.1119],\n",
       "                      [-0.2291, -0.0917,  0.1091],\n",
       "                      [-0.2071,  0.2784,  0.4110],\n",
       "                      [ 0.1130, -0.3538,  0.0155],\n",
       "                      [ 0.0150,  0.0070,  0.1698],\n",
       "                      [-0.0068, -0.3223, -0.1747],\n",
       "                      [ 0.4297,  0.0564, -0.1277],\n",
       "                      [ 0.3252,  0.1828, -0.2776],\n",
       "                      [ 0.3525,  0.2662, -0.1296],\n",
       "                      [ 0.1889,  0.2912, -0.1865],\n",
       "                      [ 0.3165,  0.6224,  0.0700]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([-0.0052, -0.3189, -0.1061, -0.4924,  0.2705, -0.3110, -0.1106,  0.0865,\n",
       "                       0.0938,  0.6408, -0.4720,  0.1811, -0.0402, -0.0725,  0.0394,  0.3309,\n",
       "                      -0.5082, -0.4818,  0.0945, -0.2450, -0.0723, -0.0125,  0.4503, -0.2711,\n",
       "                      -0.2136,  0.1309,  0.2255, -0.3762, -0.2869,  0.0046,  0.1119, -0.1403],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[ 0.0273, -0.0076,  0.1851,  ..., -0.1128, -0.0401, -0.0298],\n",
       "                      [ 0.0108, -0.0205, -0.0158,  ...,  0.0696,  0.0029,  0.0176],\n",
       "                      [ 0.1132,  0.0236,  0.0015,  ..., -0.1888,  0.0267, -0.1517],\n",
       "                      ...,\n",
       "                      [ 0.0776,  0.2044,  0.1668,  ...,  0.0007,  0.1376,  0.0687],\n",
       "                      [ 0.0985,  0.2617,  0.0012,  ...,  0.0419,  0.1280,  0.0223],\n",
       "                      [ 0.0982,  0.1183,  0.1195,  ..., -0.0640, -0.0891,  0.0785]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[-0.3374,  0.7974,  0.3491,  ...,  0.9436,  0.5279, -0.4573],\n",
       "                      [-0.2151,  0.0098,  0.3339,  ..., -0.1792,  0.0215,  0.3952],\n",
       "                      [ 0.0414,  0.7138,  0.0035,  ...,  0.5260,  0.5836, -0.7194],\n",
       "                      ...,\n",
       "                      [ 0.6491,  0.6377,  0.0542,  ..., -0.0044,  0.1819, -0.0923],\n",
       "                      [ 0.4402,  0.5049, -0.1295,  ...,  0.2027,  0.0316, -0.0976],\n",
       "                      [ 0.9695,  1.2068, -0.1438,  ..., -0.2034,  0.0558, -0.1363]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([-0.6935, -0.8767, -0.2661, -0.2840, -0.1662, -0.3103, -0.3110, -0.2346,\n",
       "                      -0.1882, -0.0797, -0.4331, -0.0518, -0.3914, -0.2881, -0.0462, -0.0429,\n",
       "                      -0.1752, -0.1707, -0.3215, -0.1479, -0.1457, -0.2826, -0.0673, -0.1234,\n",
       "                      -0.2386, -0.0525,  0.1726, -0.0404, -0.1844, -0.2554,  0.0187, -0.3408,\n",
       "                      -0.0129,  0.0175,  0.5558, -0.3192,  0.0030, -0.0729, -0.1093, -0.0074,\n",
       "                       0.0577, -0.1065,  0.3324,  0.4413,  0.7265,  0.0809,  0.0163, -0.0118,\n",
       "                      -0.1205,  0.2037,  0.0952,  0.0355, -0.2877, -0.1050, -0.1126, -0.0228,\n",
       "                      -0.1487,  0.2700,  0.2689,  0.2753,  0.0096, -0.0845,  0.1297, -0.4433,\n",
       "                      -0.1056, -0.3521,  0.0282, -0.0896, -0.0983,  0.0769, -0.1531,  0.1269,\n",
       "                       0.0920, -0.0020, -0.0493,  0.1318, -0.0485,  0.0259, -0.1331,  0.0926,\n",
       "                      -0.1901,  0.1452,  0.1344, -0.0869, -0.1735,  0.1667,  0.1512, -0.0175,\n",
       "                       0.0889,  0.0796, -0.1044,  0.1752,  0.1657, -0.2133,  0.1310, -0.1418,\n",
       "                       0.1183, -0.2412,  0.3653, -0.3295,  0.0775, -0.1643, -0.2112,  0.0142,\n",
       "                       0.0618, -0.0901, -0.3691,  0.1828,  0.1524, -0.4328, -0.0822,  0.0019,\n",
       "                      -0.3810, -0.1631, -0.0115,  0.0865, -0.1210, -0.2983,  0.0064, -0.2245,\n",
       "                      -0.0763,  0.2528, -0.0397, -0.0854,  0.1010, -0.3253, -0.0166, -0.4712],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([-0.5455, -0.6870, -0.4646, -0.1959,  0.0083, -0.1804, -0.2617,  0.0868,\n",
       "                      -0.3194, -0.2571, -0.4457, -0.0548, -0.5148, -0.3561, -0.0523, -0.2450,\n",
       "                      -0.4531, -0.0723, -0.1642, -0.2731, -0.0275, -0.3218,  0.0079, -0.0885,\n",
       "                      -0.1389,  0.1037,  0.3912, -0.0666, -0.0500, -0.2727, -0.2935, -0.4880,\n",
       "                       0.0223,  0.2713,  0.3436, -0.2576,  0.2007, -0.2052,  0.1278,  0.0636,\n",
       "                       0.1891,  0.0916,  0.1216,  0.1781,  0.5185,  0.0332, -0.2700, -0.1264,\n",
       "                      -0.2100,  0.0215, -0.0958,  0.1070, -0.1443, -0.0154, -0.1886, -0.2469,\n",
       "                      -0.0375,  0.1635,  0.1180,  0.2031,  0.0722, -0.0841,  0.0335, -0.2083,\n",
       "                      -0.0593, -0.1457,  0.1679,  0.0474,  0.1282,  0.0331, -0.0130, -0.1762,\n",
       "                      -0.1007,  0.0458, -0.0727,  0.0181, -0.1215,  0.0258, -0.0211,  0.0893,\n",
       "                      -0.1306,  0.1400, -0.0826, -0.0271, -0.0649,  0.1201, -0.1327, -0.0164,\n",
       "                       0.0856,  0.0636,  0.0669,  0.1339,  0.1544, -0.0710,  0.0023,  0.1979,\n",
       "                       0.1735, -0.1392,  0.1318, -0.2530, -0.0328, -0.0953, -0.0785, -0.1323,\n",
       "                      -0.0187, -0.1665, -0.3245,  0.1155, -0.1353, -0.4306, -0.0931,  0.0207,\n",
       "                      -0.3873, -0.2864,  0.0483, -0.1239, -0.2117, -0.0452, -0.1924, -0.0313,\n",
       "                      -0.1550,  0.0937, -0.1002,  0.0219, -0.0271, -0.0578, -0.2707, -0.3362],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[ 0.0737,  0.0998, -0.0053,  0.1741, -0.0747,  0.1395,  0.1766, -0.1791,\n",
       "                       -0.0748,  0.1804,  0.2325, -0.0815, -0.0555,  0.1252, -0.1030, -0.0931,\n",
       "                        0.1622,  0.0702, -0.1219, -0.0885,  0.3155, -0.1733, -0.1149,  0.0027,\n",
       "                       -0.1943,  0.0208,  0.0063, -0.0635, -0.0679,  0.2503,  0.3693, -0.4112]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([0.1290], device='cuda:0'))])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_model=training.RV_RNN_conv(n_diff=2, rnn_type=\"lstm\",rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=10000).to(device=device)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer=optim.Adam(RNN_model.parameters(),lr=1e-3)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)\n",
    "\n",
    "train_loss=[]\n",
    "val_loss=[]\n",
    "\n",
    "training.reg_training_loop_rmspe(optimizer=optimizer,model=RNN_model,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=100,ot_steps=10,report_interval=5,eps=0,scaler=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5aa699c1-a918-4831-9f1b-8697e25bd98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f083c7dd930>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.arange(len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344515ae-1741-4b2e-8716-2725cee570cd",
   "metadata": {},
   "source": [
    "Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "78c69b98-2b5a-4a8a-9998-a0c0951bd7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First build an approximate RV feature\n",
    "path_book=\"../raw_data/kaggle_ORVP/book_train.parquet\"\n",
    "df_rv=data_processing.create_df_RV_by_row_id_parallel(path_book)\n",
    "\n",
    "# Then merge with target dataframe\n",
    "df_rv_target=pd.merge(df_target, df_rv, on=[\"row_id\",\"time_id\",\"stock_id\"])\n",
    "\n",
    "train_dataset_base = df_rv_target.loc[df_rv_target['time_id'].isin(train_time_id), ['RV','target','row_id']].set_index('row_id')\n",
    "test_dataset_base = df_rv_target.loc[df_rv_target['time_id'].isin(test_time_id), ['RV','target','row_id']].set_index('row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b878416c-6f16-4029-9291-a62fb6d1657b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The losses for training and validation data are: 0.3019 and 0.2678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train=train_dataset_base[['RV']]\n",
    "y_train=train_dataset_base['target']\n",
    "\n",
    "X_test=test_dataset_base[['RV']]\n",
    "y_test=test_dataset_base['target']\n",
    "\n",
    "model= LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "training_loss = training.rmspe(model.predict(X_train),y_train)\n",
    "validation_loss = training.rmspe(model.predict(X_test),y_test)\n",
    "\n",
    "print(\"The losses for training and validation data are: {:.4f} and {:.4f}\".format(training_loss, validation_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c408726",
   "metadata": {},
   "source": [
    "## Training with native values, with a 10000 times scaler on input. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc50c5",
   "metadata": {},
   "source": [
    "A key issue with our input timeseries is that all values are extremely close to zero, so a 10000 times scaler can help with expanding them a little. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2efd16ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device=(torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b95e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model=training.RV_RNN_conv(n_diff=4,rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=10000).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3846a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer=optim.Adam(RNN_model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "55dd6fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=256,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=256,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "292fcf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "810267b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  2.841204881668091  epoch  1 has training loss  tensor(0.2701, device='cuda:0')  and validation loss  tensor(0.2366, device='cuda:0') .\n",
      "\n",
      "At  12.692814350128174  epoch  5 has training loss  tensor(0.2536, device='cuda:0')  and validation loss  tensor(0.2370, device='cuda:0') .\n",
      "\n",
      "At  24.804923057556152  epoch  10 has training loss  tensor(0.2527, device='cuda:0')  and validation loss  tensor(0.2350, device='cuda:0') .\n",
      "\n",
      "At  36.860355615615845  epoch  15 has training loss  tensor(0.2519, device='cuda:0')  and validation loss  tensor(0.2352, device='cuda:0') .\n",
      "\n",
      "At  49.09467816352844  epoch  20 has training loss  tensor(0.2518, device='cuda:0')  and validation loss  tensor(0.2364, device='cuda:0') .\n",
      "\n",
      "At  61.199227809906006  epoch  25 has training loss  tensor(0.2510, device='cuda:0')  and validation loss  tensor(0.2349, device='cuda:0') .\n",
      "\n",
      "At  73.4724633693695  epoch  30 has training loss  tensor(0.2506, device='cuda:0')  and validation loss  tensor(0.2344, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  10  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 23  with validation loss:  tensor(0.2343, device='cuda:0') .\n",
      " The total number of epoch trained is  33 .\n",
      " Training completed in:  80.75830578804016 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[-1.3013e-02,  3.8937e-01,  2.7331e-01, -7.7134e-02, -6.5391e-02],\n",
       "                      [-2.4403e-02, -3.2814e-02, -2.7695e-02,  1.0576e-01,  8.8450e-02],\n",
       "                      [ 2.5078e-02,  4.2850e-01,  1.4450e-01, -2.3749e-01, -1.4540e-01],\n",
       "                      [-1.5259e-02,  2.8654e-02, -2.5478e-01, -2.4515e-01, -7.4321e-02],\n",
       "                      [-2.5169e-02, -1.9296e-01, -4.6623e-02, -1.3934e-01,  2.0372e-01],\n",
       "                      [ 1.4997e-03,  3.1609e-01,  4.8015e-01,  3.6515e-01,  1.2458e-01],\n",
       "                      [-3.5017e-01, -3.9541e-01,  1.0655e-01,  1.0083e-01,  3.1811e-02],\n",
       "                      [ 3.9903e-01,  8.1790e-02,  3.0594e-01, -2.8731e-01, -2.2762e-01],\n",
       "                      [ 1.1225e-01,  5.7909e-01,  5.4034e-01, -4.9363e-02, -1.6414e-01],\n",
       "                      [-1.4101e-01, -3.6283e-01, -4.2917e-01, -2.6336e-01, -6.1351e-02],\n",
       "                      [ 2.1715e-01,  5.1638e-01, -1.4776e-01, -1.6922e-01, -1.0258e-01],\n",
       "                      [ 2.6874e-01,  2.5141e-01,  9.6520e-02, -1.4923e-01, -9.9994e-02],\n",
       "                      [-6.7987e-02,  7.4953e-01,  3.8641e-01,  2.3234e-01,  1.4717e-01],\n",
       "                      [ 3.8860e-02, -2.0319e-01, -4.3208e-01, -2.7799e-01, -6.5091e-02],\n",
       "                      [ 5.1128e-01,  6.1839e-01,  1.1226e-01, -1.0994e-01, -6.8997e-02],\n",
       "                      [-3.0949e-05, -2.7831e-02, -9.8439e-02, -5.5426e-02,  1.6215e-01],\n",
       "                      [-3.1145e-01, -6.1889e-01,  1.5116e-01, -1.3925e-03, -2.1665e-02],\n",
       "                      [ 9.4889e-03, -2.3916e-01,  3.0081e-01,  3.9099e-01,  1.0649e-01],\n",
       "                      [-8.7631e-02, -3.7799e-01, -5.4040e-01, -3.2803e-01, -9.8980e-02],\n",
       "                      [-2.5052e-02,  3.5925e-01,  1.3044e-01, -6.9229e-02, -1.0065e-02],\n",
       "                      [ 3.4754e-03, -4.0523e-02,  2.8313e-02,  1.1535e-01,  7.7040e-02],\n",
       "                      [-2.2990e-02, -6.9230e-02, -1.2776e-01, -1.1016e-01, -4.8677e-02],\n",
       "                      [ 2.5398e-01, -1.5076e-01,  9.2794e-02, -1.7250e-01,  1.4736e-02],\n",
       "                      [-3.8122e-02, -3.0778e-01, -4.4675e-01, -1.4981e-01,  8.1686e-02],\n",
       "                      [ 2.6809e-01, -4.9744e-01, -2.6351e-01,  2.3446e-01,  1.2846e-01],\n",
       "                      [ 2.7063e-02,  1.3496e-01, -1.3191e-01, -4.4728e-02,  7.4260e-02],\n",
       "                      [-4.9552e-03, -1.7302e-02, -1.3783e-01, -1.6517e-01, -8.2923e-02],\n",
       "                      [ 1.9944e-04,  8.0016e-02,  4.0945e-02, -1.2355e-01, -9.3174e-02],\n",
       "                      [ 2.1459e-02, -3.3950e-01,  9.8456e-02,  2.0546e-01,  4.4724e-02],\n",
       "                      [ 9.6839e-03,  8.9200e-03,  1.7458e-01,  2.4485e-01,  1.0483e-01],\n",
       "                      [ 1.8363e-01,  5.7163e-01,  6.0951e-01,  2.6567e-01,  1.8908e-02],\n",
       "                      [ 4.2079e-01,  7.3438e-02, -1.3992e-01,  4.8925e-02,  3.1248e-01]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([ 1.2628e-02,  2.6932e-02, -1.4197e-01,  2.5670e-02,  7.9795e-02,\n",
       "                       9.7121e-04,  1.9222e-01, -5.3905e-03,  2.0546e-01,  2.5116e-02,\n",
       "                       3.2769e-02, -5.7999e-02,  3.2334e-02, -5.3210e-02, -8.8886e-02,\n",
       "                       2.0458e-02, -1.4031e-02,  1.3967e-02,  3.6471e-02, -1.0130e-02,\n",
       "                      -4.0863e-05,  3.5490e-02,  1.2664e-02, -5.2900e-02, -9.5596e-02,\n",
       "                      -4.3202e-03,  7.3360e-03,  2.5692e-03, -4.0112e-03, -1.1612e-02,\n",
       "                      -2.5158e-01, -2.1998e-02], device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[ 0.3098, -0.0379, -0.0749,  ...,  0.0092,  0.0700,  0.5764],\n",
       "                      [-0.0177, -0.0479,  0.1101,  ..., -0.0484, -0.0547,  0.0155],\n",
       "                      [ 0.1967,  0.1626,  0.1815,  ..., -0.1098,  0.2899,  0.0953],\n",
       "                      ...,\n",
       "                      [-0.1386, -0.1555,  0.0913,  ..., -0.2777, -0.0866, -0.1767],\n",
       "                      [ 0.0174, -0.2074, -0.0237,  ..., -0.1728,  0.1267,  0.0314],\n",
       "                      [-0.0817,  0.0737, -0.0603,  ..., -0.0139,  0.0928,  0.1602]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[ 0.3250, -0.0508, -0.1123,  ..., -0.5073,  0.0732, -0.1378],\n",
       "                      [ 0.6863,  0.0797,  0.4058,  ..., -0.3456, -0.5240, -0.1203],\n",
       "                      [ 0.1124,  0.2424,  0.0326,  ..., -0.3729, -0.2419,  0.0278],\n",
       "                      ...,\n",
       "                      [ 0.1746, -0.0447,  0.0181,  ..., -0.2048,  0.1816,  0.0188],\n",
       "                      [ 0.1996,  0.6002,  0.1919,  ...,  0.2364,  0.1710, -0.4626],\n",
       "                      [-0.0490, -0.1574, -0.2917,  ..., -0.6026,  0.3585, -0.3754]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([-0.1178, -0.0024, -0.2019,  0.1001,  0.1473, -0.0491, -0.1332, -0.0582,\n",
       "                       0.1112,  0.0852,  0.0917,  0.0846, -0.0644, -0.0925, -0.1094, -0.0322,\n",
       "                      -0.2289, -0.0290,  0.0346, -0.1418,  0.0221,  0.0553,  0.0716,  0.2255,\n",
       "                       0.0076, -0.0589,  0.1047, -0.1326, -0.0157, -0.0875, -0.1506,  0.1891],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([ 3.2828e-02, -2.6533e-01, -6.7540e-02,  5.3128e-02,  1.3619e-01,\n",
       "                       8.7140e-02,  7.9682e-02, -1.9066e-01,  1.1935e-01,  6.2576e-02,\n",
       "                      -1.3442e-01,  1.0371e-02,  7.3204e-02, -1.6927e-01,  4.8571e-02,\n",
       "                      -1.3515e-01, -1.3753e-01,  5.4045e-02, -1.0209e-01, -4.2235e-03,\n",
       "                       1.6207e-01,  6.6100e-02, -1.9344e-01, -7.8733e-02, -4.8117e-02,\n",
       "                       2.7672e-01, -7.6910e-02,  1.7189e-01,  5.6509e-02,  8.6780e-03,\n",
       "                       2.5435e-02, -5.3751e-05], device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[-0.0499, -0.1899,  0.0255, -0.0264,  0.0046, -0.1370,  0.0507, -0.2109,\n",
       "                        0.3328, -0.0019,  0.0520, -0.2140, -0.1467, -0.3020,  0.0137,  0.0473,\n",
       "                        0.0489, -0.1000,  0.2518,  0.1416,  0.0663, -0.1541,  0.0913,  0.3280,\n",
       "                       -0.0199, -0.2331,  0.2933, -0.0358,  0.1127,  0.0526,  0.0145,  0.2203]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([0.1783], device='cuda:0'))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.reg_training_loop_rmspe(optimizer=optimizer,model=RNN_model,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=100,ot_steps=10,report_interval=5,eps=0,scaler=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66a81f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen_conv.frozen_conv.weight False\n",
      "linear_proj_input.weight True\n",
      "linear_proj_input.bias True\n",
      "RNN_layer.weight_ih_l0 True\n",
      "RNN_layer.weight_hh_l0 True\n",
      "RNN_layer.bias_ih_l0 True\n",
      "RNN_layer.bias_hh_l0 True\n",
      "linear_post_rnn.weight True\n",
      "linear_post_rnn.bias True\n"
     ]
    }
   ],
   "source": [
    "for name,param in RNN_model.named_parameters():\n",
    "    print(name,param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e88bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c4ccf4",
   "metadata": {},
   "source": [
    "Above is an example of the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "05ee5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.arange(len(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ebe3da0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff63811f6a0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b72925",
   "metadata": {},
   "source": [
    "## Try to normalize only the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2324a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model_norm_ts=training.RV_RNN_conv(n_diff=4,rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=1).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68516afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_norm_ts=optim.Adam(RNN_model_norm_ts.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae9de7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy.loc[:,\"sub_int_num\"]=np.nan\n",
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy.loc[:,\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV_norm\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV_norm\"],df_ts_feat=df_RV_ts,df_target=df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "509b7bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=256,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=256,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4056c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0a66b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  2.522658109664917  epoch  1 has training loss  tensor(283.0392, device='cuda:0')  and validation loss  tensor(43.5655, device='cuda:0') .\n",
      "\n",
      "At  12.718735694885254  epoch  5 has training loss  tensor(17.9191, device='cuda:0')  and validation loss  tensor(37.9335, device='cuda:0') .\n",
      "\n",
      "At  26.009549140930176  epoch  10 has training loss  tensor(7.6101, device='cuda:0')  and validation loss  tensor(3.5446, device='cuda:0') .\n",
      "\n",
      "At  39.161351442337036  epoch  15 has training loss  tensor(2.6315, device='cuda:0')  and validation loss  tensor(1.4925, device='cuda:0') .\n",
      "\n",
      "At  52.47147059440613  epoch  20 has training loss  tensor(2.2603, device='cuda:0')  and validation loss  tensor(1.0233, device='cuda:0') .\n",
      "\n",
      "At  65.79581642150879  epoch  25 has training loss  tensor(2.3343, device='cuda:0')  and validation loss  tensor(1.7118, device='cuda:0') .\n",
      "\n",
      "At  79.334139585495  epoch  30 has training loss  tensor(2.6137, device='cuda:0')  and validation loss  tensor(1.8254, device='cuda:0') .\n",
      "\n",
      "At  92.26322913169861  epoch  35 has training loss  tensor(2.3198, device='cuda:0')  and validation loss  tensor(3.5959, device='cuda:0') .\n",
      "\n",
      "At  105.20642518997192  epoch  40 has training loss  tensor(2.4839, device='cuda:0')  and validation loss  tensor(1.4842, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  20  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 21  with validation loss:  tensor(0.5534, device='cuda:0') .\n",
      " The total number of epoch trained is  41 .\n",
      " Training completed in:  107.89736342430115 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[-0.0045, -0.0901,  0.1132, -0.2228, -0.1803],\n",
       "                      [-0.1997, -0.3297,  0.1452,  0.3443, -0.0067],\n",
       "                      [-0.0107, -0.2273,  0.4138,  0.0233, -0.1586],\n",
       "                      [-0.0889,  0.3350, -0.1367, -0.1448, -0.4007],\n",
       "                      [ 0.2829, -0.0629,  0.1113, -0.0430,  0.1067],\n",
       "                      [ 0.3070,  0.1270,  0.4153,  0.1222,  0.0056],\n",
       "                      [ 0.1668, -0.4291, -0.0132, -0.2160,  0.2345],\n",
       "                      [ 0.1613, -0.3407,  0.0467,  0.4288,  0.0861],\n",
       "                      [ 0.0653, -0.0928, -0.0263, -0.2540, -0.0603],\n",
       "                      [ 0.0812, -0.2569, -0.0038,  0.1708, -0.1246],\n",
       "                      [ 0.3743,  0.4313, -0.1810, -0.2795,  0.0187],\n",
       "                      [ 0.0401,  0.0395,  0.0658, -0.1657, -0.1592],\n",
       "                      [-0.0402,  0.3869,  0.3598,  0.2136,  0.0075],\n",
       "                      [-0.0650, -0.0289,  0.2271,  0.3552,  0.2315],\n",
       "                      [ 0.3678,  0.1282, -0.2009,  0.3654,  0.2514],\n",
       "                      [-0.0062, -0.3464, -0.3324, -0.0290, -0.0126],\n",
       "                      [-0.0944,  0.2014,  0.1281,  0.3473,  0.0057],\n",
       "                      [ 0.3253, -0.0096, -0.2627,  0.0400,  0.1282],\n",
       "                      [ 0.4956, -0.1440,  0.1999, -0.2800, -0.1951],\n",
       "                      [ 0.0501,  0.2608,  0.1987,  0.1601, -0.1392],\n",
       "                      [-0.0112, -0.1569,  0.1500, -0.0583, -0.1004],\n",
       "                      [ 0.3107,  0.2088, -0.0550,  0.1293,  0.1153],\n",
       "                      [-0.2866,  0.2308, -0.2633, -0.0656,  0.0422],\n",
       "                      [ 0.3230,  0.0646, -0.2153, -0.2714, -0.1071],\n",
       "                      [ 0.2060,  0.1244, -0.3153, -0.2981,  0.5972],\n",
       "                      [-0.1061,  0.0378, -0.1545, -0.4512, -0.2370],\n",
       "                      [ 0.3597, -0.0376,  0.3642, -0.0549, -0.1750],\n",
       "                      [-0.0804, -0.3709,  0.0436, -0.5300,  0.4364],\n",
       "                      [-0.1882, -0.1901, -0.0169,  0.0589, -0.0450],\n",
       "                      [ 0.0748,  0.4169, -0.3247, -0.0675, -0.7775],\n",
       "                      [-0.1283, -0.1630,  0.2123, -0.1098, -0.1756],\n",
       "                      [-0.1097,  0.2151, -0.0023, -0.3765,  0.0132]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([-0.0057, -0.1013, -0.0074,  0.2599,  0.1890,  0.1345, -0.2150,  0.0712,\n",
       "                       0.0300,  0.3206,  0.1795,  0.0153,  0.1227,  0.0018,  0.1638, -0.0037,\n",
       "                       0.1344,  0.2068,  0.2299,  0.0294, -0.0055,  0.1430, -0.1299,  0.1851,\n",
       "                       0.1075, -0.0477,  0.1969,  0.1196, -0.0974,  0.0150, -0.0363, -0.0491],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[ 3.7883e-02, -7.4390e-02,  8.1796e-02,  ...,  1.3746e-02,\n",
       "                       -7.0671e-02,  1.1298e-01],\n",
       "                      [-1.7003e-01, -7.9825e-02,  1.1533e-01,  ..., -3.2246e-02,\n",
       "                        6.0445e-02, -2.1969e-03],\n",
       "                      [-1.2022e-01, -7.2477e-02,  4.6330e-02,  ..., -7.7177e-02,\n",
       "                        1.2686e-01, -1.2398e-01],\n",
       "                      ...,\n",
       "                      [ 1.4775e-01, -1.2599e-01,  4.8405e-02,  ..., -9.3319e-02,\n",
       "                       -1.7944e-02,  1.0043e-01],\n",
       "                      [ 1.9351e-01, -4.2060e-02, -1.4521e-02,  ..., -2.4227e-04,\n",
       "                        5.4732e-02,  5.0702e-02],\n",
       "                      [-1.7626e-01,  1.4203e-01, -7.9240e-02,  ..., -1.5068e-04,\n",
       "                        1.0361e-01, -2.5569e-01]], device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[-0.4502, -0.0572, -0.2031,  ..., -0.1551,  0.0523, -0.1695],\n",
       "                      [-0.0814, -0.4613, -0.1111,  ..., -0.0268, -0.0094, -0.2520],\n",
       "                      [ 0.0196, -0.0430, -0.1224,  ...,  0.3012, -0.0557, -0.1092],\n",
       "                      ...,\n",
       "                      [ 0.0309, -0.0523,  0.3242,  ..., -0.3381, -0.2077,  0.0575],\n",
       "                      [-0.0524,  0.1094,  0.1877,  ...,  0.1321, -0.1839, -0.0140],\n",
       "                      [ 0.0234, -0.1200, -0.0735,  ...,  0.1487,  0.0068, -0.1879]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([-0.0868, -0.1199, -0.0193,  0.0328, -0.0508, -0.1069,  0.0045,  0.0335,\n",
       "                       0.1042,  0.0911, -0.1099,  0.0213,  0.0692, -0.0064, -0.0378,  0.1201,\n",
       "                       0.0012, -0.0127, -0.0158,  0.0450,  0.0414,  0.0459, -0.1204,  0.0210,\n",
       "                       0.1474, -0.0206,  0.0538, -0.1286, -0.0392, -0.0545,  0.0740,  0.0011],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([ 0.0416,  0.0699, -0.0982,  0.0742,  0.0536,  0.1397, -0.1213, -0.0425,\n",
       "                      -0.0891,  0.0819, -0.0114, -0.0097,  0.0637,  0.0775,  0.0467, -0.0504,\n",
       "                      -0.0148, -0.0131,  0.0554, -0.0901,  0.0738,  0.0375,  0.1045,  0.0359,\n",
       "                      -0.1340,  0.0005, -0.0602,  0.0842,  0.0283, -0.0201, -0.0855,  0.0435],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[ 3.1699e-05,  1.8070e-05, -2.9846e-04, -2.0921e-04, -2.3639e-05,\n",
       "                        1.6927e-04,  8.7622e-04, -7.0414e-07,  2.3696e-04,  6.3952e-06,\n",
       "                        1.4242e-04,  6.8951e-06,  1.3125e-03, -6.4379e-05,  4.0132e-05,\n",
       "                        1.1604e-05, -5.0481e-05, -1.5871e-04,  4.1738e-04, -1.9004e-04,\n",
       "                        3.3420e-04,  1.4637e-04, -1.8485e-04,  7.9809e-05, -1.3285e-04,\n",
       "                       -1.1879e-04,  1.7192e-04,  4.4917e-04,  4.9060e-05, -1.2610e-04,\n",
       "                        8.2578e-05,  2.0158e-04]], device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([0.0001], device='cuda:0'))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.reg_training_loop_rmspe(optimizer=optimizer_norm_ts,model=RNN_model_norm_ts,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=200,ot_steps=20,report_interval=5,eps=0,scaler=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d7684d",
   "metadata": {},
   "source": [
    "As a remark, I ran above loop twice, the keep learning to same model after the fact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef1351bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen_conv.frozen_conv.weight False\n",
      "linear_proj_input.weight True\n",
      "linear_proj_input.bias True\n",
      "RNN_layer.weight_ih_l0 True\n",
      "RNN_layer.weight_hh_l0 True\n",
      "RNN_layer.bias_ih_l0 True\n",
      "RNN_layer.bias_hh_l0 True\n",
      "linear_post_rnn.weight True\n",
      "linear_post_rnn.bias True\n"
     ]
    }
   ],
   "source": [
    "for name,param in RNN_model_norm_ts.named_parameters():\n",
    "    print(name,param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2bb082d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1802af02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b022072c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd07d2c3b20>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.arange(len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb605a91",
   "metadata": {},
   "source": [
    "It appears that only normalizing input ts is not a good idea. I should consider normalizing both the input and the target. Plus, in above, I fit transformed on both the training and the test set together, that is technically a data leak. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef78913",
   "metadata": {},
   "source": [
    "## Training with normalization on both input and target "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64325299",
   "metadata": {},
   "source": [
    "I have added normalization functionality to dataset creation function, so not we can create the train and test datasets without dataleaking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c3ffa765",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model_norm_ts=training.RV_RNN_conv(n_diff=4,rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=1).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1190590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_norm_ts=optim.Adam(RNN_model_norm_ts.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2a6245db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:324: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_whole_pv_dna=pd.merge(df_ts_pv,df_tab_pv,on=\"row_id\").dropna(axis=\"rows\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice: sub_int_RV has been normalized.\n",
      "The mean and std of this feature has been stored in feat_norm_dict\n",
      "Notice: target has been normalized.\n",
      "The mean and std of this feature has been stored in feat_norm_dict\n"
     ]
    }
   ],
   "source": [
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target,norm_feature_dict={\"sub_int_RV\":None,\"target\":None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4d97d6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sub_int_RV': (np.float64(0.0004411965933048684),\n",
       "  np.float64(0.0005610956509180131)),\n",
       " 'target': (np.float64(0.0038471398027541486),\n",
       "  np.float64(0.0029489987966883967))}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.feat_norm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8b790b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_norm_feat_dict=copy.deepcopy(train_dataset.feat_norm_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "40163bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.0038471398027541486), np.float64(0.0029489987966883967))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_norm_feat_dict.pop(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "630660e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sub_int_RV': (np.float64(0.0004411965933048684),\n",
       "  np.float64(0.0005610956509180131)),\n",
       " 'target': (np.float64(0.0038471398027541486),\n",
       "  np.float64(0.0029489987966883967))}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.feat_norm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ee121136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sub_int_RV': (np.float64(0.0004411965933048684),\n",
       "  np.float64(0.0005610956509180131))}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_norm_feat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9622afc7",
   "metadata": {},
   "source": [
    "As a reminder, do not apply normalization to target of test set. I am choosing to force the target input features to share the same mean and std as the test dataset's corresponding features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "de12b187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice: sub_int_RV has been normalized.\n",
      "The mean and std of this feature has been stored in feat_norm_dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:324: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_whole_pv_dna=pd.merge(df_ts_pv,df_tab_pv,on=\"row_id\").dropna(axis=\"rows\")\n"
     ]
    }
   ],
   "source": [
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target,norm_feature_dict=test_norm_feat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "0f6a5622",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=256,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=256,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8c799fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8f5ab2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  2.6898677349090576  epoch  1 has training loss  tensor(0.5225, device='cuda:0')  and validation loss  tensor(0.2701, device='cuda:0') .\n",
      "\n",
      "At  13.334021091461182  epoch  5 has training loss  tensor(0.2698, device='cuda:0')  and validation loss  tensor(0.2405, device='cuda:0') .\n",
      "\n",
      "At  27.14174461364746  epoch  10 has training loss  tensor(0.2601, device='cuda:0')  and validation loss  tensor(0.2378, device='cuda:0') .\n",
      "\n",
      "At  40.86601209640503  epoch  15 has training loss  tensor(0.2571, device='cuda:0')  and validation loss  tensor(0.2376, device='cuda:0') .\n",
      "\n",
      "At  54.34972524642944  epoch  20 has training loss  tensor(0.2563, device='cuda:0')  and validation loss  tensor(0.2367, device='cuda:0') .\n",
      "\n",
      "At  68.93456530570984  epoch  25 has training loss  tensor(0.2565, device='cuda:0')  and validation loss  tensor(0.2374, device='cuda:0') .\n",
      "\n",
      "At  82.71377658843994  epoch  30 has training loss  tensor(0.2558, device='cuda:0')  and validation loss  tensor(0.2372, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  20  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 11  with validation loss:  tensor(0.2356, device='cuda:0') .\n",
      " The total number of epoch trained is  31 .\n",
      " Training completed in:  85.40374302864075 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[ 0.2627, -0.2206,  0.5197,  0.2868,  0.2761],\n",
       "                      [ 0.0648, -0.1319, -0.3829, -0.2078, -0.0508],\n",
       "                      [ 0.1711, -0.4481, -0.4151, -0.0360,  0.1213],\n",
       "                      [ 0.3005,  0.7172,  0.1621,  0.3056, -0.3716],\n",
       "                      [ 0.2696, -0.7922, -0.0776,  0.1457, -0.3060],\n",
       "                      [ 0.1616,  0.5800,  0.5489, -0.0974, -0.1805],\n",
       "                      [ 0.2192, -0.6146, -0.5099,  0.1171,  0.0296],\n",
       "                      [ 0.1563, -0.4378,  0.0431,  0.2210, -0.3875],\n",
       "                      [ 0.0191, -0.1619, -0.1135, -0.0143, -0.0737],\n",
       "                      [-0.0346,  0.0979, -0.3353, -0.1638, -0.0153],\n",
       "                      [-0.1278, -0.0767,  0.1895, -0.0360, -0.1317],\n",
       "                      [-0.0106, -0.4260,  0.0853, -0.1074, -0.1160],\n",
       "                      [ 0.2242,  0.0838,  0.2800,  0.1939, -0.0882],\n",
       "                      [-0.0151,  0.2627, -0.0807,  0.1391,  0.1945],\n",
       "                      [-0.1204, -0.4106, -0.0698,  0.4132,  0.2422],\n",
       "                      [ 0.0014, -0.0197, -0.0586, -0.0371, -0.0117],\n",
       "                      [-0.4407, -0.8041,  0.1079, -0.0097, -0.1569],\n",
       "                      [ 0.1369,  0.7717,  0.1749, -0.0880,  0.0141],\n",
       "                      [-0.2244, -0.5144, -0.3802,  0.0841,  0.2931],\n",
       "                      [-0.0177,  0.6688, -0.1303, -0.1975,  0.0780],\n",
       "                      [ 0.3691,  0.3933, -0.0165, -0.0347,  0.0015],\n",
       "                      [-0.1067, -0.0119,  0.0709, -0.2542, -0.3250],\n",
       "                      [ 0.3248, -0.0178,  0.4446, -0.4324, -0.0296],\n",
       "                      [ 0.0640, -0.1950, -0.2156,  0.2956,  0.2932],\n",
       "                      [-0.2894, -0.0806,  0.0479,  0.2667, -0.2006],\n",
       "                      [-0.2902,  0.1691,  0.4975,  0.3598, -0.1383],\n",
       "                      [-0.0593, -0.0494, -0.2019, -0.3801, -0.2338],\n",
       "                      [ 0.3579,  0.4490,  0.4561,  0.2170, -0.0604],\n",
       "                      [-0.0941, -0.1384,  0.0632, -0.3969,  0.0851],\n",
       "                      [-0.0189,  0.0916,  0.2350,  0.3435,  0.1484],\n",
       "                      [-0.0025, -0.3809, -0.4149, -0.0897,  0.0078],\n",
       "                      [-0.1204, -0.6309, -0.4735,  0.0243, -0.2124]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([-0.1184,  0.0286,  0.0943, -0.0719,  0.1210, -0.1309,  0.1087,  0.0460,\n",
       "                       0.0035, -0.0199, -0.0728,  0.0781,  0.1526, -0.0034, -0.0619, -0.0009,\n",
       "                      -0.2076,  0.0470, -0.1594, -0.3214,  0.2005, -0.0664, -0.1967,  0.0397,\n",
       "                      -0.1671, -0.1662, -0.0363, -0.1583,  0.0601, -0.0075, -0.0015,  0.0690],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[-0.0737, -0.0286, -0.0282,  ...,  0.1204,  0.0017, -0.1161],\n",
       "                      [ 0.1474,  0.1602, -0.2286,  ..., -0.0724, -0.0498, -0.1034],\n",
       "                      [ 0.0612,  0.0237,  0.1189,  ...,  0.0276,  0.0360,  0.0412],\n",
       "                      ...,\n",
       "                      [ 0.1249, -0.3130, -0.1970,  ...,  0.0495, -0.1351, -0.1423],\n",
       "                      [-0.0886, -0.0322, -0.1906,  ...,  0.1398, -0.0983,  0.0665],\n",
       "                      [-0.0043,  0.1341,  0.0765,  ...,  0.0741, -0.0293, -0.1369]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[-0.1895, -0.0594, -0.0215,  ..., -0.2617,  0.2027,  0.0856],\n",
       "                      [-0.0672, -0.3342, -0.1581,  ...,  0.1365,  0.1601, -0.0197],\n",
       "                      [ 0.0601, -0.1033, -0.3444,  ...,  0.1922, -0.0840,  0.2269],\n",
       "                      ...,\n",
       "                      [-0.0961, -0.0212, -0.0008,  ..., -0.3447,  0.1249,  0.1260],\n",
       "                      [-0.0278, -0.2637,  0.0896,  ...,  0.0788,  0.6341,  0.0218],\n",
       "                      [-0.0851,  0.0073, -0.2826,  ..., -0.0943,  0.1422, -0.3483]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([ 0.1257,  0.1285,  0.0056,  0.0072,  0.0981, -0.0419, -0.0503, -0.0593,\n",
       "                      -0.0561, -0.1627, -0.0562, -0.0970,  0.0416,  0.1311,  0.1716, -0.0104,\n",
       "                       0.0958, -0.0908, -0.0258, -0.0615, -0.0663,  0.1170,  0.1220,  0.0765,\n",
       "                      -0.0244, -0.0866,  0.0323,  0.0243, -0.0364, -0.0223, -0.1194,  0.0786],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([-0.1000,  0.0082, -0.1038,  0.0070, -0.0460, -0.0015, -0.0904, -0.0403,\n",
       "                       0.0361, -0.0229,  0.0154,  0.0835, -0.0775,  0.1120, -0.1352,  0.0151,\n",
       "                      -0.0686, -0.0858, -0.0893,  0.0849, -0.0679, -0.1626, -0.1585, -0.0967,\n",
       "                       0.0153,  0.0543,  0.0920, -0.0517,  0.0156, -0.0064,  0.0820, -0.0590],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[-0.0074,  0.0067,  0.0007, -0.0105, -0.0001,  0.0014,  0.0036,  0.0019,\n",
       "                       -0.0045,  0.0272,  0.0021, -0.0205, -0.0012, -0.0250, -0.0017, -0.0031,\n",
       "                       -0.0158,  0.0583, -0.0011,  0.0134, -0.0030, -0.0029, -0.0053,  0.0043,\n",
       "                       -0.0129,  0.0281, -0.0078,  0.0022,  0.0098, -0.0047, -0.0021, -0.0034]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([0.0122], device='cuda:0'))])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.reg_training_loop_rmspe(optimizer=optimizer_norm_ts,model=RNN_model_norm_ts,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=200,ot_steps=20,report_interval=5,eps=0,scaler=1,norm_train_target=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea81cbbb",
   "metadata": {},
   "source": [
    "Oh this over trained quickly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0703dbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen_conv.frozen_conv.weight False\n",
      "linear_proj_input.weight True\n",
      "linear_proj_input.bias True\n",
      "RNN_layer.weight_ih_l0 True\n",
      "RNN_layer.weight_hh_l0 True\n",
      "RNN_layer.bias_ih_l0 True\n",
      "RNN_layer.bias_hh_l0 True\n",
      "linear_post_rnn.weight True\n",
      "linear_post_rnn.bias True\n"
     ]
    }
   ],
   "source": [
    "for name,param in RNN_model_norm_ts.named_parameters():\n",
    "    print(name,param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "20ecaf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b859c9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff63819d960>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAALgdJREFUeJzt3X9wFGWC//HPJJoEEBLcSH6QkQTw4Osp5Ewklz1RXLImlqew0SpYrSXmPKz1V8llXVfcFRZ1Ky57ZUVXTu68Zf21Aqcb8W5rj927LOH0LsKJUrieUkIFCZKEH3fJQJSwzjzfP2YzMiQh09NJ+pnJ+1XVFdLTT/fTT3roz3T384zPGGMEAABgsRSvKwAAADAUAgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHrneV2B4RAKhXT48GFNnDhRPp/P6+oAAIAYGGN04sQJ5efnKyXl3NdQkiKwHD58WH6/3+tqAACAOLS1tamgoOCcyyRFYJk4caKk8A5PmjTJ49oAAIBYBAIB+f3+yHn8XJIisPTdBpo0aRKBBQCABBPL4xw8dAsAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWC8pBo4bKcGg9OabUnu7lJcnzZ8vpaZ6XSsAAMYeAssgGhul+++XDh36cl5BgfTUU1J1tXf1AgBgLOKW0AAaG6VbbokOK5L06afh+Y2N3tQLAICxisBylmAwfGXFmP6v9c1bsSK8HAAAGB0ElrO8+Wb/KytnMkZqawsvBwAARgeB5Szt7cO7HAAAcI/Acpa8vOFdDgAAuEdgOcv8+eHeQD7fwK/7fJLfH14OAACMDgLLWVJTw12Xpf6hpe/3hgbGYwEAYDQRWAZQXS299po0dWr0/IKC8HzGYQEAYHQxcNwgqqulRYsY6RYAABsQWM4hNVVasMDrWgAAAG4JAQAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANaLK7CsW7dOhYWFysjIUFlZmXbu3Dnoss8//7x8Pl/UlJGREbWMMUarVq1SXl6exo0bp4qKCn388cfxVA0AACQhx4Fl8+bNqqur0+rVq/Xuu+9q7ty5qqys1JEjRwYtM2nSJLW3t0emTz75JOr1tWvX6umnn9b69eu1Y8cOTZgwQZWVlTp16pTzPQIAAEnHcWB58skntXz5ctXW1urSSy/V+vXrNX78eG3YsGHQMj6fT7m5uZEpJycn8poxRg0NDfrBD36gRYsWac6cOXrxxRd1+PBhbdmyJa6dAgAAycVRYDl9+rR27dqlioqKL1eQkqKKigq1tLQMWu7kyZOaNm2a/H6/Fi1apA8++CDyWmtrqzo6OqLWmZmZqbKyskHX2dvbq0AgEDUBAIDk5SiwHDt2TMFgMOoKiSTl5OSoo6NjwDKzZs3Shg0b9MYbb+jll19WKBTSV7/6VR06dEiSIuWcrLO+vl6ZmZmRye/3O9kNAACQYEa8l1B5ebmWLVum4uJiXXPNNWpsbNRFF12kv//7v497nStXrlR3d3dkamtrG8YaAwAA2zgKLNnZ2UpNTVVnZ2fU/M7OTuXm5sa0jvPPP19/9md/pn379klSpJyTdaanp2vSpElREwAASF6OAktaWppKSkrU1NQUmRcKhdTU1KTy8vKY1hEMBvX+++8rLy9PklRUVKTc3NyodQYCAe3YsSPmdQIAgOR2ntMCdXV1qqmpUWlpqebNm6eGhgb19PSotrZWkrRs2TJNnTpV9fX1kqRHH31Uf/7nf66ZM2eqq6tLP/nJT/TJJ5/or//6ryWFexCtWLFCjz/+uC655BIVFRXpkUceUX5+vhYvXjx8ewoAABKW48CyZMkSHT16VKtWrVJHR4eKi4u1devWyEOzBw8eVErKlxdu/u///k/Lly9XR0eHJk+erJKSEv3Xf/2XLr300sgyDz74oHp6enTnnXeqq6tLV111lbZu3dpvgDkAADA2+YwxxutKuBUIBJSZmanu7m6eZwEAIEE4OX/zXUIAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrxRVY1q1bp8LCQmVkZKisrEw7d+6MqdymTZvk8/m0ePHiqPm33367fD5f1FRVVRVP1QAAQBJyHFg2b96suro6rV69Wu+++67mzp2ryspKHTly5JzlDhw4oAceeEDz588f8PWqqiq1t7dHpo0bNzqtGgAASFKOA8uTTz6p5cuXq7a2VpdeeqnWr1+v8ePHa8OGDYOWCQaDuu2227RmzRpNnz59wGXS09OVm5sbmSZPnuy0agAAIEk5CiynT5/Wrl27VFFR8eUKUlJUUVGhlpaWQcs9+uijmjJliu64445Bl2lubtaUKVM0a9Ys3XXXXTp+/Pigy/b29ioQCERNAAAgeTkKLMeOHVMwGFROTk7U/JycHHV0dAxY5q233tLPfvYzPffcc4Out6qqSi+++KKampr04x//WNu3b9f111+vYDA44PL19fXKzMyMTH6/38luAACABHPeSK78xIkT+ta3vqXnnntO2dnZgy63dOnSyL8vv/xyzZkzRzNmzFBzc7MWLlzYb/mVK1eqrq4u8nsgECC0AACQxBwFluzsbKWmpqqzszNqfmdnp3Jzc/stv3//fh04cEA33nhjZF4oFApv+LzztHfvXs2YMaNfuenTpys7O1v79u0bMLCkp6crPT3dSdUBAEACc3RLKC0tTSUlJWpqaorMC4VCampqUnl5eb/lZ8+erffff1+7d++OTDfddJOuvfZa7d69e9CrIocOHdLx48eVl5fncHcAAEAycnxLqK6uTjU1NSotLdW8efPU0NCgnp4e1dbWSpKWLVumqVOnqr6+XhkZGbrsssuiymdlZUlSZP7Jkye1Zs0a3XzzzcrNzdX+/fv14IMPaubMmaqsrHS5ewAAIBk4DixLlizR0aNHtWrVKnV0dKi4uFhbt26NPIh78OBBpaTEfuEmNTVVe/bs0QsvvKCuri7l5+fruuuu02OPPcZtHwAAIEnyGWOM15VwKxAIKDMzU93d3Zo0aZLX1QEAADFwcv7mu4QAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrxRVY1q1bp8LCQmVkZKisrEw7d+6MqdymTZvk8/m0ePHiqPnGGK1atUp5eXkaN26cKioq9PHHH8dTNQAAkIQcB5bNmzerrq5Oq1ev1rvvvqu5c+eqsrJSR44cOWe5AwcO6IEHHtD8+fP7vbZ27Vo9/fTTWr9+vXbs2KEJEyaosrJSp06dclo9AACQhBwHlieffFLLly9XbW2tLr30Uq1fv17jx4/Xhg0bBi0TDAZ12223ac2aNZo+fXrUa8YYNTQ06Ac/+IEWLVqkOXPm6MUXX9Thw4e1ZcsWxzsEAACSj6PAcvr0ae3atUsVFRVfriAlRRUVFWppaRm03KOPPqopU6bojjvu6Pdaa2urOjo6otaZmZmpsrKyQdfZ29urQCAQNQEAgOTlKLAcO3ZMwWBQOTk5UfNzcnLU0dExYJm33npLP/vZz/Tcc88N+HpfOSfrrK+vV2ZmZmTy+/1OdgMAACSYEe0ldOLECX3rW9/Sc889p+zs7GFb78qVK9Xd3R2Z2trahm3dAADAPuc5WTg7O1upqanq7OyMmt/Z2anc3Nx+y+/fv18HDhzQjTfeGJkXCoXCGz7vPO3duzdSrrOzU3l5eVHrLC4uHrAe6enpSk9Pd1J1AACQwBxdYUlLS1NJSYmampoi80KhkJqamlReXt5v+dmzZ+v999/X7t27I9NNN92ka6+9Vrt375bf71dRUZFyc3Oj1hkIBLRjx44B1wkAAMYeR1dYJKmurk41NTUqLS3VvHnz1NDQoJ6eHtXW1kqSli1bpqlTp6q+vl4ZGRm67LLLospnZWVJUtT8FStW6PHHH9cll1yioqIiPfLII8rPz+83XgsAABibHAeWJUuW6OjRo1q1apU6OjpUXFysrVu3Rh6aPXjwoFJSnD0a8+CDD6qnp0d33nmnurq6dNVVV2nr1q3KyMhwWj0AAJCEfMYY43Ul3AoEAsrMzFR3d7cmTZrkdXUAAEAMnJy/+S4hAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9eIKLOvWrVNhYaEyMjJUVlamnTt3DrpsY2OjSktLlZWVpQkTJqi4uFgvvfRS1DK33367fD5f1FRVVRVP1QAAQBI6z2mBzZs3q66uTuvXr1dZWZkaGhpUWVmpvXv3asqUKf2Wv/DCC/X9739fs2fPVlpamn71q1+ptrZWU6ZMUWVlZWS5qqoq/fznP4/8np6eHucuAQCAZOMzxhgnBcrKynTllVfqmWeekSSFQiH5/X7dd999euihh2JaxxVXXKEbbrhBjz32mKTwFZauri5t2bLFWe3/KBAIKDMzU93d3Zo0aVJc6wAAAKPLyfnb0S2h06dPa9euXaqoqPhyBSkpqqioUEtLy5DljTFqamrS3r17dfXVV0e91tzcrClTpmjWrFm66667dPz48UHX09vbq0AgEDUBAIDk5eiW0LFjxxQMBpWTkxM1PycnRx999NGg5bq7uzV16lT19vYqNTVVf/d3f6evf/3rkderqqpUXV2toqIi7d+/Xw8//LCuv/56tbS0KDU1td/66uvrtWbNGidVBwAACczxMyzxmDhxonbv3q2TJ0+qqalJdXV1mj59uhYsWCBJWrp0aWTZyy+/XHPmzNGMGTPU3NyshQsX9lvfypUrVVdXF/k9EAjI7/eP+H4AAABvOAos2dnZSk1NVWdnZ9T8zs5O5ebmDlouJSVFM2fOlCQVFxfrww8/VH19fSSwnG369OnKzs7Wvn37Bgws6enpPJQLAMAY4ugZlrS0NJWUlKipqSkyLxQKqampSeXl5TGvJxQKqbe3d9DXDx06pOPHjysvL89J9QAAQJJyfEuorq5ONTU1Ki0t1bx589TQ0KCenh7V1tZKkpYtW6apU6eqvr5eUvh5k9LSUs2YMUO9vb369a9/rZdeeknPPvusJOnkyZNas2aNbr75ZuXm5mr//v168MEHNXPmzKhuzwAAYOxyHFiWLFmio0ePatWqVero6FBxcbG2bt0aeRD34MGDSkn58sJNT0+P7r77bh06dEjjxo3T7Nmz9fLLL2vJkiWSpNTUVO3Zs0cvvPCCurq6lJ+fr+uuu06PPfYYt30AAICkOMZhsRHjsAAAkHhGbBwWAAAALxBYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAegQWAABgPQILAACwHoEFAABYj8ACAACsR2ABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPUILAAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1osrsKxbt06FhYXKyMhQWVmZdu7cOeiyjY2NKi0tVVZWliZMmKDi4mK99NJLUcsYY7Rq1Srl5eVp3Lhxqqio0McffxxP1QAAQBJyHFg2b96suro6rV69Wu+++67mzp2ryspKHTlyZMDlL7zwQn3/+99XS0uL9uzZo9raWtXW1uo3v/lNZJm1a9fq6aef1vr167Vjxw5NmDBBlZWVOnXqVPx7BgAAkobPGGOcFCgrK9OVV16pZ555RpIUCoXk9/t133336aGHHoppHVdccYVuuOEGPfbYYzLGKD8/X9/5znf0wAMPSJK6u7uVk5Oj559/XkuXLh1yfYFAQJmZmeru7takSZOc7A4AAPCIk/O3oyssp0+f1q5du1RRUfHlClJSVFFRoZaWliHLG2PU1NSkvXv36uqrr5Yktba2qqOjI2qdmZmZKisrG3Sdvb29CgQCURMAAEhejgLLsWPHFAwGlZOTEzU/JydHHR0dg5br7u7WBRdcoLS0NN1www366U9/qq9//euSFCnnZJ319fXKzMyMTH6/38luAACABDMqvYQmTpyo3bt367//+7/1ox/9SHV1dWpubo57fStXrlR3d3dkamtrG77KAgAA65znZOHs7Gylpqaqs7Mzan5nZ6dyc3MHLZeSkqKZM2dKkoqLi/Xhhx+qvr5eCxYsiJTr7OxUXl5e1DqLi4sHXF96errS09OdVB0AACQwR1dY0tLSVFJSoqampsi8UCikpqYmlZeXx7yeUCik3t5eSVJRUZFyc3Oj1hkIBLRjxw5H67RNMCg1N0sbN4Z/BoNe1wgAgMTl6AqLJNXV1ammpkalpaWaN2+eGhoa1NPTo9raWknSsmXLNHXqVNXX10sKP29SWlqqGTNmqLe3V7/+9a/10ksv6dlnn5Uk+Xw+rVixQo8//rguueQSFRUV6ZFHHlF+fr4WL148fHs6ihobpfvvlw4d+nJeQYH01FNSdbV39QIAIFE5DixLlizR0aNHtWrVKnV0dKi4uFhbt26NPDR78OBBpaR8eeGmp6dHd999tw4dOqRx48Zp9uzZevnll7VkyZLIMg8++KB6enp05513qqurS1dddZW2bt2qjIyMYdjF0dXYKN1yi3R2Z/FPPw3Pf+01QgsAAE45HofFRraMwxIMSoWF0VdWzuTzha+0tLZKqamjWjUAAKwzYuOw4NzefHPwsCKFr7q0tYWXAwAAsSOwDKP29uFdDgAAhBFYhtEZvbKHZTkAABBGYBlG8+eHn1Hx+QZ+3eeT/P7wcgAAIHYElmGUmhruuiz1Dy19vzc08MAtAABOEViGWXV1uOvy1KnR8wsK6NIMAEC8HI/DgqFVV0uLFoV7A7W3h59ZmT+fKysAAMSLwDJCUlOlBQu8rgUAAMmBW0IAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHLyELBYN0iQYA4EwEFss0Nkr33x/9rc8FBeERdBl0DgAwVnFLyCKNjdItt0SHFUn69NPw/MZGb+oFAIDXCCyWCAbDV1aM6f9a37wVK8LLAQAw1hBYLPHmm/2vrJzJGKmtLbwcAABjDYHFEu3tw7scAADJhMBiiby84V0OAIBkQmCxxPz54d5APt/Ar/t8kt8fXg4AgLGGwGKJ1NRw12Wpf2jp+72hgfFYAABjE4HFItXV0muvSVOnRs8vKAjPj2UclmBQam6WNm4M/6RXEQAgGTBw3LmEgtLRN6XP26VxedJF86WUkb3EUV0tLVoU30i3bgedY4RdAICtfMYMNPJHYgkEAsrMzFR3d7cmTZo0PCtta5R23S99dsbZf3yBVPKU5LdvyNm+QefO/mv23U4a6goNI+wCAEabk/M3gWUgbY3Sm7dIOrtp/nj2n/+aVaElGJQKCwcfx8XnC4eP1taBr5i4DTsAAMTDyfmbZ1jOFgqGr6z0Cyv6ct6uFeHlLOFm0DlG2AUAJAICy9mOvhl9G6gfI33WFl7OEm4GnWOEXQBAIuCh27N9HuPZP9blRoGbQeeGa4RdHtgFAIwkrrCcbVyMZ/9YlxsFbgadG44Rdhsbw8/QXHutdOut4Z+FhXy7NABg+BBYznbR/HBvIA1y9pdPGu8PL2cJN4POuR1ht++B3bNvK336aXh+LKGFsWMAAEMhsJwtJTXcdVlS/9Dyx99LGkZ8PBan4h10zk3YGY4Hdrk6AwCIBd2aBzPgOCz+cFixqEvz2eJ9lmSgcVj8/nBYGSzsNDeHA8ZQtm2TFiwYeJtuu1Pz7AwAJC7GYRkuHox06yWnJ/+NG8NXRYbyyivSN7/Zf1tuxo6RGOwOABKdk/M3vYTOJSVVylngdS1GTWrqwFdCBuPmgV0n3amdXJ3pe3aGwe4AILnwDAvi5uaBXTfdqYdrsDs3D/vyoDAAjC4CC+Lm5oHd0bo6Mxg3D/vyoDAAjD4CC1yJt3eSV1dnJHddsb3uxs2VHQBjFQ/dYljE01un7+QvRd/eGaqXkJveSW4e9vX6QWG3Dxm76VE11sq6Qc81IHaOzt8mCXR3dxtJpru72+uqwKFf/tKYggJjwpElPPn94fmD+eKLcBmfL7pc3+TzhdfxxRf9y27bNnCZs6dt24a3bN++DlRnny88nWuf3ZTtK392OxcUDF1uLJY1JnzsbNtmzCuvhH8OdCzZtF23Zb3cNmVjL5uMnJy/CSzwXDxv4L4T+Nkn8aFO4K+8ElvoeOWV4S3bF7IGK3OukOWm7JltNdpBKRHL9pWPJ3Qkaqj0ctuUTYxAO5Ihi8CCMSGeqzNeXWHxqqxXQSkRyxoTf+hI1FDp5bYp6/zvlIghaygEFowZTpO/m9tJbsp6dWUnEUNWIoa7RAyVXm6bss7+TokasmLh5PxNL6GREgpKnc3SgY3hnyG6c4yEvsHuvvnN8M+hHm500xXbq27cbsq66VE11sq66S7v1XbddvH3atuUjb2sm3GnvCo7UggsI6GtUfrnQqnpWum/bg3//OfC8Hx4Lt6u2G7KuunG7aasV0EpEcu6CR2JGCq93DZlYy97ZthJ8QV1zf9r1tLyjbrm/zUrxRe0MmSNFIbmH25tjdKbt0g6K5Z+9ml4/vzXrP7yxLGiulpatCi+7qfxlO27OnPLLeGAceanlliv7MRTti/sfPrpwJ+U+rpinysojZWybkKHV9t1U9bLbVM29rJ9IeYbpY16atn98n/lyxTRdrxA97/4lF5/p9qqkDVi3N+B8p41z7AEvzDm9QJjfqFBJp8xr/vDy2FMiudBYbdl4+1RNdbKunlGyavtuq2zV9umbOxlt20z5hulvzTBl30m+HL0OSX4ks8EX/aZb5T+0qrnwZwY8Ydun3nmGTNt2jSTnp5u5s2bZ3bs2DHosv/wD/9grrrqKpOVlWWysrLMwoUL+y1fU1NjFL4kEZkqKytjro81gaVj2znCyhlTxzZv6wlPedG90IuglIhl3QQlr7Y7HHVOpGA51sp+cfoL8+m6gn5h5czQcmid33xxuv9/Bl6G4ViNaGDZtGmTSUtLMxs2bDAffPCBWb58ucnKyjKdnZ0DLn/rrbeadevWmffee898+OGH5vbbbzeZmZnm0KFDkWVqampMVVWVaW9vj0z/+7//G3OdrAksra/EFlhaB+jOAYywRBzDIdHCnVfbdVvnRAuWY6qsyw/CXobhWDg5f/uMMcbJLaSysjJdeeWVeuaZZyRJoVBIfr9f9913nx566KEhyweDQU2ePFnPPPOMli1bJkm6/fbb1dXVpS1btjipSoQ1Q/N3NocfsB3Kwm1SzoKRrg2AOCXisP5u65yIX6EwJsoe2BjuvDGUr74iFX5zwJcG+loPvz/87Fs8XwkSa9lYODl/Owosp0+f1vjx4/Xaa69p8eLFkfk1NTXq6urSG2+8MeQ6Tpw4oSlTpujVV1/VX/7lX0oKB5YtW7YoLS1NkydP1te+9jU9/vjj+spXvhJTvawJLKFguDfQZ59KZz90K0nySeMLpJtapRS+XAQAMIRh+iBs6/dyOTl/O+oldOzYMQWDQeXk5ETNz8nJ0UcffRTTOr73ve8pPz9fFRUVkXlVVVWqrq5WUVGR9u/fr4cffljXX3+9WlpalDpAq/T29qq3tzfyeyAQcLIbIyclVSp56o+9hHyKDi1/7M5R0jB0WAkFpaNvSp+3S+PypIvmJ3fAGWv7CwCxumh++IPuUB+ELxqgC9oZ+sasioebssNpVLs1P/HEE9q0aZOam5uVkZERmb906dLIvy+//HLNmTNHM2bMUHNzsxYuXNhvPfX19VqzZs2o1Nkxf3W46/Ku+6XPzriGNr4gHFaG6tLc1jhI2aeSszv0WNtfAHBiuD4IJwFHA8dlZ2crNTVVnZ2dUfM7OzuVm5t7zrJ/+7d/qyeeeEK//e1vNWfOnHMuO336dGVnZ2vfvn0Dvr5y5Up1d3dHpra2Nie7MfL81dJNB8KX6L76SvjnTa2xhZU3b4k+eUtfjuGSbAPPjbX9BYB49H0QHn/WiJXjC8bU2F6OrrCkpaWppKRETU1NkWdYQqGQmpqadO+99w5abu3atfrRj36k3/zmNyotLR1yO4cOHdLx48eVN8hoO+np6UpPT3dS9dGXkurswdpQMHylYcBLfkaST9q1Qpq6KDmS9FjbXwBww18d/v9wDN8+dzw0f11dnZ577jm98MIL+vDDD3XXXXepp6dHtbW1kqRly5Zp5cqVkeV//OMf65FHHtGGDRtUWFiojo4OdXR06OTJk5KkkydP6rvf/a7efvttHThwQE1NTVq0aJFmzpypysrKYdrNBHD0zf5XGqIY6bO28HLJYKztLwC41fdBuPCb4Z9jKKxIcTzDsmTJEh09elSrVq1SR0eHiouLtXXr1siDuAcPHlRKypc56Nlnn9Xp06d1yy23RK1n9erV+uEPf6jU1FTt2bNHL7zwgrq6upSfn6/rrrtOjz32mP1XUYbT5zGObxzrcrYba/sLAHDF8TgsNrKmW7MbY20Ml7G2vxh99D7DuXB8WGHEujVjBA1T1zVXRvMNbMP+InnR+wznwvGRkAgstvC665rbN7DTsMOYNaNvrLSV19+YPlbaebiMdnt5fXwgbtwSss2AwcEf2xgubrY50Bu4LzgM9QZ2E3bc7C+fkmI3VtoqMtr0YA90j/Bo02OlnYfLaLeX18cH+hmxofltlVSBRRrdTxxu38Buw05fHZzu73Bs141E+hTt1d9oOMo65eWzUV4fk4nGi+NyuI6PRHr/W45nWBKd0zFczuT0jeSke/HZdRqusVS8GrMm3v90EulT9HC01bBfQRvBW41e9T7z+ph0W3a0t+3VcTkcx0civf/PlAQhi8CSTEb7Dewm7LgxHNuN9z+d4bj/PZonBrdt5WZ/3bZVPH+jcQMPNul4udFuZ8nbYDja2/bquHR7fHj9/o/XaH9wGCGOB46DpeId5t7NG9irT7NutxtvWw35qVDhT4Wh4OB1amsM34Jrujb8lfFN14Z/j+VrCOIp66at3Oyv27aK92/U1/us77ZCP77wM1Ln6n022u3ct814v6bC7VdceLFtr45LN8eH1+//eA3H8THadR4EgSUZePUGHq5Ps0652a6btnI7Oq8XJwY3beVmf92UdfM36ut9Jqn/MR1D7zMv2tnLYOjVtr06Lt0cH16+/+Pl1QeHEUJgSQZevYGH49NsPNxs101bJeLVCjdt5WZ/R+tW40Di/aI4r9rZq2Do5ba9Oi6l+I8Pr97/bnj1wWGEEFiSgVdvYLefZuPlZrtu2ioRr1a4aSs3++v1rcZ4vjHdq3b2Khh6uW2vjss+8RwfXr3/3fDyg8MIILAkA6/ewH3lvPja83i366atEvFqhRR/W7nZXxtuNTr9ojiv2tmrYOj1tr04Ls/k9Pjw8qpQvLz+4DDM6CWUDIZrmPt4u1N79bXn8WzXTVu5GZ3XyxODFF9budlfN2W9+toGr9rZzf66bSsvty2N/nHphlfvfzfc/I28qvM5cIUlGXh1a+bsOnjxtedOt+u2rRLtasWZ4vkbubmClmi3Gr1qZzf767atvNz2mesZzePSDa+vCjmViM8ongMj3SYTL4b1T1Ru28rV6LzSgJ/OYhrTJI6yw8GLAc08/ZoKadTbedi/psJBW3m5bTe8Gh9ktN//bsX7NxqFOjM0/1hmyQA/CcGaAZwS4MTglUT7G7k1Vka6HasS8dga4ToTWACbcWKwH+2MkZKIx9YI1pnAAgAArOfk/M1DtwAAwHoEFgAAYD0CCwAAsB6BBQAAWI/AAgAArEdgAQAA1iOwAAAA6xFYAACA9QgsAADAeud5XYHh0DdYbyAQ8LgmAAAgVn3n7VgG3U+KwHLixAlJkt/v97gmAADAqRMnTigzM/OcyyTFdwmFQiEdPnxYEydOlM/n6/d6IBCQ3+9XW1sb3zU0BNoqdrRV7Gir2NFWztBesbOxrYwxOnHihPLz85WScu6nVJLiCktKSooKCgqGXG7SpEnW/JFsR1vFjraKHW0VO9rKGdordra11VBXVvrw0C0AALAegQUAAFhvTASW9PR0rV69Wunp6V5XxXq0Vexoq9jRVrGjrZyhvWKX6G2VFA/dAgCA5DYmrrAAAIDERmABAADWI7AAAADrEVgAAID1kj6wrFu3ToWFhcrIyFBZWZl27tzpdZWs9MMf/lA+ny9qmj17ttfVssJ//Md/6MYbb1R+fr58Pp+2bNkS9boxRqtWrVJeXp7GjRuniooKffzxx95U1mNDtdXtt9/e7zirqqryprIeq6+v15VXXqmJEydqypQpWrx4sfbu3Ru1zKlTp3TPPffoK1/5ii644ALdfPPN6uzs9KjG3omlrRYsWNDv2Pr2t7/tUY298+yzz2rOnDmRweHKy8v1r//6r5HXE/mYSurAsnnzZtXV1Wn16tV69913NXfuXFVWVurIkSNeV81Kf/qnf6r29vbI9NZbb3ldJSv09PRo7ty5Wrdu3YCvr127Vk8//bTWr1+vHTt2aMKECaqsrNSpU6dGuabeG6qtJKmqqirqONu4ceMo1tAe27dv1z333KO3335b//Zv/6Y//OEPuu6669TT0xNZ5m/+5m/0L//yL3r11Ve1fft2HT58WNXV1R7W2huxtJUkLV++POrYWrt2rUc19k5BQYGeeOIJ7dq1S++8846+9rWvadGiRfrggw8kJfgxZZLYvHnzzD333BP5PRgMmvz8fFNfX+9hrey0evVqM3fuXK+rYT1J5vXXX4/8HgqFTG5urvnJT34SmdfV1WXS09PNxo0bPaihPc5uK2OMqampMYsWLfKkPrY7cuSIkWS2b99ujAkfR+eff7559dVXI8t8+OGHRpJpaWnxqppWOLutjDHmmmuuMffff793lbLY5MmTzT/+4z8m/DGVtFdYTp8+rV27dqmioiIyLyUlRRUVFWppafGwZvb6+OOPlZ+fr+nTp+u2227TwYMHva6S9VpbW9XR0RF1nGVmZqqsrIzjbBDNzc2aMmWKZs2apbvuukvHjx/3ukpW6O7uliRdeOGFkqRdu3bpD3/4Q9SxNXv2bF188cVj/tg6u636/OIXv1B2drYuu+wyrVy5Up999pkX1bNGMBjUpk2b1NPTo/Ly8oQ/ppLiyw8HcuzYMQWDQeXk5ETNz8nJ0UcffeRRrexVVlam559/XrNmzVJ7e7vWrFmj+fPn6/e//70mTpzodfWs1dHRIUkDHmd9r+FLVVVVqq6uVlFRkfbv36+HH35Y119/vVpaWpSamup19TwTCoW0YsUK/cVf/IUuu+wySeFjKy0tTVlZWVHLjvVja6C2kqRbb71V06ZNU35+vvbs2aPvfe972rt3rxobGz2srTfef/99lZeX69SpU7rgggv0+uuv69JLL9Xu3bsT+phK2sACZ66//vrIv+fMmaOysjJNmzZN//RP/6Q77rjDw5ohmSxdujTy78svv1xz5szRjBkz1NzcrIULF3pYM2/dc889+v3vf89zYzEYrK3uvPPOyL8vv/xy5eXlaeHChdq/f79mzJgx2tX01KxZs7R79251d3frtddeU01NjbZv3+51tVxL2ltC2dnZSk1N7ff0c2dnp3Jzcz2qVeLIysrSn/zJn2jfvn1eV8VqfccSx1l8pk+fruzs7DF9nN1777361a9+pW3btqmgoCAyPzc3V6dPn1ZXV1fU8mP52BqsrQZSVlYmSWPy2EpLS9PMmTNVUlKi+vp6zZ07V0899VTCH1NJG1jS0tJUUlKipqamyLxQKKSmpiaVl5d7WLPEcPLkSe3fv195eXleV8VqRUVFys3NjTrOAoGAduzYwXEWg0OHDun48eNj8jgzxujee+/V66+/rt/97ncqKiqKer2kpETnn39+1LG1d+9eHTx4cMwdW0O11UB2794tSWPy2DpbKBRSb29v4h9TXj/1O5I2bdpk0tPTzfPPP2/+53/+x9x5550mKyvLdHR0eF0163znO98xzc3NprW11fznf/6nqaioMNnZ2ebIkSNeV81zJ06cMO+995557733jCTz5JNPmvfee8988sknxhhjnnjiCZOVlWXeeOMNs2fPHrNo0SJTVFRkPv/8c49rPvrO1VYnTpwwDzzwgGlpaTGtra3m3//9380VV1xhLrnkEnPq1Cmvqz7q7rrrLpOZmWmam5tNe3t7ZPrss88iy3z72982F198sfnd735n3nnnHVNeXm7Ky8s9rLU3hmqrffv2mUcffdS88847prW11bzxxhtm+vTp5uqrr/a45qPvoYceMtu3bzetra1mz5495qGHHjI+n8/89re/NcYk9jGV1IHFGGN++tOfmosvvtikpaWZefPmmbffftvrKllpyZIlJi8vz6SlpZmpU6eaJUuWmH379nldLSts27bNSOo31dTUGGPCXZsfeeQRk5OTY9LT083ChQvN3r17va20R87VVp999pm57rrrzEUXXWTOP/98M23aNLN8+fIx+wFioHaSZH7+859Hlvn888/N3XffbSZPnmzGjx9vvvGNb5j29nbvKu2Rodrq4MGD5uqrrzYXXnihSU9PNzNnzjTf/e53TXd3t7cV98Bf/dVfmWnTppm0tDRz0UUXmYULF0bCijGJfUz5jDFm9K7nAAAAOJe0z7AAAIDkQWABAADWI7AAAADrEVgAAID1CCwAAMB6BBYAAGA9AgsAALAegQUAAFiPwAIAAKxHYAEAANYjsAAAAOsRWAAAgPX+PwT/j0PbsWjSAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.linspace(1,len(train_loss),len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e44b27b",
   "metadata": {},
   "source": [
    "As of now, the best outcome comes with \"scaling\" the input timeseries by 10000. Maybe adjust the NN a bit? add some linear and conv layers after the RNN? Multiple layers of RNN? We will see. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
