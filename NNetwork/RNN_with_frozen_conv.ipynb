{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77e9ebe",
   "metadata": {},
   "source": [
    "## RNN with frozen convolution layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6b854e",
   "metadata": {},
   "source": [
    "The idea is inspired by an application of RNN in predicting if an online review (say, for a product) is positive or negative (1 or 0). Each word in the review sentence is first projected to a large dimension vector space and then sent into an RNN network sequentially. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f6b66b",
   "metadata": {},
   "source": [
    "We will make use of frozen convolution layer to create derivative like features for our time series features. Then, we use the derivative values of a certain time as if a \"word\" in a \"review\", the target RV as if the \"score\" of the \"review\" to train an RNN network that predicts the target RV with the time series features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bd88f7",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "907e47ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from proj_mod import training, data_processing\n",
    "importlib.reload(training);\n",
    "importlib.reload(data_processing);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12efccd",
   "metadata": {},
   "source": [
    "Below is what Yuan needed to get his gpu working, do not run if you do not need it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd83d5f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m load_dotenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../dotenv_env/deep_learning.env\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"../dotenv_env/deep_learning.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd9ea17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.3.0\n"
     ]
    }
   ],
   "source": [
    "print(os.environ.get(\"HSA_OVERRIDE_GFX_VERSION\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cb26cd",
   "metadata": {},
   "source": [
    "Let's say, we have following timeseries feature (created randomly), we will create the derivative features first. As a reminder, the zero dimension is the batch size, the dimension one is channel (needed for the first convolution layer, not really a \"thing\" for time series like features). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3d0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_feature=torch.randn(1,1,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b28d5ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6195, -0.6389, -0.1555, -0.3383,  0.0798, -1.6650,  1.1695,\n",
       "          -0.2593,  1.7058,  0.2396,  0.4143, -2.1079, -0.7786,  0.8063,\n",
       "          -1.2070,  0.1275, -1.1544, -1.7544,  0.6644, -0.6037, -0.3678,\n",
       "           0.1948, -1.8461,  0.4062,  0.4913,  0.3940,  1.2150, -1.6215,\n",
       "           0.2274, -1.1374, -0.2868,  0.5215, -1.2731, -0.7222,  2.1310,\n",
       "           0.0263, -0.4286, -1.1935,  2.1196, -0.3426,  0.5490, -0.7507,\n",
       "          -0.2163,  0.7056,  0.3744, -2.0829,  0.8318,  0.5373,  0.6641,\n",
       "          -1.2179, -0.4955, -0.5833, -0.0965,  0.4021,  0.2072, -0.6592,\n",
       "          -0.1757, -1.8129, -0.4105, -0.4676]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "739b2fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_create_diff=training.frozen_diff_conv(n_diff=4)\n",
    "ts_diff_feature=conv_create_diff(ts_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c48f9ca2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6195e+00, -6.3887e-01, -1.5554e-01, -3.3828e-01,  7.9807e-02,\n",
       "          -1.6650e+00,  1.1695e+00, -2.5925e-01,  1.7058e+00,  2.3961e-01,\n",
       "           4.1431e-01, -2.1079e+00, -7.7858e-01,  8.0633e-01, -1.2070e+00,\n",
       "           1.2753e-01, -1.1544e+00, -1.7544e+00,  6.6437e-01, -6.0370e-01,\n",
       "          -3.6780e-01,  1.9476e-01, -1.8461e+00,  4.0624e-01,  4.9125e-01,\n",
       "           3.9399e-01,  1.2150e+00, -1.6215e+00,  2.2744e-01, -1.1374e+00,\n",
       "          -2.8682e-01,  5.2154e-01, -1.2731e+00, -7.2217e-01,  2.1310e+00,\n",
       "           2.6333e-02, -4.2858e-01, -1.1935e+00,  2.1196e+00, -3.4262e-01,\n",
       "           5.4896e-01, -7.5067e-01, -2.1627e-01,  7.0559e-01,  3.7443e-01,\n",
       "          -2.0829e+00,  8.3176e-01,  5.3735e-01,  6.6414e-01, -1.2179e+00,\n",
       "          -4.9555e-01, -5.8328e-01, -9.6545e-02,  4.0210e-01,  2.0719e-01,\n",
       "          -6.5925e-01, -1.7569e-01, -1.8129e+00, -4.1051e-01, -4.6761e-01],\n",
       "         [-2.2584e+00,  4.8334e-01, -1.8275e-01,  4.1809e-01, -1.7448e+00,\n",
       "           2.8345e+00, -1.4288e+00,  1.9651e+00, -1.4662e+00,  1.7470e-01,\n",
       "          -2.5222e+00,  1.3293e+00,  1.5849e+00, -2.0134e+00,  1.3346e+00,\n",
       "          -1.2819e+00, -5.9996e-01,  2.4187e+00, -1.2681e+00,  2.3589e-01,\n",
       "           5.6257e-01, -2.0409e+00,  2.2524e+00,  8.5012e-02, -9.7262e-02,\n",
       "           8.2102e-01, -2.8365e+00,  1.8489e+00, -1.3649e+00,  8.5060e-01,\n",
       "           8.0836e-01, -1.7947e+00,  5.5097e-01,  2.8532e+00, -2.1047e+00,\n",
       "          -4.5491e-01, -7.6488e-01,  3.3130e+00, -2.4622e+00,  8.9158e-01,\n",
       "          -1.2996e+00,  5.3440e-01,  9.2187e-01, -3.3116e-01, -2.4573e+00,\n",
       "           2.9146e+00, -2.9441e-01,  1.2680e-01, -1.8821e+00,  7.2238e-01,\n",
       "          -8.7733e-02,  4.8674e-01,  4.9864e-01, -1.9491e-01, -8.6643e-01,\n",
       "           4.8356e-01, -1.6372e+00,  1.4024e+00, -5.7104e-02,  0.0000e+00],\n",
       "         [ 2.7417e+00, -6.6608e-01,  6.0083e-01, -2.1629e+00,  4.5793e+00,\n",
       "          -4.2633e+00,  3.3938e+00, -3.4313e+00,  1.6409e+00, -2.6969e+00,\n",
       "           3.8515e+00,  2.5562e-01, -3.5983e+00,  3.3479e+00, -2.6165e+00,\n",
       "           6.8196e-01,  3.0187e+00, -3.6868e+00,  1.5040e+00,  3.2667e-01,\n",
       "          -2.6035e+00,  4.2932e+00, -2.1674e+00, -1.8227e-01,  9.1828e-01,\n",
       "          -3.6575e+00,  4.6854e+00, -3.2138e+00,  2.2155e+00, -4.2240e-02,\n",
       "          -2.6030e+00,  2.3457e+00,  2.3022e+00, -4.9578e+00,  1.6498e+00,\n",
       "          -3.0997e-01,  4.0779e+00, -5.7752e+00,  3.3538e+00, -2.1912e+00,\n",
       "           1.8340e+00,  3.8747e-01, -1.2530e+00, -2.1261e+00,  5.3719e+00,\n",
       "          -3.2090e+00,  4.2121e-01, -2.0089e+00,  2.6044e+00, -8.1011e-01,\n",
       "           5.7447e-01,  1.1906e-02, -6.9355e-01, -6.7152e-01,  1.3500e+00,\n",
       "          -2.1208e+00,  3.0396e+00, -1.4595e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-3.4078e+00,  1.2669e+00, -2.7637e+00,  6.7423e+00, -8.8426e+00,\n",
       "           7.6571e+00, -6.8251e+00,  5.0722e+00, -4.3378e+00,  6.5483e+00,\n",
       "          -3.5958e+00, -3.8539e+00,  6.9462e+00, -5.9644e+00,  3.2984e+00,\n",
       "           2.3367e+00, -6.7055e+00,  5.1907e+00, -1.1773e+00, -2.9301e+00,\n",
       "           6.8967e+00, -6.4606e+00,  1.9851e+00,  1.1006e+00, -4.5758e+00,\n",
       "           8.3429e+00, -7.8992e+00,  5.4292e+00, -2.2577e+00, -2.5608e+00,\n",
       "           4.9487e+00, -4.3453e-02, -7.2600e+00,  6.6076e+00, -1.9597e+00,\n",
       "           4.3879e+00, -9.8532e+00,  9.1290e+00, -5.5450e+00,  4.0252e+00,\n",
       "          -1.4466e+00, -1.6405e+00, -8.7309e-01,  7.4980e+00, -8.5809e+00,\n",
       "           3.6302e+00, -2.4301e+00,  4.6133e+00, -3.4146e+00,  1.3846e+00,\n",
       "          -5.6256e-01, -7.0546e-01,  2.2026e-02,  2.0215e+00, -3.4708e+00,\n",
       "           5.1604e+00, -4.4991e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 4.6747e+00, -4.0307e+00,  9.5060e+00, -1.5585e+01,  1.6500e+01,\n",
       "          -1.4482e+01,  1.1897e+01, -9.4100e+00,  1.0886e+01, -1.0144e+01,\n",
       "          -2.5807e-01,  1.0800e+01, -1.2911e+01,  9.2629e+00, -9.6171e-01,\n",
       "          -9.0422e+00,  1.1896e+01, -6.3680e+00, -1.7528e+00,  9.8268e+00,\n",
       "          -1.3357e+01,  8.4457e+00, -8.8452e-01, -5.6763e+00,  1.2919e+01,\n",
       "          -1.6242e+01,  1.3328e+01, -7.6869e+00, -3.0310e-01,  7.5095e+00,\n",
       "          -4.9921e+00, -7.2166e+00,  1.3868e+01, -8.5673e+00,  6.3476e+00,\n",
       "          -1.4241e+01,  1.8982e+01, -1.4674e+01,  9.5702e+00, -5.4718e+00,\n",
       "          -1.9394e-01,  7.6741e-01,  8.3711e+00, -1.6079e+01,  1.2211e+01,\n",
       "          -6.0603e+00,  7.0434e+00, -8.0279e+00,  4.7991e+00, -1.9471e+00,\n",
       "          -1.4289e-01,  7.2748e-01,  1.9995e+00, -5.4923e+00,  8.6311e+00,\n",
       "          -9.6594e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_diff_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79075913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 60])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_diff_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3354b4",
   "metadata": {},
   "source": [
    "We now permute the last two dimensions, essentially, this is just a transposition of the last two dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76682d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_diff_feature=ts_diff_feature.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed4b060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_diff_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cff150",
   "metadata": {},
   "source": [
    "Now, this is a batch (of size 1) of timeseries feature with 60 time steps, and 5 features in each step. We then expand the 5 features, say, to 32 by projection. As a reminder, nn.Linear automatically apply to the last dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b7d96c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_proj=nn.Linear(5,32)\n",
    "ts_feature_proj=linear_proj(ts_diff_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33f82b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_feature_proj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e40c151",
   "metadata": {},
   "source": [
    "In this example, we will not go into too much detail, so let's make the most simple version. We then pass through a layer of RNN, then a layer of linear (to project to dimension 1 again). Learn more about RNN at https://docs.pytorch.org/docs/stable/generated/torch.nn.RNN.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f611ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_layer=nn.RNN(input_size=32,hidden_size=32,num_layers=1,nonlinearity=\"tanh\",batch_first=True,dropout=0)\n",
    "linear_end=nn.Linear(32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "207568f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_out=RNN_layer(ts_feature_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc91386",
   "metadata": {},
   "source": [
    "As a reminder, since no training is done, the RNN basically just applies the initial weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f31dfe8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e423255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_proj=linear_end(RNN_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ba4ee6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_proj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22784470",
   "metadata": {},
   "source": [
    "We will use sum, but we may change this to other functions, according to context or just feeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e293bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_out=torch.sum(out_proj,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b35c7bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2557]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b9f52c",
   "metadata": {},
   "source": [
    "## Creating the actual NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4d007bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created 07/02/25\n",
    "#07/02/25: Moved to training.py \n",
    "#07/08/25: Moved from training.py\n",
    "class RV_RNN_conv(nn.Module):        \n",
    "    #Created 07/02/25 see RNN_with_frozen_conv.ipynb for documentation. \n",
    "    #Modified 07/08/25 Added LSTM and GRU options\n",
    "    def __init__(self,n_diff,rnn_num_layer,rnn_drop_out,rnn_type=\"rnn\",rnn_act=\"tanh\",proj_dim=32,rnn_hidden_size=32,input_scaler=10000):\n",
    "        \"\"\"\n",
    "        :param n_diff: Decides how many derivative features is wanted in the time series. \n",
    "        :param rnn_num_layer: num_layer parameter for rnn. \n",
    "        :param rnn_drop_out: dropout parameter for rnn. \n",
    "        :param rnn_act: Defaulted to \"tanh\". Nonlinearity parameter for rnn. \n",
    "        :param proj_dim: Defaulted to 32. Decided the dimension of projection before feeding into rnn. \n",
    "        :param rnn_hidden_size: Defaulted to 32. The hidden_size parameter for rnn. \n",
    "        :param input_scaler: Defaulted to 10000. Set a scaling to input, a lot of timeseries values of our data are extremely close to zero. \n",
    "        :param rnn_type: 'rnn', 'lstm', or 'gru'\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_scaler=input_scaler\n",
    "        self.frozen_conv=frozen_diff_conv(n_diff=n_diff)\n",
    "        self.linear_proj_input=nn.Linear(n_diff+1,proj_dim)\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "\n",
    "        if rnn_type == \"rnn\":\n",
    "            self.RNN_layer=nn.RNN(input_size=proj_dim,\n",
    "                                  hidden_size=rnn_hidden_size,\n",
    "                                  num_layers=rnn_num_layer,\n",
    "                                  nonlinearity=rnn_act,\n",
    "                                  batch_first=True,\n",
    "                                  dropout=rnn_drop_out)\n",
    "        elif rnn_type == \"lstm\":\n",
    "            if rnn_act is not None:\n",
    "                print(f\"Warning: rnn_act='{rnn_act}' is ignored when using rnn_type='lstm'\")\n",
    "            self.RNN_layer = nn.LSTM(input_size=proj_dim,\n",
    "                                     hidden_size=rnn_hidden_size,\n",
    "                                     num_layers=rnn_num_layer,\n",
    "                                     batch_first=True,\n",
    "                                     dropout=rnn_drop_out)\n",
    "        elif rnn_type == \"gru\":\n",
    "            if rnn_act is not None:\n",
    "                print(f\"Warning: rnn_act='{rnn_act}' is ignored when using rnn_type='gru'\")\n",
    "            self.RNN_layer = nn.GRU(input_size=proj_dim,\n",
    "                                    hidden_size=rnn_hidden_size,\n",
    "                                    num_layers=rnn_num_layer,\n",
    "                                    batch_first=True,\n",
    "                                    dropout=rnn_drop_out)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported rnn_type: {rnn_type}\")\n",
    "        \n",
    "        self.linear_post_rnn=nn.Linear(rnn_hidden_size,1)\n",
    "        self.frozen_list=[\"frozen_conv\"] \n",
    "        \n",
    "    def forward(self,x):\n",
    "        #First, scale the input, and unsqueese to add in one dimension in dim 1 as channel. This is needed for convolution. \n",
    "        x*=self.input_scaler\n",
    "        x=torch.unsqueeze(x,dim=1)\n",
    "        x=self.frozen_conv(x)\n",
    "        x=x.permute(0,2,1)\n",
    "        x=self.linear_proj_input(x)\n",
    "        x=self.RNN_layer(x)[0]\n",
    "        x=self.linear_post_rnn(x)\n",
    "        \n",
    "        return torch.sum(x,dim=1)/self.input_scaler\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71432b31",
   "metadata": {},
   "source": [
    "## Basic testing on the RNN with frozen convolution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9583750",
   "metadata": {},
   "source": [
    "Test it first. As a reminder, the expected input dimensions are (Batch Size, Time Series Length), this is distinct from the example above in that the channel dimension is not present. The channel dimension is added with unsqueeze at dimension 1 so that the first convolution layer can be utilized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df3d8c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_feature=torch.randn(10,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a33fd643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.9971e-01, -1.3001e-01, -1.1403e+00, -7.7236e-01,  1.8599e+00,\n",
       "         -6.9808e-01,  1.5106e+00, -1.4802e+00, -3.9169e-01, -3.1802e-02,\n",
       "         -1.1092e+00,  4.7330e-01,  7.7057e-02, -6.1030e-02,  4.4273e-02,\n",
       "          1.1545e+00,  1.6664e+00, -2.5811e-01, -1.0196e+00,  3.4227e-01,\n",
       "          9.0611e-02, -7.1442e-01, -5.1483e-01,  6.6749e-01,  1.6236e+00,\n",
       "         -1.5389e+00, -7.6098e-01, -6.0926e-01,  1.5119e+00,  1.4623e+00,\n",
       "         -1.8738e+00, -1.0195e+00,  5.1206e-01,  6.5966e-01,  2.5789e-02,\n",
       "         -1.6673e-01, -3.5891e-01, -1.8669e+00, -2.8837e-01,  7.1051e-01,\n",
       "          8.5181e-01,  1.8687e-01,  6.3762e-01, -2.0904e-01, -1.0262e+00,\n",
       "         -6.2161e-01,  1.8408e+00, -1.6856e+00,  5.2398e-01, -5.6024e-01,\n",
       "          1.3300e-01,  1.2988e+00,  7.8794e-02,  4.5463e-02, -3.4238e-01,\n",
       "         -9.0760e-01, -1.3707e+00, -4.4723e-01, -2.9356e-01, -6.8926e-01],\n",
       "        [ 1.4308e+00,  5.3982e-01, -5.7762e-02,  7.6088e-01, -4.5305e-01,\n",
       "          3.6230e-01,  2.3692e-01,  1.2783e+00, -3.0438e-01,  4.8155e-01,\n",
       "         -9.4604e-02, -5.2999e-02,  7.0097e-01, -1.3007e+00, -8.7723e-01,\n",
       "          7.4288e-02, -2.6345e-01,  5.9917e-02, -1.4569e-01,  1.7438e+00,\n",
       "         -7.0533e-01,  1.8248e-01,  6.2562e-01, -1.1259e-01, -6.2901e-01,\n",
       "          4.4033e-01, -4.3137e-01,  1.1272e-02, -2.5805e-01, -4.9702e-01,\n",
       "          1.3716e+00, -3.2789e-01,  3.0504e-01, -8.9711e-01,  2.3774e+00,\n",
       "          1.6353e+00, -1.2243e+00,  1.6841e-01,  7.3736e-01, -1.0567e+00,\n",
       "         -1.0988e+00, -8.9903e-01,  1.6964e-01, -1.3469e+00,  6.7174e-02,\n",
       "         -1.0021e+00,  3.9571e-01,  8.8042e-01, -1.5078e+00,  3.5894e-01,\n",
       "          3.3802e-01,  3.0487e-01,  3.4259e-01, -3.8630e-01, -2.4155e-02,\n",
       "          7.3312e-01,  8.7817e-01, -8.2768e-01, -2.9355e-01,  3.3061e-01],\n",
       "        [ 2.5318e-01,  3.8102e-01,  2.6876e+00, -3.9484e-01, -2.3881e-01,\n",
       "          6.8641e-02,  5.9486e-01, -1.4737e+00,  7.0669e-01,  1.5046e+00,\n",
       "          5.9085e-01,  1.4933e+00, -2.1005e-01,  1.3130e+00, -9.1704e-01,\n",
       "         -1.1039e+00,  1.4833e+00,  4.7081e-02,  2.2842e-01,  4.6167e-01,\n",
       "         -1.0363e-01,  6.6925e-01, -1.5840e+00,  6.5668e-02, -1.4168e+00,\n",
       "         -1.2486e+00, -1.8272e+00,  1.8112e+00,  6.1650e-01, -1.1103e-01,\n",
       "         -1.8234e-01,  5.7363e-02,  8.6665e-01, -2.0815e+00,  4.1343e-01,\n",
       "         -4.2743e-01,  2.8909e-01,  9.4002e-01,  5.8888e-01,  1.6420e-02,\n",
       "         -8.4871e-02,  3.4691e-01, -9.5851e-01, -1.0034e+00, -1.3980e-01,\n",
       "         -4.1359e-01, -1.7873e+00, -9.6459e-01,  3.7664e-01,  1.8563e+00,\n",
       "          1.9582e+00,  8.4362e-01,  1.0092e+00,  1.4458e-03, -8.9394e-02,\n",
       "         -2.7246e+00, -6.4128e-01, -1.9199e+00, -3.2695e-01, -5.1117e-02],\n",
       "        [-1.2159e-01, -9.3231e-01, -9.6076e-01,  1.6190e+00,  1.5291e+00,\n",
       "         -4.0395e-01,  7.7714e-01,  1.8677e+00,  7.4954e-01, -1.0456e+00,\n",
       "         -1.4263e+00, -3.0523e-01,  6.0739e-01, -7.2510e-01, -1.8583e+00,\n",
       "         -1.3546e+00, -2.8826e-01,  1.0497e+00,  9.0350e-01, -1.5834e+00,\n",
       "         -1.6264e-01, -2.9454e-01, -1.1195e+00,  8.4818e-01, -6.9007e-01,\n",
       "         -7.8531e-01,  5.0420e-01, -8.7133e-01, -6.6761e-02, -1.1322e+00,\n",
       "          1.3554e+00, -1.2367e-01,  1.7541e+00, -4.7034e-01,  1.3373e+00,\n",
       "          2.4652e-01, -1.1514e+00,  5.9967e-01, -1.0854e+00, -4.6820e-01,\n",
       "          1.1397e+00, -9.3558e-02, -6.7728e-01, -1.7160e+00,  1.4537e+00,\n",
       "          9.9533e-01,  1.7130e+00,  7.6425e-01, -2.5230e+00,  1.2070e+00,\n",
       "          1.0142e+00, -9.4738e-02, -1.1420e-01, -9.2427e-01,  2.3712e-01,\n",
       "          1.4228e-01,  4.5694e-01,  6.2191e-01,  1.8468e+00, -9.8112e-01],\n",
       "        [ 1.1306e+00,  8.3529e-01, -2.9954e-01, -4.7112e-01, -2.0877e-01,\n",
       "         -4.8950e-03, -7.8825e-01,  1.4376e+00,  8.9070e-01,  5.7410e-01,\n",
       "         -2.1297e+00,  2.0067e+00, -4.7687e-01, -1.6458e-02, -1.0851e+00,\n",
       "          1.0390e+00, -1.5669e+00,  5.4534e-01,  8.1195e-03,  7.4603e-01,\n",
       "          1.7752e+00, -2.3654e-02,  5.3764e-01,  7.7837e-01,  1.7001e-01,\n",
       "          5.3340e-01,  8.1639e-01,  5.8233e-02,  2.0643e+00,  9.8667e-01,\n",
       "          3.8659e-01, -1.8921e+00, -1.5634e+00, -1.3588e+00,  7.2107e-01,\n",
       "         -3.4673e-01,  1.0420e+00, -1.3223e+00, -2.3510e-01,  7.3066e-01,\n",
       "          1.4870e-01, -1.6533e+00, -5.8012e-01,  2.5478e+00, -2.4914e-01,\n",
       "          6.1622e-01, -3.0964e-01, -7.9378e-01,  6.9507e-01,  8.6993e-01,\n",
       "          2.0109e+00,  1.2179e+00, -1.4531e+00, -6.3152e-01, -1.0339e+00,\n",
       "          7.5825e-02,  7.8944e-01,  4.8174e-01,  1.1309e+00,  1.0797e+00],\n",
       "        [ 7.7379e-01, -1.0015e+00, -6.1293e-01, -4.6681e-01, -4.5193e-01,\n",
       "          2.1192e+00,  9.8311e-01,  7.3992e-01, -8.6174e-01,  8.6770e-01,\n",
       "         -3.8720e-01,  8.5517e-02, -8.4072e-01,  9.0587e-01, -5.6736e-01,\n",
       "          2.3657e-01, -5.1644e-01, -8.5824e-01,  1.0341e+00, -1.1768e+00,\n",
       "          9.0630e-01, -6.1566e-02, -8.9221e-02, -4.8559e-01, -1.4921e+00,\n",
       "          9.0793e-01,  7.9805e-01, -1.7393e+00, -3.4292e-02,  1.2818e+00,\n",
       "         -3.2004e+00,  9.9491e-02, -1.3688e+00, -1.2971e+00,  2.6267e-01,\n",
       "          9.5438e-01, -1.4132e+00,  1.8926e+00,  7.1759e-01, -1.9862e+00,\n",
       "         -9.0729e-01, -7.5776e-01, -7.7266e-01, -6.4274e-01, -1.7269e-01,\n",
       "          1.2985e-01,  4.4351e-02,  1.7689e-01,  7.7345e-01, -1.0645e+00,\n",
       "          6.4652e-01, -1.5979e+00,  6.0500e-01, -1.0385e+00, -2.3670e+00,\n",
       "         -4.2446e-01,  1.4906e+00, -7.9251e-01,  9.9229e-01, -1.5774e+00],\n",
       "        [ 5.0177e-01,  2.4106e-01, -6.5872e-01,  1.0902e-01,  5.8086e-01,\n",
       "          1.9186e+00, -2.1326e+00, -6.2231e-01, -2.3593e-01,  1.7025e-01,\n",
       "          1.4749e+00, -9.4292e-01,  1.4547e-01,  9.4311e-01, -8.5379e-01,\n",
       "         -2.2129e-01, -1.3732e+00,  1.3589e+00,  4.6782e-01, -8.9807e-01,\n",
       "          4.7402e-01,  9.1744e-01, -3.2876e-01,  5.9779e-02, -6.4242e-01,\n",
       "          6.8333e-01,  8.7154e-01, -2.3882e-01, -1.0712e+00,  3.9495e-01,\n",
       "          9.2707e-01, -3.0983e-01, -9.8542e-01, -3.6934e-02,  2.6743e+00,\n",
       "          1.0013e+00,  1.1709e-01,  1.5947e-02,  3.3760e-01, -3.6029e-01,\n",
       "         -9.8500e-01,  6.7139e-02, -1.4012e+00,  2.3760e+00,  9.4070e-01,\n",
       "          4.0330e-01,  7.5822e-01,  8.5953e-01,  2.1727e-03,  2.1302e+00,\n",
       "         -8.0883e-01, -6.9155e-01, -6.3846e-01,  3.0520e-01,  7.0363e-01,\n",
       "         -3.8721e-01, -7.9320e-02, -3.1789e-01,  1.6018e+00, -1.7475e-01],\n",
       "        [ 4.8490e-01, -1.3485e+00, -5.2845e-01,  5.3322e-02, -1.4477e+00,\n",
       "          9.9759e-01, -1.8074e+00,  5.3383e-01, -9.1542e-01,  1.7862e+00,\n",
       "          2.3016e-01,  8.7560e-02, -1.2497e+00,  6.4770e-01,  1.8212e-01,\n",
       "         -1.4018e+00,  8.9644e-01, -3.1460e-01, -2.0938e-01, -7.8133e-01,\n",
       "         -7.5440e-01,  1.2900e-01, -7.9421e-01, -3.7794e-01, -6.4391e-01,\n",
       "          1.0784e+00, -3.2008e-01,  1.4775e+00, -1.3190e+00, -1.1476e-01,\n",
       "          7.4479e-01, -3.8717e-01,  1.5714e+00, -1.8139e+00,  1.0767e+00,\n",
       "         -1.9131e-01, -3.9009e-01,  6.7437e-01,  1.9352e-01,  1.2796e+00,\n",
       "          8.4135e-01, -1.4779e-01,  1.2561e+00,  1.0188e+00, -2.6481e-01,\n",
       "         -8.8988e-01, -2.6440e-01,  3.8843e-01,  1.8583e+00,  6.6880e-01,\n",
       "         -3.5173e-01,  7.0168e-01,  6.8942e-03,  8.2315e-01, -5.4192e-01,\n",
       "          3.9011e-01, -2.0729e+00,  2.0115e-01, -1.0041e+00,  1.4397e+00],\n",
       "        [-5.4609e-01, -4.4945e-01,  8.4361e-01,  9.1256e-01, -2.1864e-01,\n",
       "          1.4071e+00,  9.5832e-01,  1.1638e+00,  4.8710e-01,  1.4185e+00,\n",
       "         -5.6033e-01,  5.4311e-01, -1.0688e+00, -6.0023e-02, -4.0872e-01,\n",
       "          7.2920e-01,  3.6835e-01,  1.2659e+00, -9.8012e-01,  1.3341e-01,\n",
       "          4.7883e-01, -3.3977e-01, -3.3112e-02,  1.7383e+00, -1.0779e-01,\n",
       "          6.0118e-01, -7.4359e-01,  2.2610e-02, -7.3870e-01,  8.4551e-01,\n",
       "          3.0700e-01, -1.1002e-01,  9.7740e-01, -1.0727e+00,  1.0603e-01,\n",
       "          4.6367e-01,  4.9650e-01, -1.1421e-01, -1.8990e-01, -3.7088e-01,\n",
       "         -1.0236e+00, -4.6599e-02, -1.7324e-01, -7.4255e-02,  6.5932e-01,\n",
       "          1.0170e+00,  1.3835e+00,  1.2800e+00, -3.1610e-01, -5.9489e-01,\n",
       "          8.0888e-01,  7.8598e-01,  2.4849e-01, -1.0180e+00,  7.3784e-01,\n",
       "          3.8891e-01, -4.3239e-01,  1.6123e+00,  1.9342e-01,  1.8111e+00],\n",
       "        [ 1.0528e+00,  1.5704e+00,  1.9603e-03, -1.4646e+00, -7.5266e-01,\n",
       "          1.3770e-01, -1.9638e-01, -2.8527e-01,  1.1037e+00, -1.8202e+00,\n",
       "         -5.3344e-01,  9.3706e-02, -1.7282e+00,  4.0101e-01,  1.5522e+00,\n",
       "         -7.6144e-01,  1.1975e+00,  1.1506e+00, -1.7320e+00,  3.1218e-01,\n",
       "         -5.2718e-01,  1.3342e-01,  4.5582e-01, -1.1597e+00, -6.2798e-01,\n",
       "          5.8446e-02,  2.7572e-01,  1.1971e+00,  1.5550e+00, -1.8516e+00,\n",
       "         -7.1024e-01,  4.1439e-01,  7.8271e-01,  1.0857e+00, -5.0055e-01,\n",
       "         -1.8306e+00,  6.7957e-02, -5.3453e-01, -1.3076e-01,  1.4755e+00,\n",
       "          5.7825e-01,  1.9042e+00,  3.1708e-01, -8.3081e-01,  1.7181e-01,\n",
       "          3.1793e-02,  1.8867e-01,  1.6538e+00,  3.2521e-02,  2.5793e-01,\n",
       "         -1.6234e-02, -8.3267e-01, -2.0775e+00, -8.5538e-01,  3.1289e-02,\n",
       "          4.3229e-01,  7.8150e-01, -1.9540e+00,  4.6232e-01,  1.4607e+00]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72cd7276",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.9971e-01, -1.3001e-01, -1.1403e+00, -7.7236e-01,  1.8599e+00,\n",
       "          -6.9808e-01,  1.5106e+00, -1.4802e+00, -3.9169e-01, -3.1802e-02,\n",
       "          -1.1092e+00,  4.7330e-01,  7.7057e-02, -6.1030e-02,  4.4273e-02,\n",
       "           1.1545e+00,  1.6664e+00, -2.5811e-01, -1.0196e+00,  3.4227e-01,\n",
       "           9.0611e-02, -7.1442e-01, -5.1483e-01,  6.6749e-01,  1.6236e+00,\n",
       "          -1.5389e+00, -7.6098e-01, -6.0926e-01,  1.5119e+00,  1.4623e+00,\n",
       "          -1.8738e+00, -1.0195e+00,  5.1206e-01,  6.5966e-01,  2.5789e-02,\n",
       "          -1.6673e-01, -3.5891e-01, -1.8669e+00, -2.8837e-01,  7.1051e-01,\n",
       "           8.5181e-01,  1.8687e-01,  6.3762e-01, -2.0904e-01, -1.0262e+00,\n",
       "          -6.2161e-01,  1.8408e+00, -1.6856e+00,  5.2398e-01, -5.6024e-01,\n",
       "           1.3300e-01,  1.2988e+00,  7.8794e-02,  4.5463e-02, -3.4238e-01,\n",
       "          -9.0760e-01, -1.3707e+00, -4.4723e-01, -2.9356e-01, -6.8926e-01]],\n",
       "\n",
       "        [[ 1.4308e+00,  5.3982e-01, -5.7762e-02,  7.6088e-01, -4.5305e-01,\n",
       "           3.6230e-01,  2.3692e-01,  1.2783e+00, -3.0438e-01,  4.8155e-01,\n",
       "          -9.4604e-02, -5.2999e-02,  7.0097e-01, -1.3007e+00, -8.7723e-01,\n",
       "           7.4288e-02, -2.6345e-01,  5.9917e-02, -1.4569e-01,  1.7438e+00,\n",
       "          -7.0533e-01,  1.8248e-01,  6.2562e-01, -1.1259e-01, -6.2901e-01,\n",
       "           4.4033e-01, -4.3137e-01,  1.1272e-02, -2.5805e-01, -4.9702e-01,\n",
       "           1.3716e+00, -3.2789e-01,  3.0504e-01, -8.9711e-01,  2.3774e+00,\n",
       "           1.6353e+00, -1.2243e+00,  1.6841e-01,  7.3736e-01, -1.0567e+00,\n",
       "          -1.0988e+00, -8.9903e-01,  1.6964e-01, -1.3469e+00,  6.7174e-02,\n",
       "          -1.0021e+00,  3.9571e-01,  8.8042e-01, -1.5078e+00,  3.5894e-01,\n",
       "           3.3802e-01,  3.0487e-01,  3.4259e-01, -3.8630e-01, -2.4155e-02,\n",
       "           7.3312e-01,  8.7817e-01, -8.2768e-01, -2.9355e-01,  3.3061e-01]],\n",
       "\n",
       "        [[ 2.5318e-01,  3.8102e-01,  2.6876e+00, -3.9484e-01, -2.3881e-01,\n",
       "           6.8641e-02,  5.9486e-01, -1.4737e+00,  7.0669e-01,  1.5046e+00,\n",
       "           5.9085e-01,  1.4933e+00, -2.1005e-01,  1.3130e+00, -9.1704e-01,\n",
       "          -1.1039e+00,  1.4833e+00,  4.7081e-02,  2.2842e-01,  4.6167e-01,\n",
       "          -1.0363e-01,  6.6925e-01, -1.5840e+00,  6.5668e-02, -1.4168e+00,\n",
       "          -1.2486e+00, -1.8272e+00,  1.8112e+00,  6.1650e-01, -1.1103e-01,\n",
       "          -1.8234e-01,  5.7363e-02,  8.6665e-01, -2.0815e+00,  4.1343e-01,\n",
       "          -4.2743e-01,  2.8909e-01,  9.4002e-01,  5.8888e-01,  1.6420e-02,\n",
       "          -8.4871e-02,  3.4691e-01, -9.5851e-01, -1.0034e+00, -1.3980e-01,\n",
       "          -4.1359e-01, -1.7873e+00, -9.6459e-01,  3.7664e-01,  1.8563e+00,\n",
       "           1.9582e+00,  8.4362e-01,  1.0092e+00,  1.4458e-03, -8.9394e-02,\n",
       "          -2.7246e+00, -6.4128e-01, -1.9199e+00, -3.2695e-01, -5.1117e-02]],\n",
       "\n",
       "        [[-1.2159e-01, -9.3231e-01, -9.6076e-01,  1.6190e+00,  1.5291e+00,\n",
       "          -4.0395e-01,  7.7714e-01,  1.8677e+00,  7.4954e-01, -1.0456e+00,\n",
       "          -1.4263e+00, -3.0523e-01,  6.0739e-01, -7.2510e-01, -1.8583e+00,\n",
       "          -1.3546e+00, -2.8826e-01,  1.0497e+00,  9.0350e-01, -1.5834e+00,\n",
       "          -1.6264e-01, -2.9454e-01, -1.1195e+00,  8.4818e-01, -6.9007e-01,\n",
       "          -7.8531e-01,  5.0420e-01, -8.7133e-01, -6.6761e-02, -1.1322e+00,\n",
       "           1.3554e+00, -1.2367e-01,  1.7541e+00, -4.7034e-01,  1.3373e+00,\n",
       "           2.4652e-01, -1.1514e+00,  5.9967e-01, -1.0854e+00, -4.6820e-01,\n",
       "           1.1397e+00, -9.3558e-02, -6.7728e-01, -1.7160e+00,  1.4537e+00,\n",
       "           9.9533e-01,  1.7130e+00,  7.6425e-01, -2.5230e+00,  1.2070e+00,\n",
       "           1.0142e+00, -9.4738e-02, -1.1420e-01, -9.2427e-01,  2.3712e-01,\n",
       "           1.4228e-01,  4.5694e-01,  6.2191e-01,  1.8468e+00, -9.8112e-01]],\n",
       "\n",
       "        [[ 1.1306e+00,  8.3529e-01, -2.9954e-01, -4.7112e-01, -2.0877e-01,\n",
       "          -4.8950e-03, -7.8825e-01,  1.4376e+00,  8.9070e-01,  5.7410e-01,\n",
       "          -2.1297e+00,  2.0067e+00, -4.7687e-01, -1.6458e-02, -1.0851e+00,\n",
       "           1.0390e+00, -1.5669e+00,  5.4534e-01,  8.1195e-03,  7.4603e-01,\n",
       "           1.7752e+00, -2.3654e-02,  5.3764e-01,  7.7837e-01,  1.7001e-01,\n",
       "           5.3340e-01,  8.1639e-01,  5.8233e-02,  2.0643e+00,  9.8667e-01,\n",
       "           3.8659e-01, -1.8921e+00, -1.5634e+00, -1.3588e+00,  7.2107e-01,\n",
       "          -3.4673e-01,  1.0420e+00, -1.3223e+00, -2.3510e-01,  7.3066e-01,\n",
       "           1.4870e-01, -1.6533e+00, -5.8012e-01,  2.5478e+00, -2.4914e-01,\n",
       "           6.1622e-01, -3.0964e-01, -7.9378e-01,  6.9507e-01,  8.6993e-01,\n",
       "           2.0109e+00,  1.2179e+00, -1.4531e+00, -6.3152e-01, -1.0339e+00,\n",
       "           7.5825e-02,  7.8944e-01,  4.8174e-01,  1.1309e+00,  1.0797e+00]],\n",
       "\n",
       "        [[ 7.7379e-01, -1.0015e+00, -6.1293e-01, -4.6681e-01, -4.5193e-01,\n",
       "           2.1192e+00,  9.8311e-01,  7.3992e-01, -8.6174e-01,  8.6770e-01,\n",
       "          -3.8720e-01,  8.5517e-02, -8.4072e-01,  9.0587e-01, -5.6736e-01,\n",
       "           2.3657e-01, -5.1644e-01, -8.5824e-01,  1.0341e+00, -1.1768e+00,\n",
       "           9.0630e-01, -6.1566e-02, -8.9221e-02, -4.8559e-01, -1.4921e+00,\n",
       "           9.0793e-01,  7.9805e-01, -1.7393e+00, -3.4292e-02,  1.2818e+00,\n",
       "          -3.2004e+00,  9.9491e-02, -1.3688e+00, -1.2971e+00,  2.6267e-01,\n",
       "           9.5438e-01, -1.4132e+00,  1.8926e+00,  7.1759e-01, -1.9862e+00,\n",
       "          -9.0729e-01, -7.5776e-01, -7.7266e-01, -6.4274e-01, -1.7269e-01,\n",
       "           1.2985e-01,  4.4351e-02,  1.7689e-01,  7.7345e-01, -1.0645e+00,\n",
       "           6.4652e-01, -1.5979e+00,  6.0500e-01, -1.0385e+00, -2.3670e+00,\n",
       "          -4.2446e-01,  1.4906e+00, -7.9251e-01,  9.9229e-01, -1.5774e+00]],\n",
       "\n",
       "        [[ 5.0177e-01,  2.4106e-01, -6.5872e-01,  1.0902e-01,  5.8086e-01,\n",
       "           1.9186e+00, -2.1326e+00, -6.2231e-01, -2.3593e-01,  1.7025e-01,\n",
       "           1.4749e+00, -9.4292e-01,  1.4547e-01,  9.4311e-01, -8.5379e-01,\n",
       "          -2.2129e-01, -1.3732e+00,  1.3589e+00,  4.6782e-01, -8.9807e-01,\n",
       "           4.7402e-01,  9.1744e-01, -3.2876e-01,  5.9779e-02, -6.4242e-01,\n",
       "           6.8333e-01,  8.7154e-01, -2.3882e-01, -1.0712e+00,  3.9495e-01,\n",
       "           9.2707e-01, -3.0983e-01, -9.8542e-01, -3.6934e-02,  2.6743e+00,\n",
       "           1.0013e+00,  1.1709e-01,  1.5947e-02,  3.3760e-01, -3.6029e-01,\n",
       "          -9.8500e-01,  6.7139e-02, -1.4012e+00,  2.3760e+00,  9.4070e-01,\n",
       "           4.0330e-01,  7.5822e-01,  8.5953e-01,  2.1727e-03,  2.1302e+00,\n",
       "          -8.0883e-01, -6.9155e-01, -6.3846e-01,  3.0520e-01,  7.0363e-01,\n",
       "          -3.8721e-01, -7.9320e-02, -3.1789e-01,  1.6018e+00, -1.7475e-01]],\n",
       "\n",
       "        [[ 4.8490e-01, -1.3485e+00, -5.2845e-01,  5.3322e-02, -1.4477e+00,\n",
       "           9.9759e-01, -1.8074e+00,  5.3383e-01, -9.1542e-01,  1.7862e+00,\n",
       "           2.3016e-01,  8.7560e-02, -1.2497e+00,  6.4770e-01,  1.8212e-01,\n",
       "          -1.4018e+00,  8.9644e-01, -3.1460e-01, -2.0938e-01, -7.8133e-01,\n",
       "          -7.5440e-01,  1.2900e-01, -7.9421e-01, -3.7794e-01, -6.4391e-01,\n",
       "           1.0784e+00, -3.2008e-01,  1.4775e+00, -1.3190e+00, -1.1476e-01,\n",
       "           7.4479e-01, -3.8717e-01,  1.5714e+00, -1.8139e+00,  1.0767e+00,\n",
       "          -1.9131e-01, -3.9009e-01,  6.7437e-01,  1.9352e-01,  1.2796e+00,\n",
       "           8.4135e-01, -1.4779e-01,  1.2561e+00,  1.0188e+00, -2.6481e-01,\n",
       "          -8.8988e-01, -2.6440e-01,  3.8843e-01,  1.8583e+00,  6.6880e-01,\n",
       "          -3.5173e-01,  7.0168e-01,  6.8942e-03,  8.2315e-01, -5.4192e-01,\n",
       "           3.9011e-01, -2.0729e+00,  2.0115e-01, -1.0041e+00,  1.4397e+00]],\n",
       "\n",
       "        [[-5.4609e-01, -4.4945e-01,  8.4361e-01,  9.1256e-01, -2.1864e-01,\n",
       "           1.4071e+00,  9.5832e-01,  1.1638e+00,  4.8710e-01,  1.4185e+00,\n",
       "          -5.6033e-01,  5.4311e-01, -1.0688e+00, -6.0023e-02, -4.0872e-01,\n",
       "           7.2920e-01,  3.6835e-01,  1.2659e+00, -9.8012e-01,  1.3341e-01,\n",
       "           4.7883e-01, -3.3977e-01, -3.3112e-02,  1.7383e+00, -1.0779e-01,\n",
       "           6.0118e-01, -7.4359e-01,  2.2610e-02, -7.3870e-01,  8.4551e-01,\n",
       "           3.0700e-01, -1.1002e-01,  9.7740e-01, -1.0727e+00,  1.0603e-01,\n",
       "           4.6367e-01,  4.9650e-01, -1.1421e-01, -1.8990e-01, -3.7088e-01,\n",
       "          -1.0236e+00, -4.6599e-02, -1.7324e-01, -7.4255e-02,  6.5932e-01,\n",
       "           1.0170e+00,  1.3835e+00,  1.2800e+00, -3.1610e-01, -5.9489e-01,\n",
       "           8.0888e-01,  7.8598e-01,  2.4849e-01, -1.0180e+00,  7.3784e-01,\n",
       "           3.8891e-01, -4.3239e-01,  1.6123e+00,  1.9342e-01,  1.8111e+00]],\n",
       "\n",
       "        [[ 1.0528e+00,  1.5704e+00,  1.9603e-03, -1.4646e+00, -7.5266e-01,\n",
       "           1.3770e-01, -1.9638e-01, -2.8527e-01,  1.1037e+00, -1.8202e+00,\n",
       "          -5.3344e-01,  9.3706e-02, -1.7282e+00,  4.0101e-01,  1.5522e+00,\n",
       "          -7.6144e-01,  1.1975e+00,  1.1506e+00, -1.7320e+00,  3.1218e-01,\n",
       "          -5.2718e-01,  1.3342e-01,  4.5582e-01, -1.1597e+00, -6.2798e-01,\n",
       "           5.8446e-02,  2.7572e-01,  1.1971e+00,  1.5550e+00, -1.8516e+00,\n",
       "          -7.1024e-01,  4.1439e-01,  7.8271e-01,  1.0857e+00, -5.0055e-01,\n",
       "          -1.8306e+00,  6.7957e-02, -5.3453e-01, -1.3076e-01,  1.4755e+00,\n",
       "           5.7825e-01,  1.9042e+00,  3.1708e-01, -8.3081e-01,  1.7181e-01,\n",
       "           3.1793e-02,  1.8867e-01,  1.6538e+00,  3.2521e-02,  2.5793e-01,\n",
       "          -1.6234e-02, -8.3267e-01, -2.0775e+00, -8.5538e-01,  3.1289e-02,\n",
       "           4.3229e-01,  7.8150e-01, -1.9540e+00,  4.6232e-01,  1.4607e+00]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(ts_feature,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "455ed170",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=training.RV_RNN_conv(n_diff=4,rnn_act=\"tanh\",rnn_num_layer=2,rnn_drop_out=0.3,rnn_hidden_size=32,proj_dim=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85bf9cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=model(ts_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc35034a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3662e-05],\n",
       "        [ 2.1474e-04],\n",
       "        [-1.5604e-04],\n",
       "        [ 4.3390e-04],\n",
       "        [ 1.9061e-04],\n",
       "        [ 1.2641e-04],\n",
       "        [ 1.4729e-04],\n",
       "        [ 2.5284e-04],\n",
       "        [ 2.1373e-04],\n",
       "        [ 1.3819e-04]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bfbac7",
   "metadata": {},
   "source": [
    "## Training loop (basic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06d4fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_time=np.load(\"../processed_data/recovered_time_id_order.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "739d9a32-e68b-4f66-bd6b-0fda83803f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4294 31984 31570 ... 29316 32195 10890]\n"
     ]
    }
   ],
   "source": [
    "print(list_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "825838c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In fold 0 :\n",
      "\n",
      "Train set end at 8117 .\n",
      "\n",
      "Test set start at 15516 end at 10890 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_split_list=data_processing.time_cross_val_split(list_time=list_time,n_split=1,percent_val_size=10,list_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87ca970a-b88b-4b85-8337-6cf6a957e5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4294, 31984, 31570, ...,  5629, 10421,  8117])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_split_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7ba8aa2-a446-4389-8d49-bca021ceb63f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15516, 30276, 16402, 27182, 24497, 13529,   373,  4219, 20323,\n",
       "        9160, 28983, 17820, 22678,  7460, 29676, 32048, 22405, 31380,\n",
       "        1816, 14079, 29944, 21990, 26804, 28210, 18142, 11682, 32597,\n",
       "       13513, 32690, 27120, 27427,  7418,  1213,  9822, 29692, 24523,\n",
       "       25318,  6274, 25569, 12713,   169, 20732, 15906, 28877, 25551,\n",
       "       10745, 31320, 31714,  6076, 23656,   424,   309, 17604, 28963,\n",
       "       23144, 11872, 29219, 25357, 22828, 17569, 17955, 11920, 18509,\n",
       "       19626, 16149,  5392,  7200, 10929,  4774, 27278, 23639, 10633,\n",
       "          72, 32534, 26944, 31018, 26494,  6648,   709,  6823, 21239,\n",
       "       11995, 23265, 31883,  2711,  1350,  1321, 16282,  5046, 29875,\n",
       "        7133, 15823, 25463,  9064,  3333, 11440, 16831,  6815, 19580,\n",
       "       30620, 24014, 17193, 10708, 30597,  4367, 27962, 13010, 32254,\n",
       "       23226, 22903,  5929, 30327,  1866, 14629,  1205,  9352, 10619,\n",
       "       14234, 15276,  4091, 22752, 18653, 11453, 26708, 30183, 13986,\n",
       "           5,  7864,  9889, 31471, 26868, 10672, 31347, 15418, 30430,\n",
       "       26568, 28267,  3955,  1392, 27014, 22081, 15845, 18728,  9936,\n",
       "        5232,  2366, 26886, 30272, 11393, 30750,  7572, 21601,  2331,\n",
       "       13207, 12073,  2058, 18502, 25429, 12532, 27496,  5932,   536,\n",
       "       27595, 23185, 26752,  2683,  6585, 15131,  6144, 27042,  7743,\n",
       "       22249, 32611,  3758, 19271, 13614, 31572, 17570,  9367, 11263,\n",
       "       14285, 12981,   146,  2643, 31266, 23490,  2109, 29906, 30303,\n",
       "       12102, 32649,  8721, 26606, 32012, 16511, 30908, 19871,  3513,\n",
       "        3001, 24127, 29974, 27752, 16504,  6631,  8750,  6493, 29819,\n",
       "       12147, 13503, 11264, 31236,  8365, 23486, 13294,  1292, 17265,\n",
       "       16594, 20928, 18205,  6316,  8459, 19955,  7369, 26763, 13560,\n",
       "        3211, 31254, 13720,   152,  4844, 14738, 22548, 27886,  4131,\n",
       "        6657, 13699, 25639,  2000, 26788, 21103, 11577, 29037,  9947,\n",
       "       32134, 30341, 17112,  7548, 20265, 12533, 10262, 10616,  7512,\n",
       "       28354, 25879,  2440, 21614, 32255, 15584,  9735, 31874, 30366,\n",
       "       31047, 16507,  6906,  9396,  6217,  1521, 17378, 26091,  3318,\n",
       "       32746,  8744, 26889,  1468,  6965, 17117,   817,  3130, 14928,\n",
       "       21373, 13980, 28634,   103, 27543, 26849,  7909, 18077, 30569,\n",
       "       10105, 12178, 20491, 32704, 12923, 15393, 14976, 26168,  2867,\n",
       "       12182, 27524, 30339, 18285, 28474, 27981, 13928, 10892, 14909,\n",
       "       21024, 25971,  9266, 25277,  5425, 17454,  3962, 14449, 31389,\n",
       "       17672,  9887, 20669,  4089, 19512, 30212, 11151, 22912, 25359,\n",
       "       29947, 31348, 16731,  1948,  6730, 14176,  2656, 15728,  8573,\n",
       "       21762,  6359,  5846, 12521, 26578,  8623,  9096, 23423, 22513,\n",
       "       23539, 17528,  5663, 24021, 32240, 28635,  2553, 13791, 22427,\n",
       "       19647, 26170,  2718, 28192, 19065,  2136, 29679,  9028, 17120,\n",
       "       25312,   618, 18184, 21658, 13627, 25338, 31402, 24406, 31331,\n",
       "        7759,  3123,  2027, 18703, 28837, 11718, 13579, 10455, 10604,\n",
       "       24913, 15365, 29316, 32195, 10890])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_split_list[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72aedca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_id,test_time_id=time_split_list[0][0],time_split_list[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3338fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RV_ts=pd.read_parquet(\"../processed_data/book_RV_ts_60_si.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62e2f34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b9cf070",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e42729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RV_ts[\"sub_int_RV_norm\"]=scalar.fit_transform(df_RV_ts[[\"sub_int_RV\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "995d9083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>sub_int_RV</th>\n",
       "      <th>sub_int_num</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>sub_int_RV_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-5</td>\n",
       "      <td>-0.208285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-11</td>\n",
       "      <td>-0.453866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-16</td>\n",
       "      <td>-0.569259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-31</td>\n",
       "      <td>-0.428690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>93-62</td>\n",
       "      <td>-0.540259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735915</th>\n",
       "      <td>32686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32686</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735916</th>\n",
       "      <td>32690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32690</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735917</th>\n",
       "      <td>32712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32712</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735918</th>\n",
       "      <td>32746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32746</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735919</th>\n",
       "      <td>32758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>104-32758</td>\n",
       "      <td>-0.793956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25735920 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          time_id  sub_int_RV  sub_int_num  stock_id     row_id  \\\n",
       "0               5    0.000329            1        93       93-5   \n",
       "1              11    0.000191            1        93      93-11   \n",
       "2              16    0.000126            1        93      93-16   \n",
       "3              31    0.000205            1        93      93-31   \n",
       "4              62    0.000142            1        93      93-62   \n",
       "...           ...         ...          ...       ...        ...   \n",
       "25735915    32686    0.000000           60       104  104-32686   \n",
       "25735916    32690    0.000000           60       104  104-32690   \n",
       "25735917    32712    0.000000           60       104  104-32712   \n",
       "25735918    32746    0.000000           60       104  104-32746   \n",
       "25735919    32758    0.000000           60       104  104-32758   \n",
       "\n",
       "          sub_int_RV_norm  \n",
       "0               -0.208285  \n",
       "1               -0.453866  \n",
       "2               -0.569259  \n",
       "3               -0.428690  \n",
       "4               -0.540259  \n",
       "...                   ...  \n",
       "25735915        -0.793956  \n",
       "25735916        -0.793956  \n",
       "25735917        -0.793956  \n",
       "25735918        -0.793956  \n",
       "25735919        -0.793956  \n",
       "\n",
       "[25735920 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RV_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de450e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"21\" halign=\"left\">sub_int_RV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_int_num</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-1000</th>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>3.818799e-07</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>2.313288e-04</td>\n",
       "      <td>1.060893e-05</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10000</th>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>3.154886e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>3.777703e-08</td>\n",
       "      <td>3.777703e-08</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10005</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>4.375100e-04</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>2.552987e-03</td>\n",
       "      <td>5.364106e-04</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10017</th>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>6.771948e-05</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>3.104404e-03</td>\n",
       "      <td>1.224910e-03</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.003287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0-10030</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>2.586782e-04</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>4.842470e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9972</th>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>2.503467e-04</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>9.916624e-05</td>\n",
       "      <td>1.809852e-04</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9973</th>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>9.650211e-04</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>1.862600e-03</td>\n",
       "      <td>7.668418e-04</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.002115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9976</th>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>7.203531e-04</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>5.946683e-04</td>\n",
       "      <td>1.509652e-04</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9988</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.957402e-04</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.440137e-04</td>\n",
       "      <td>3.200939e-05</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99-9993</th>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>1.798617e-04</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>2.728767e-04</td>\n",
       "      <td>2.108380e-04</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows  60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sub_int_RV                                                        \\\n",
       "sub_int_num         1         2         3         4         5             6    \n",
       "row_id                                                                         \n",
       "0-1000        0.000341  0.000000  0.000023  0.000000  0.000170  3.818799e-07   \n",
       "0-10000       0.000290  0.000191  0.000087  0.000193  0.000241  3.154886e-04   \n",
       "0-10005       0.000000  0.000000  0.001554  0.002177  0.002303  4.375100e-04   \n",
       "0-10017       0.000142  0.000142  0.001464  0.001086  0.000068  6.771948e-05   \n",
       "0-10030       0.000327  0.000058  0.000293  0.000842  0.000120  2.586782e-04   \n",
       "...                ...       ...       ...       ...       ...           ...   \n",
       "99-9972       0.000197  0.000181  0.000171  0.000172  0.000369  2.503467e-04   \n",
       "99-9973       0.000821  0.000346  0.000691  0.001591  0.000863  9.650211e-04   \n",
       "99-9976       0.000569  0.001101  0.001002  0.000430  0.000797  7.203531e-04   \n",
       "99-9988       0.000040  0.000069  0.000123  0.000056  0.000016  1.957402e-04   \n",
       "99-9993       0.000249  0.000179  0.000155  0.000025  0.000325  1.798617e-04   \n",
       "\n",
       "                                                     ...                      \\\n",
       "sub_int_num        7         8         9         10  ...        51        52   \n",
       "row_id                                               ...                       \n",
       "0-1000       0.000089  0.000552  0.000012  0.000000  ...  0.000265  0.000000   \n",
       "0-10000      0.000000  0.000247  0.000265  0.000000  ...  0.000202  0.000375   \n",
       "0-10005      0.000617  0.001199  0.002306  0.001215  ...  0.000000  0.000486   \n",
       "0-10017      0.000899  0.000064  0.000593  0.000451  ...  0.000029  0.000000   \n",
       "0-10030      0.000221  0.000436  0.000099  0.000008  ...  0.000410  0.000437   \n",
       "...               ...       ...       ...       ...  ...       ...       ...   \n",
       "99-9972      0.000349  0.000356  0.000390  0.000050  ...  0.000075  0.000185   \n",
       "99-9973      0.000504  0.001925  0.000641  0.000382  ...  0.001081  0.001095   \n",
       "99-9976      0.000586  0.000538  0.000570  0.000781  ...  0.000508  0.000406   \n",
       "99-9988      0.000071  0.000095  0.000063  0.000030  ...  0.000034  0.000176   \n",
       "99-9993      0.000080  0.000125  0.000126  0.000205  ...  0.000099  0.000370   \n",
       "\n",
       "                                                                   \\\n",
       "sub_int_num        53        54        55        56            57   \n",
       "row_id                                                              \n",
       "0-1000       0.000214  0.000003  0.000000  0.000118  2.313288e-04   \n",
       "0-10000      0.000616  0.000564  0.000000  0.000023  3.777703e-08   \n",
       "0-10005      0.000050  0.001761  0.001617  0.001801  2.552987e-03   \n",
       "0-10017      0.001293  0.002092  0.000994  0.000848  3.104404e-03   \n",
       "0-10030      0.000004  0.000215  0.000457  0.000183  4.842470e-04   \n",
       "...               ...       ...       ...       ...           ...   \n",
       "99-9972      0.000314  0.000318  0.000115  0.000143  9.916624e-05   \n",
       "99-9973      0.000425  0.000789  0.001295  0.000596  1.862600e-03   \n",
       "99-9976      0.000662  0.000338  0.000710  0.000179  5.946683e-04   \n",
       "99-9988      0.000140  0.000129  0.000175  0.000019  1.440137e-04   \n",
       "99-9993      0.000929  0.000328  0.000251  0.000204  2.728767e-04   \n",
       "\n",
       "                                               \n",
       "sub_int_num            58        59        60  \n",
       "row_id                                         \n",
       "0-1000       1.060893e-05  0.000111  0.000288  \n",
       "0-10000      3.777703e-08  0.000020  0.000310  \n",
       "0-10005      5.364106e-04  0.000872  0.000000  \n",
       "0-10017      1.224910e-03  0.001316  0.003287  \n",
       "0-10030      0.000000e+00  0.000756  0.000005  \n",
       "...                   ...       ...       ...  \n",
       "99-9972      1.809852e-04  0.000334  0.000089  \n",
       "99-9973      7.668418e-04  0.001035  0.002115  \n",
       "99-9976      1.509652e-04  0.000388  0.000403  \n",
       "99-9988      3.200939e-05  0.000041  0.000007  \n",
       "99-9993      2.108380e-04  0.000126  0.000353  \n",
       "\n",
       "[428932 rows x 60 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RV_ts.pivot(index=\"row_id\",columns=[\"sub_int_num\"],values=[\"sub_int_RV\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "677c1b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target=pd.read_csv(\"../raw_data/kaggle_ORVP/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "252d6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target[\"row_id\"]=df_target[\"stock_id\"].astype(int).astype(str)+\"-\"+df_target[\"time_id\"].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fdb28caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0-62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>126</td>\n",
       "      <td>32751</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>126-32751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>126</td>\n",
       "      <td>32753</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>126-32753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>126</td>\n",
       "      <td>32758</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>126-32758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>126</td>\n",
       "      <td>32763</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>126-32763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>126</td>\n",
       "      <td>32767</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>126-32767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stock_id  time_id    target     row_id\n",
       "0              0        5  0.004136        0-5\n",
       "1              0       11  0.001445       0-11\n",
       "2              0       16  0.002168       0-16\n",
       "3              0       31  0.002195       0-31\n",
       "4              0       62  0.001747       0-62\n",
       "...          ...      ...       ...        ...\n",
       "428927       126    32751  0.003461  126-32751\n",
       "428928       126    32753  0.003113  126-32753\n",
       "428929       126    32758  0.004070  126-32758\n",
       "428930       126    32763  0.003357  126-32763\n",
       "428931       126    32767  0.002090  126-32767\n",
       "\n",
       "[428932 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b2a07cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy.loc[:,\"sub_int_num\"]=np.nan\n",
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy.loc[:,\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7c432cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([386036, 60])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07885f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([386036, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0056627",
   "metadata": {},
   "source": [
    "Not entirely sure what the error code is about, I am literally doing exactly as suggested by the warning. https://stackoverflow.com/questions/23688307/settingwithcopywarning-even-when-using-loc says this is a false positive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596532d4-3c50-4a8e-bbda-8448b8f02b4d",
   "metadata": {},
   "source": [
    "## Experiment: RNN (with some fine tuning) and LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a44c92-9ff1-4909-808f-0a05b6aa2a14",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2721fdfa-a2d2-4461-8a99-0fe183fcbfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In fold 0 :\n",
      "\n",
      "Train set end at 8117 .\n",
      "\n",
      "Test set start at 15516 end at 10890 .\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy.loc[:,\"sub_int_num\"]=np.nan\n",
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy.loc[:,\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "time_split_list=data_processing.time_cross_val_split(list_time=list_time,n_split=1,percent_val_size=10,list_output=True)\n",
    "train_time_id,test_time_id=time_split_list[0][0],time_split_list[0][1]\n",
    "\n",
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "00de91c2-12af-4f4b-953c-8fa907c945c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  1.1259548664093018  epoch  1 has training loss  tensor(0.2896, device='cuda:0')  and validation loss  tensor(0.2389, device='cuda:0') .\n",
      "\n",
      "At  5.657813310623169  epoch  5 has training loss  tensor(0.2545, device='cuda:0')  and validation loss  tensor(0.2361, device='cuda:0') .\n",
      "\n",
      "At  11.313392400741577  epoch  10 has training loss  tensor(0.2538, device='cuda:0')  and validation loss  tensor(0.2427, device='cuda:0') .\n",
      "\n",
      "At  16.896981716156006  epoch  15 has training loss  tensor(0.2530, device='cuda:0')  and validation loss  tensor(0.2357, device='cuda:0') .\n",
      "\n",
      "At  22.79364776611328  epoch  20 has training loss  tensor(0.2530, device='cuda:0')  and validation loss  tensor(0.2363, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  10  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 11  with validation loss:  tensor(0.2350, device='cuda:0') .\n",
      " The total number of epoch trained is  21 .\n",
      " Training completed in:  24.1021409034729 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[-0.0524,  0.1166,  0.3613],\n",
       "                      [ 0.4102, -0.2438, -0.3042],\n",
       "                      [ 0.1017, -0.3535,  0.2945],\n",
       "                      [-0.3145, -0.3647,  0.0260],\n",
       "                      [-0.0218, -0.4941, -0.3822],\n",
       "                      [ 0.2193, -0.3291, -0.1590],\n",
       "                      [-0.4361,  0.0441,  0.4776],\n",
       "                      [ 0.0271,  0.1691, -0.2051],\n",
       "                      [-0.2331, -0.4190, -0.2371],\n",
       "                      [ 0.1960, -0.1463,  0.2876],\n",
       "                      [ 0.5642, -0.0635, -0.1513],\n",
       "                      [ 0.3667, -0.1713, -0.3825],\n",
       "                      [ 0.0795,  0.2197,  0.1175],\n",
       "                      [-0.4910, -0.5349, -0.0316],\n",
       "                      [ 0.0243, -0.0835,  0.3983],\n",
       "                      [-0.1049,  0.2092,  0.1669],\n",
       "                      [ 0.0683, -0.2225, -0.0558],\n",
       "                      [ 0.0268,  0.4545, -0.1466],\n",
       "                      [ 0.0548,  0.6002, -0.4397],\n",
       "                      [ 0.0124,  0.4542, -0.1003],\n",
       "                      [ 0.3318, -0.1818, -0.0419],\n",
       "                      [ 0.0542,  0.3127,  0.2811],\n",
       "                      [ 0.0597,  0.4335,  0.4108],\n",
       "                      [ 0.1343,  0.2494, -0.0172],\n",
       "                      [ 0.3500,  0.4864,  0.3270],\n",
       "                      [-0.4841,  0.1337,  0.2444],\n",
       "                      [-0.4286, -0.3755, -0.5535],\n",
       "                      [-0.0395,  0.1098,  0.2103],\n",
       "                      [-0.2160, -0.2336,  0.0535],\n",
       "                      [ 0.4270,  0.6611,  0.0042],\n",
       "                      [ 0.5384,  0.4582,  0.1764],\n",
       "                      [-0.3215,  0.4249,  0.3971]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([ 0.0565,  0.3750, -0.1814,  0.5064,  0.0070,  0.4297, -0.2707,  0.3682,\n",
       "                       0.1320, -0.1604,  0.3333, -0.2035, -0.2929,  0.4854,  0.3049,  0.2397,\n",
       "                       0.2061, -0.2553,  0.2978,  0.2901,  0.0375, -0.1228, -0.0772,  0.1586,\n",
       "                      -0.3151,  0.0313,  0.4861, -0.0483, -0.3051,  0.0523,  0.3857,  0.4430],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[ 0.0638,  0.0879, -0.0658,  ..., -0.0118,  0.1422, -0.1496],\n",
       "                      [-0.0146, -0.0710, -0.2644,  ...,  0.1242,  0.0106,  0.1596],\n",
       "                      [-0.0399,  0.1481,  0.3496,  ..., -0.2518, -0.1111, -0.0876],\n",
       "                      ...,\n",
       "                      [-0.1594, -0.0400, -0.0220,  ...,  0.1323,  0.0036, -0.1439],\n",
       "                      [ 0.0450, -0.1261, -0.1450,  ...,  0.0590, -0.1030,  0.0224],\n",
       "                      [ 0.0299, -0.3106, -0.1435,  ..., -0.1198, -0.2041,  0.1189]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[-0.1008, -0.3354,  0.7316,  ...,  0.0674,  0.0366,  0.0772],\n",
       "                      [-0.1867, -0.1755,  0.0948,  ...,  0.2690, -0.0818,  0.0967],\n",
       "                      [-0.0259,  0.0152, -0.1912,  ..., -0.0153,  0.0754, -0.0735],\n",
       "                      ...,\n",
       "                      [-0.2218, -0.2004,  0.1634,  ...,  0.0215,  0.1279,  0.1362],\n",
       "                      [ 0.1235,  0.0638, -0.1146,  ...,  0.1886,  0.2580,  0.1354],\n",
       "                      [ 0.0140, -0.1508,  0.3804,  ...,  0.1608,  0.0671,  0.3947]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([-0.0746,  0.0153, -0.1192,  0.0897, -0.0128,  0.0187,  0.0530, -0.0135,\n",
       "                       0.0810, -0.0701, -0.1078,  0.0442, -0.1483, -0.0124,  0.1132,  0.1527,\n",
       "                      -0.2337, -0.1655, -0.0988,  0.0312, -0.0196, -0.0160, -0.1407,  0.2001,\n",
       "                       0.0040, -0.0672,  0.1628, -0.1221, -0.0441, -0.1045,  0.0084,  0.0534],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([-0.0179, -0.1047,  0.1247,  0.0297, -0.0712,  0.0735,  0.1310, -0.0467,\n",
       "                      -0.0418, -0.1837, -0.1145,  0.0814, -0.1174, -0.1739, -0.1031,  0.0879,\n",
       "                      -0.0058, -0.0032,  0.0623, -0.1886, -0.0082,  0.1346, -0.2283,  0.0437,\n",
       "                      -0.1526, -0.0548, -0.0153,  0.0578,  0.2273,  0.0087, -0.1287, -0.0376],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[ 0.1488,  0.0533, -0.0347,  0.0504, -0.1152, -0.1995, -0.0429,  0.2020,\n",
       "                       -0.0609,  0.1170,  0.2578,  0.0255,  0.2165, -0.0831,  0.1169,  0.0973,\n",
       "                       -0.0868, -0.0670, -0.0520, -0.1935,  0.0968,  0.0784, -0.1583,  0.1320,\n",
       "                       -0.0675,  0.0219,  0.1515,  0.0754,  0.0931,  0.0379, -0.1848, -0.0431]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([-0.0953], device='cuda:0'))])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_model=training.RV_RNN_conv(n_diff=2, rnn_type=\"rnn\",rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=10000).to(device=device)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer=optim.Adam(RNN_model.parameters(),lr=1e-3)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)\n",
    "\n",
    "train_loss=[]\n",
    "val_loss=[]\n",
    "\n",
    "training.reg_training_loop_rmspe(optimizer=optimizer,model=RNN_model,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=100,ot_steps=10,report_interval=5,eps=0,scaler=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fb1f55fb-a478-4bee-bf57-12189db4383a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff728733640>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.arange(len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b608cb1-05a8-417d-8a2a-8816518de943",
   "metadata": {},
   "source": [
    "LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "cf7afa75-8e8c-4318-9c75-4e4029fdc57d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: rnn_act='tanh' is ignored when using rnn_type='lstm'\n",
      "At  1.3160498142242432  epoch  1 has training loss  tensor(0.2946, device='cuda:0')  and validation loss  tensor(0.2380, device='cuda:0') .\n",
      "\n",
      "At  7.0563132762908936  epoch  5 has training loss  tensor(0.2515, device='cuda:0')  and validation loss  tensor(0.2435, device='cuda:0') .\n",
      "\n",
      "At  13.919213056564331  epoch  10 has training loss  tensor(0.2480, device='cuda:0')  and validation loss  tensor(0.2333, device='cuda:0') .\n",
      "\n",
      "At  21.059534311294556  epoch  15 has training loss  tensor(0.2467, device='cuda:0')  and validation loss  tensor(0.2317, device='cuda:0') .\n",
      "\n",
      "At  27.933840036392212  epoch  20 has training loss  tensor(0.2456, device='cuda:0')  and validation loss  tensor(0.2305, device='cuda:0') .\n",
      "\n",
      "At  34.766276359558105  epoch  25 has training loss  tensor(0.2450, device='cuda:0')  and validation loss  tensor(0.2319, device='cuda:0') .\n",
      "\n",
      "At  41.926653146743774  epoch  30 has training loss  tensor(0.2456, device='cuda:0')  and validation loss  tensor(0.2317, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  10  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 20  with validation loss:  tensor(0.2305, device='cuda:0') .\n",
      " The total number of epoch trained is  30 .\n",
      " Training completed in:  41.926653146743774 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[ 2.8287e-01, -1.2812e-01, -1.9540e-01],\n",
       "                      [ 7.6169e-02,  8.2936e-02,  1.6934e-01],\n",
       "                      [ 8.4557e-02,  1.1125e-01, -4.9658e-02],\n",
       "                      [ 2.3866e-01,  4.2292e-01, -1.4144e-01],\n",
       "                      [ 2.5859e-01,  3.8769e-01,  1.6039e-01],\n",
       "                      [-1.3353e-01, -1.0613e-01,  1.5888e-01],\n",
       "                      [-9.4303e-02,  4.4136e-01,  4.5364e-01],\n",
       "                      [-1.2019e-01, -3.0865e-01, -1.2840e-01],\n",
       "                      [-3.6024e-01, -2.2654e-01, -4.2460e-02],\n",
       "                      [-1.2951e-01,  4.0940e-01, -3.1637e-01],\n",
       "                      [ 2.9412e-02, -2.4630e-01,  1.8425e-01],\n",
       "                      [-1.1579e-01,  9.2390e-02, -3.0648e-01],\n",
       "                      [ 4.4675e-01,  5.8284e-01,  9.3860e-02],\n",
       "                      [ 2.9786e-01, -3.6340e-01, -4.0888e-01],\n",
       "                      [-1.9269e-01, -2.2923e-01, -1.9861e-01],\n",
       "                      [-3.6934e-01,  3.0802e-01,  1.3600e-01],\n",
       "                      [ 1.3577e-01,  2.4975e-01,  2.4985e-01],\n",
       "                      [ 1.9766e-02,  5.2280e-02, -5.8723e-02],\n",
       "                      [ 1.4205e-01, -1.0376e-01, -2.7897e-01],\n",
       "                      [-4.1767e-01,  4.2013e-01, -7.8533e-02],\n",
       "                      [-7.2344e-02,  2.0965e-01,  1.9213e-01],\n",
       "                      [ 2.7601e-01,  3.3062e-01,  2.2457e-02],\n",
       "                      [-2.6737e-03,  2.6045e-01, -4.8382e-02],\n",
       "                      [ 8.6824e-02,  4.7444e-02, -2.5511e-01],\n",
       "                      [-1.2724e-01, -1.7309e-01, -2.6903e-01],\n",
       "                      [-1.6493e-01,  3.7189e-01, -1.9371e-01],\n",
       "                      [ 4.1152e-02,  3.6700e-01,  3.0662e-01],\n",
       "                      [ 1.7308e-01,  4.9467e-01, -7.6316e-02],\n",
       "                      [ 2.8380e-02,  4.5984e-01,  2.8179e-01],\n",
       "                      [ 8.4289e-02, -3.6588e-02,  5.7256e-03],\n",
       "                      [-4.1221e-04,  4.7418e-01,  1.7140e-01],\n",
       "                      [ 7.0668e-02,  4.7931e-01,  3.2046e-01]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([-0.2983, -0.1900, -0.2540, -0.2469, -0.5523,  0.2452, -0.1389, -0.3495,\n",
       "                       0.3158,  0.1968, -0.0741, -0.4061, -0.2949, -0.0117, -0.2292,  0.0847,\n",
       "                      -0.2570,  0.3851, -0.4787, -0.1112,  0.2315, -0.2033,  0.1461,  0.1206,\n",
       "                       0.3610,  0.2838, -0.0439, -0.0175, -0.2979, -0.2187,  0.4394,  0.4289],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[-0.1302,  0.0306,  0.1278,  ..., -0.0159, -0.2059, -0.0626],\n",
       "                      [-0.1780, -0.0298,  0.0826,  ..., -0.1116,  0.1321, -0.0280],\n",
       "                      [ 0.2559, -0.1207,  0.1252,  ...,  0.1487, -0.0985, -0.3161],\n",
       "                      ...,\n",
       "                      [ 0.0318, -0.1098, -0.0774,  ..., -0.3043,  0.3783,  0.2680],\n",
       "                      [ 0.2067, -0.2865,  0.1590,  ..., -0.1575, -0.2147, -0.1338],\n",
       "                      [-0.0373,  0.0044,  0.2288,  ...,  0.1337,  0.1402,  0.2360]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[ 4.3170e-01,  6.2768e-05, -1.6631e-01,  ..., -3.9386e-01,\n",
       "                        4.0146e-02, -2.6923e-01],\n",
       "                      [ 1.6718e-01,  3.0029e-02, -3.5764e-01,  ..., -5.8933e-02,\n",
       "                       -8.0800e-02, -2.8373e-01],\n",
       "                      [ 1.2000e-01,  1.4232e-01, -2.8669e-02,  ..., -2.7607e-01,\n",
       "                        2.6044e-01, -3.9581e-01],\n",
       "                      ...,\n",
       "                      [-7.5897e-01, -8.8791e-03,  3.4001e-01,  ..., -7.7025e-01,\n",
       "                       -5.4125e-03,  2.7048e-01],\n",
       "                      [ 3.0025e-01,  6.3299e-01,  1.3490e-02,  ...,  4.5537e-01,\n",
       "                       -1.1574e-01, -1.8971e-01],\n",
       "                      [ 6.3166e-02, -2.5839e-02,  1.3114e-01,  ..., -7.8299e-01,\n",
       "                        9.9837e-02, -2.0265e-01]], device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([-0.4938, -0.2677, -0.1083, -0.1267,  0.1184, -0.5709, -0.0937,  0.1480,\n",
       "                      -0.3691,  0.0629, -0.2898, -0.0205, -0.4146,  0.1555, -0.1239, -0.2336,\n",
       "                      -0.0042, -0.1201, -0.4351, -0.2019, -0.0112, -0.0164, -0.2845, -0.0906,\n",
       "                       0.1414, -0.0078, -0.0382,  0.1062, -0.2026, -0.6243,  0.0657,  0.1646,\n",
       "                       0.4150, -0.0509, -0.0890, -0.0664,  0.1950,  0.0259, -0.0726,  0.0330,\n",
       "                       0.4827, -0.1783, -0.0879,  0.1549, -0.4941, -0.0483,  0.0864,  0.1655,\n",
       "                      -0.2236, -0.1031,  0.3385,  0.1159,  0.3644, -0.0486, -0.0374,  0.2406,\n",
       "                       0.0616, -0.1644,  0.0086,  0.0880, -0.1338,  0.3830,  0.0269,  0.1815,\n",
       "                      -0.0203, -0.0719,  0.1459,  0.1237, -0.2315,  0.0912, -0.0028,  0.0012,\n",
       "                       0.0030,  0.0704, -0.0049, -0.1124, -0.1562,  0.0261,  0.0173,  0.0719,\n",
       "                       0.0114, -0.1360, -0.0924, -0.0868,  0.0977,  0.0385, -0.0797,  0.0062,\n",
       "                       0.0223,  0.0442, -0.0495, -0.0977, -0.1472,  0.2238,  0.0094, -0.1477,\n",
       "                       0.1381, -0.2422,  0.1109, -0.1225,  0.0124, -0.0261, -0.1858,  0.0349,\n",
       "                       0.0992, -0.1370, -0.1795,  0.1219, -0.6650,  0.0365, -0.4488,  0.0020,\n",
       "                       0.0108, -0.2535, -0.0453, -0.0139, -0.0034, -0.2134, -0.1345, -0.1528,\n",
       "                      -0.0756, -0.3250,  0.0862,  0.1196, -0.0274,  0.3972, -0.0365, -0.1682],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([-0.3876, -0.2218, -0.0016,  0.0718, -0.1357, -0.5576, -0.2660,  0.0416,\n",
       "                      -0.4279, -0.0884, -0.2587, -0.2049, -0.3352, -0.0780,  0.0269, -0.1108,\n",
       "                      -0.0823, -0.3417, -0.4297,  0.0739, -0.2420, -0.1294, -0.3609,  0.1001,\n",
       "                      -0.1129,  0.0335, -0.2348, -0.0859, -0.2399, -0.6554,  0.0296,  0.0122,\n",
       "                       0.2893, -0.3290, -0.1613,  0.0526,  0.1214,  0.0397, -0.2420,  0.1235,\n",
       "                       0.2657, -0.0858,  0.1642,  0.2007, -0.2517,  0.0983, -0.1783,  0.3025,\n",
       "                      -0.0849,  0.0182,  0.1420,  0.0705,  0.1836,  0.0451,  0.1148,  0.2419,\n",
       "                       0.3495,  0.0256, -0.0721, -0.1726, -0.2092,  0.2427,  0.0896,  0.1569,\n",
       "                      -0.1029,  0.1029,  0.1405,  0.1496, -0.2720,  0.0941,  0.1371, -0.3311,\n",
       "                       0.0019, -0.1920, -0.0989, -0.0573, -0.1488,  0.0354, -0.0782,  0.0748,\n",
       "                       0.0541,  0.1308, -0.1617,  0.0368,  0.1072, -0.0883,  0.1133,  0.0426,\n",
       "                       0.0415,  0.0324,  0.0934, -0.1891, -0.0834, -0.0170, -0.0410, -0.1194,\n",
       "                       0.1962, -0.0747, -0.1705,  0.0594, -0.0857, -0.0354,  0.0855,  0.1224,\n",
       "                       0.1827, -0.2131,  0.0654,  0.0422, -0.4033, -0.0885, -0.2362, -0.0168,\n",
       "                      -0.1178, -0.1081, -0.1814,  0.0382,  0.0984, -0.1232, -0.2019, -0.1462,\n",
       "                       0.0299, -0.3844, -0.1802,  0.1078, -0.2487,  0.2704, -0.0377, -0.1184],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[-0.1061, -0.2874,  0.0858,  0.0568, -0.1293, -0.2087,  0.1499, -0.1795,\n",
       "                        0.0724, -0.2038, -0.1536, -0.0927,  0.6361, -0.1503,  0.3629, -0.1354,\n",
       "                        0.2004, -0.0782,  0.0727, -0.1520, -0.1786, -0.0288, -0.1435,  0.1596,\n",
       "                       -0.0098, -0.1415,  0.1112, -0.1463, -0.2588, -0.1183,  0.0861,  0.0849]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([-0.1002], device='cuda:0'))])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_model=training.RV_RNN_conv(n_diff=2, rnn_type=\"lstm\",rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=10000).to(device=device)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer=optim.Adam(RNN_model.parameters(),lr=1e-3)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=512,shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=512,shuffle=True, num_workers =4, pin_memory=True)\n",
    "\n",
    "train_loss=[]\n",
    "val_loss=[]\n",
    "\n",
    "training.reg_training_loop_rmspe(optimizer=optimizer,model=RNN_model,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=100,ot_steps=10,report_interval=5,eps=0,scaler=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5aa699c1-a918-4831-9f1b-8697e25bd98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff7288565f0>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.arange(len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c408726",
   "metadata": {},
   "source": [
    "## Training with native values, with a 10000 times scaler on input. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc50c5",
   "metadata": {},
   "source": [
    "A key issue with our input timeseries is that all values are extremely close to zero, so a 10000 times scaler can help with expanding them a little. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2efd16ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device=(torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b95e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model=training.RV_RNN_conv(n_diff=4,rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=10000).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3846a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer=optim.Adam(RNN_model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "55dd6fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=256,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=256,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "292fcf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "810267b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  2.841204881668091  epoch  1 has training loss  tensor(0.2701, device='cuda:0')  and validation loss  tensor(0.2366, device='cuda:0') .\n",
      "\n",
      "At  12.692814350128174  epoch  5 has training loss  tensor(0.2536, device='cuda:0')  and validation loss  tensor(0.2370, device='cuda:0') .\n",
      "\n",
      "At  24.804923057556152  epoch  10 has training loss  tensor(0.2527, device='cuda:0')  and validation loss  tensor(0.2350, device='cuda:0') .\n",
      "\n",
      "At  36.860355615615845  epoch  15 has training loss  tensor(0.2519, device='cuda:0')  and validation loss  tensor(0.2352, device='cuda:0') .\n",
      "\n",
      "At  49.09467816352844  epoch  20 has training loss  tensor(0.2518, device='cuda:0')  and validation loss  tensor(0.2364, device='cuda:0') .\n",
      "\n",
      "At  61.199227809906006  epoch  25 has training loss  tensor(0.2510, device='cuda:0')  and validation loss  tensor(0.2349, device='cuda:0') .\n",
      "\n",
      "At  73.4724633693695  epoch  30 has training loss  tensor(0.2506, device='cuda:0')  and validation loss  tensor(0.2344, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  10  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 23  with validation loss:  tensor(0.2343, device='cuda:0') .\n",
      " The total number of epoch trained is  33 .\n",
      " Training completed in:  80.75830578804016 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[-1.3013e-02,  3.8937e-01,  2.7331e-01, -7.7134e-02, -6.5391e-02],\n",
       "                      [-2.4403e-02, -3.2814e-02, -2.7695e-02,  1.0576e-01,  8.8450e-02],\n",
       "                      [ 2.5078e-02,  4.2850e-01,  1.4450e-01, -2.3749e-01, -1.4540e-01],\n",
       "                      [-1.5259e-02,  2.8654e-02, -2.5478e-01, -2.4515e-01, -7.4321e-02],\n",
       "                      [-2.5169e-02, -1.9296e-01, -4.6623e-02, -1.3934e-01,  2.0372e-01],\n",
       "                      [ 1.4997e-03,  3.1609e-01,  4.8015e-01,  3.6515e-01,  1.2458e-01],\n",
       "                      [-3.5017e-01, -3.9541e-01,  1.0655e-01,  1.0083e-01,  3.1811e-02],\n",
       "                      [ 3.9903e-01,  8.1790e-02,  3.0594e-01, -2.8731e-01, -2.2762e-01],\n",
       "                      [ 1.1225e-01,  5.7909e-01,  5.4034e-01, -4.9363e-02, -1.6414e-01],\n",
       "                      [-1.4101e-01, -3.6283e-01, -4.2917e-01, -2.6336e-01, -6.1351e-02],\n",
       "                      [ 2.1715e-01,  5.1638e-01, -1.4776e-01, -1.6922e-01, -1.0258e-01],\n",
       "                      [ 2.6874e-01,  2.5141e-01,  9.6520e-02, -1.4923e-01, -9.9994e-02],\n",
       "                      [-6.7987e-02,  7.4953e-01,  3.8641e-01,  2.3234e-01,  1.4717e-01],\n",
       "                      [ 3.8860e-02, -2.0319e-01, -4.3208e-01, -2.7799e-01, -6.5091e-02],\n",
       "                      [ 5.1128e-01,  6.1839e-01,  1.1226e-01, -1.0994e-01, -6.8997e-02],\n",
       "                      [-3.0949e-05, -2.7831e-02, -9.8439e-02, -5.5426e-02,  1.6215e-01],\n",
       "                      [-3.1145e-01, -6.1889e-01,  1.5116e-01, -1.3925e-03, -2.1665e-02],\n",
       "                      [ 9.4889e-03, -2.3916e-01,  3.0081e-01,  3.9099e-01,  1.0649e-01],\n",
       "                      [-8.7631e-02, -3.7799e-01, -5.4040e-01, -3.2803e-01, -9.8980e-02],\n",
       "                      [-2.5052e-02,  3.5925e-01,  1.3044e-01, -6.9229e-02, -1.0065e-02],\n",
       "                      [ 3.4754e-03, -4.0523e-02,  2.8313e-02,  1.1535e-01,  7.7040e-02],\n",
       "                      [-2.2990e-02, -6.9230e-02, -1.2776e-01, -1.1016e-01, -4.8677e-02],\n",
       "                      [ 2.5398e-01, -1.5076e-01,  9.2794e-02, -1.7250e-01,  1.4736e-02],\n",
       "                      [-3.8122e-02, -3.0778e-01, -4.4675e-01, -1.4981e-01,  8.1686e-02],\n",
       "                      [ 2.6809e-01, -4.9744e-01, -2.6351e-01,  2.3446e-01,  1.2846e-01],\n",
       "                      [ 2.7063e-02,  1.3496e-01, -1.3191e-01, -4.4728e-02,  7.4260e-02],\n",
       "                      [-4.9552e-03, -1.7302e-02, -1.3783e-01, -1.6517e-01, -8.2923e-02],\n",
       "                      [ 1.9944e-04,  8.0016e-02,  4.0945e-02, -1.2355e-01, -9.3174e-02],\n",
       "                      [ 2.1459e-02, -3.3950e-01,  9.8456e-02,  2.0546e-01,  4.4724e-02],\n",
       "                      [ 9.6839e-03,  8.9200e-03,  1.7458e-01,  2.4485e-01,  1.0483e-01],\n",
       "                      [ 1.8363e-01,  5.7163e-01,  6.0951e-01,  2.6567e-01,  1.8908e-02],\n",
       "                      [ 4.2079e-01,  7.3438e-02, -1.3992e-01,  4.8925e-02,  3.1248e-01]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([ 1.2628e-02,  2.6932e-02, -1.4197e-01,  2.5670e-02,  7.9795e-02,\n",
       "                       9.7121e-04,  1.9222e-01, -5.3905e-03,  2.0546e-01,  2.5116e-02,\n",
       "                       3.2769e-02, -5.7999e-02,  3.2334e-02, -5.3210e-02, -8.8886e-02,\n",
       "                       2.0458e-02, -1.4031e-02,  1.3967e-02,  3.6471e-02, -1.0130e-02,\n",
       "                      -4.0863e-05,  3.5490e-02,  1.2664e-02, -5.2900e-02, -9.5596e-02,\n",
       "                      -4.3202e-03,  7.3360e-03,  2.5692e-03, -4.0112e-03, -1.1612e-02,\n",
       "                      -2.5158e-01, -2.1998e-02], device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[ 0.3098, -0.0379, -0.0749,  ...,  0.0092,  0.0700,  0.5764],\n",
       "                      [-0.0177, -0.0479,  0.1101,  ..., -0.0484, -0.0547,  0.0155],\n",
       "                      [ 0.1967,  0.1626,  0.1815,  ..., -0.1098,  0.2899,  0.0953],\n",
       "                      ...,\n",
       "                      [-0.1386, -0.1555,  0.0913,  ..., -0.2777, -0.0866, -0.1767],\n",
       "                      [ 0.0174, -0.2074, -0.0237,  ..., -0.1728,  0.1267,  0.0314],\n",
       "                      [-0.0817,  0.0737, -0.0603,  ..., -0.0139,  0.0928,  0.1602]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[ 0.3250, -0.0508, -0.1123,  ..., -0.5073,  0.0732, -0.1378],\n",
       "                      [ 0.6863,  0.0797,  0.4058,  ..., -0.3456, -0.5240, -0.1203],\n",
       "                      [ 0.1124,  0.2424,  0.0326,  ..., -0.3729, -0.2419,  0.0278],\n",
       "                      ...,\n",
       "                      [ 0.1746, -0.0447,  0.0181,  ..., -0.2048,  0.1816,  0.0188],\n",
       "                      [ 0.1996,  0.6002,  0.1919,  ...,  0.2364,  0.1710, -0.4626],\n",
       "                      [-0.0490, -0.1574, -0.2917,  ..., -0.6026,  0.3585, -0.3754]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([-0.1178, -0.0024, -0.2019,  0.1001,  0.1473, -0.0491, -0.1332, -0.0582,\n",
       "                       0.1112,  0.0852,  0.0917,  0.0846, -0.0644, -0.0925, -0.1094, -0.0322,\n",
       "                      -0.2289, -0.0290,  0.0346, -0.1418,  0.0221,  0.0553,  0.0716,  0.2255,\n",
       "                       0.0076, -0.0589,  0.1047, -0.1326, -0.0157, -0.0875, -0.1506,  0.1891],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([ 3.2828e-02, -2.6533e-01, -6.7540e-02,  5.3128e-02,  1.3619e-01,\n",
       "                       8.7140e-02,  7.9682e-02, -1.9066e-01,  1.1935e-01,  6.2576e-02,\n",
       "                      -1.3442e-01,  1.0371e-02,  7.3204e-02, -1.6927e-01,  4.8571e-02,\n",
       "                      -1.3515e-01, -1.3753e-01,  5.4045e-02, -1.0209e-01, -4.2235e-03,\n",
       "                       1.6207e-01,  6.6100e-02, -1.9344e-01, -7.8733e-02, -4.8117e-02,\n",
       "                       2.7672e-01, -7.6910e-02,  1.7189e-01,  5.6509e-02,  8.6780e-03,\n",
       "                       2.5435e-02, -5.3751e-05], device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[-0.0499, -0.1899,  0.0255, -0.0264,  0.0046, -0.1370,  0.0507, -0.2109,\n",
       "                        0.3328, -0.0019,  0.0520, -0.2140, -0.1467, -0.3020,  0.0137,  0.0473,\n",
       "                        0.0489, -0.1000,  0.2518,  0.1416,  0.0663, -0.1541,  0.0913,  0.3280,\n",
       "                       -0.0199, -0.2331,  0.2933, -0.0358,  0.1127,  0.0526,  0.0145,  0.2203]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([0.1783], device='cuda:0'))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.reg_training_loop_rmspe(optimizer=optimizer,model=RNN_model,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=100,ot_steps=10,report_interval=5,eps=0,scaler=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66a81f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen_conv.frozen_conv.weight False\n",
      "linear_proj_input.weight True\n",
      "linear_proj_input.bias True\n",
      "RNN_layer.weight_ih_l0 True\n",
      "RNN_layer.weight_hh_l0 True\n",
      "RNN_layer.bias_ih_l0 True\n",
      "RNN_layer.bias_hh_l0 True\n",
      "linear_post_rnn.weight True\n",
      "linear_post_rnn.bias True\n"
     ]
    }
   ],
   "source": [
    "for name,param in RNN_model.named_parameters():\n",
    "    print(name,param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e88bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c4ccf4",
   "metadata": {},
   "source": [
    "Above is an example of the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "05ee5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.arange(len(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ebe3da0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff63811f6a0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b72925",
   "metadata": {},
   "source": [
    "## Try to normalize only the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2324a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model_norm_ts=training.RV_RNN_conv(n_diff=4,rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=1).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68516afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_norm_ts=optim.Adam(RNN_model_norm_ts.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae9de7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy.loc[:,\"sub_int_num\"]=np.nan\n",
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy.loc[:,\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV_norm\"],df_ts_feat=df_RV_ts,df_target=df_target)\n",
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV_norm\"],df_ts_feat=df_RV_ts,df_target=df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "509b7bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=256,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=256,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4056c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0a66b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  2.522658109664917  epoch  1 has training loss  tensor(283.0392, device='cuda:0')  and validation loss  tensor(43.5655, device='cuda:0') .\n",
      "\n",
      "At  12.718735694885254  epoch  5 has training loss  tensor(17.9191, device='cuda:0')  and validation loss  tensor(37.9335, device='cuda:0') .\n",
      "\n",
      "At  26.009549140930176  epoch  10 has training loss  tensor(7.6101, device='cuda:0')  and validation loss  tensor(3.5446, device='cuda:0') .\n",
      "\n",
      "At  39.161351442337036  epoch  15 has training loss  tensor(2.6315, device='cuda:0')  and validation loss  tensor(1.4925, device='cuda:0') .\n",
      "\n",
      "At  52.47147059440613  epoch  20 has training loss  tensor(2.2603, device='cuda:0')  and validation loss  tensor(1.0233, device='cuda:0') .\n",
      "\n",
      "At  65.79581642150879  epoch  25 has training loss  tensor(2.3343, device='cuda:0')  and validation loss  tensor(1.7118, device='cuda:0') .\n",
      "\n",
      "At  79.334139585495  epoch  30 has training loss  tensor(2.6137, device='cuda:0')  and validation loss  tensor(1.8254, device='cuda:0') .\n",
      "\n",
      "At  92.26322913169861  epoch  35 has training loss  tensor(2.3198, device='cuda:0')  and validation loss  tensor(3.5959, device='cuda:0') .\n",
      "\n",
      "At  105.20642518997192  epoch  40 has training loss  tensor(2.4839, device='cuda:0')  and validation loss  tensor(1.4842, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  20  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 21  with validation loss:  tensor(0.5534, device='cuda:0') .\n",
      " The total number of epoch trained is  41 .\n",
      " Training completed in:  107.89736342430115 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[-0.0045, -0.0901,  0.1132, -0.2228, -0.1803],\n",
       "                      [-0.1997, -0.3297,  0.1452,  0.3443, -0.0067],\n",
       "                      [-0.0107, -0.2273,  0.4138,  0.0233, -0.1586],\n",
       "                      [-0.0889,  0.3350, -0.1367, -0.1448, -0.4007],\n",
       "                      [ 0.2829, -0.0629,  0.1113, -0.0430,  0.1067],\n",
       "                      [ 0.3070,  0.1270,  0.4153,  0.1222,  0.0056],\n",
       "                      [ 0.1668, -0.4291, -0.0132, -0.2160,  0.2345],\n",
       "                      [ 0.1613, -0.3407,  0.0467,  0.4288,  0.0861],\n",
       "                      [ 0.0653, -0.0928, -0.0263, -0.2540, -0.0603],\n",
       "                      [ 0.0812, -0.2569, -0.0038,  0.1708, -0.1246],\n",
       "                      [ 0.3743,  0.4313, -0.1810, -0.2795,  0.0187],\n",
       "                      [ 0.0401,  0.0395,  0.0658, -0.1657, -0.1592],\n",
       "                      [-0.0402,  0.3869,  0.3598,  0.2136,  0.0075],\n",
       "                      [-0.0650, -0.0289,  0.2271,  0.3552,  0.2315],\n",
       "                      [ 0.3678,  0.1282, -0.2009,  0.3654,  0.2514],\n",
       "                      [-0.0062, -0.3464, -0.3324, -0.0290, -0.0126],\n",
       "                      [-0.0944,  0.2014,  0.1281,  0.3473,  0.0057],\n",
       "                      [ 0.3253, -0.0096, -0.2627,  0.0400,  0.1282],\n",
       "                      [ 0.4956, -0.1440,  0.1999, -0.2800, -0.1951],\n",
       "                      [ 0.0501,  0.2608,  0.1987,  0.1601, -0.1392],\n",
       "                      [-0.0112, -0.1569,  0.1500, -0.0583, -0.1004],\n",
       "                      [ 0.3107,  0.2088, -0.0550,  0.1293,  0.1153],\n",
       "                      [-0.2866,  0.2308, -0.2633, -0.0656,  0.0422],\n",
       "                      [ 0.3230,  0.0646, -0.2153, -0.2714, -0.1071],\n",
       "                      [ 0.2060,  0.1244, -0.3153, -0.2981,  0.5972],\n",
       "                      [-0.1061,  0.0378, -0.1545, -0.4512, -0.2370],\n",
       "                      [ 0.3597, -0.0376,  0.3642, -0.0549, -0.1750],\n",
       "                      [-0.0804, -0.3709,  0.0436, -0.5300,  0.4364],\n",
       "                      [-0.1882, -0.1901, -0.0169,  0.0589, -0.0450],\n",
       "                      [ 0.0748,  0.4169, -0.3247, -0.0675, -0.7775],\n",
       "                      [-0.1283, -0.1630,  0.2123, -0.1098, -0.1756],\n",
       "                      [-0.1097,  0.2151, -0.0023, -0.3765,  0.0132]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([-0.0057, -0.1013, -0.0074,  0.2599,  0.1890,  0.1345, -0.2150,  0.0712,\n",
       "                       0.0300,  0.3206,  0.1795,  0.0153,  0.1227,  0.0018,  0.1638, -0.0037,\n",
       "                       0.1344,  0.2068,  0.2299,  0.0294, -0.0055,  0.1430, -0.1299,  0.1851,\n",
       "                       0.1075, -0.0477,  0.1969,  0.1196, -0.0974,  0.0150, -0.0363, -0.0491],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[ 3.7883e-02, -7.4390e-02,  8.1796e-02,  ...,  1.3746e-02,\n",
       "                       -7.0671e-02,  1.1298e-01],\n",
       "                      [-1.7003e-01, -7.9825e-02,  1.1533e-01,  ..., -3.2246e-02,\n",
       "                        6.0445e-02, -2.1969e-03],\n",
       "                      [-1.2022e-01, -7.2477e-02,  4.6330e-02,  ..., -7.7177e-02,\n",
       "                        1.2686e-01, -1.2398e-01],\n",
       "                      ...,\n",
       "                      [ 1.4775e-01, -1.2599e-01,  4.8405e-02,  ..., -9.3319e-02,\n",
       "                       -1.7944e-02,  1.0043e-01],\n",
       "                      [ 1.9351e-01, -4.2060e-02, -1.4521e-02,  ..., -2.4227e-04,\n",
       "                        5.4732e-02,  5.0702e-02],\n",
       "                      [-1.7626e-01,  1.4203e-01, -7.9240e-02,  ..., -1.5068e-04,\n",
       "                        1.0361e-01, -2.5569e-01]], device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[-0.4502, -0.0572, -0.2031,  ..., -0.1551,  0.0523, -0.1695],\n",
       "                      [-0.0814, -0.4613, -0.1111,  ..., -0.0268, -0.0094, -0.2520],\n",
       "                      [ 0.0196, -0.0430, -0.1224,  ...,  0.3012, -0.0557, -0.1092],\n",
       "                      ...,\n",
       "                      [ 0.0309, -0.0523,  0.3242,  ..., -0.3381, -0.2077,  0.0575],\n",
       "                      [-0.0524,  0.1094,  0.1877,  ...,  0.1321, -0.1839, -0.0140],\n",
       "                      [ 0.0234, -0.1200, -0.0735,  ...,  0.1487,  0.0068, -0.1879]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([-0.0868, -0.1199, -0.0193,  0.0328, -0.0508, -0.1069,  0.0045,  0.0335,\n",
       "                       0.1042,  0.0911, -0.1099,  0.0213,  0.0692, -0.0064, -0.0378,  0.1201,\n",
       "                       0.0012, -0.0127, -0.0158,  0.0450,  0.0414,  0.0459, -0.1204,  0.0210,\n",
       "                       0.1474, -0.0206,  0.0538, -0.1286, -0.0392, -0.0545,  0.0740,  0.0011],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([ 0.0416,  0.0699, -0.0982,  0.0742,  0.0536,  0.1397, -0.1213, -0.0425,\n",
       "                      -0.0891,  0.0819, -0.0114, -0.0097,  0.0637,  0.0775,  0.0467, -0.0504,\n",
       "                      -0.0148, -0.0131,  0.0554, -0.0901,  0.0738,  0.0375,  0.1045,  0.0359,\n",
       "                      -0.1340,  0.0005, -0.0602,  0.0842,  0.0283, -0.0201, -0.0855,  0.0435],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[ 3.1699e-05,  1.8070e-05, -2.9846e-04, -2.0921e-04, -2.3639e-05,\n",
       "                        1.6927e-04,  8.7622e-04, -7.0414e-07,  2.3696e-04,  6.3952e-06,\n",
       "                        1.4242e-04,  6.8951e-06,  1.3125e-03, -6.4379e-05,  4.0132e-05,\n",
       "                        1.1604e-05, -5.0481e-05, -1.5871e-04,  4.1738e-04, -1.9004e-04,\n",
       "                        3.3420e-04,  1.4637e-04, -1.8485e-04,  7.9809e-05, -1.3285e-04,\n",
       "                       -1.1879e-04,  1.7192e-04,  4.4917e-04,  4.9060e-05, -1.2610e-04,\n",
       "                        8.2578e-05,  2.0158e-04]], device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([0.0001], device='cuda:0'))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.reg_training_loop_rmspe(optimizer=optimizer_norm_ts,model=RNN_model_norm_ts,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=200,ot_steps=20,report_interval=5,eps=0,scaler=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d7684d",
   "metadata": {},
   "source": [
    "As a remark, I ran above loop twice, the keep learning to same model after the fact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef1351bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen_conv.frozen_conv.weight False\n",
      "linear_proj_input.weight True\n",
      "linear_proj_input.bias True\n",
      "RNN_layer.weight_ih_l0 True\n",
      "RNN_layer.weight_hh_l0 True\n",
      "RNN_layer.bias_ih_l0 True\n",
      "RNN_layer.bias_hh_l0 True\n",
      "linear_post_rnn.weight True\n",
      "linear_post_rnn.bias True\n"
     ]
    }
   ],
   "source": [
    "for name,param in RNN_model_norm_ts.named_parameters():\n",
    "    print(name,param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2bb082d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1802af02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b022072c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd07d2c3b20>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.arange(len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb605a91",
   "metadata": {},
   "source": [
    "It appears that only normalizing input ts is not a good idea. I should consider normalizing both the input and the target. Plus, in above, I fit transformed on both the training and the test set together, that is technically a data leak. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef78913",
   "metadata": {},
   "source": [
    "## Training with normalization on both input and target "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64325299",
   "metadata": {},
   "source": [
    "I have added normalization functionality to dataset creation function, so not we can create the train and test datasets without dataleaking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c3ffa765",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model_norm_ts=training.RV_RNN_conv(n_diff=4,rnn_act=\"tanh\",rnn_drop_out=0,rnn_hidden_size=32,proj_dim=32,rnn_num_layer=1,input_scaler=1).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1190590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_norm_ts=optim.Adam(RNN_model_norm_ts.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a6245db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy.loc[:,\"sub_int_num\"]=np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice: sub_int_RV has been normalized.\n",
      "The mean and std of this feature has been stored in feat_norm_dict\n",
      "Notice: target has been normalized.\n",
      "The mean and std of this feature has been stored in feat_norm_dict\n"
     ]
    }
   ],
   "source": [
    "train_dataset=training.RVdataset(time_id_list=train_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target,norm_feature_dict={\"sub_int_RV\":None,\"target\":None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4d97d6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sub_int_RV': (np.float64(0.0004411965933048684),\n",
       "  np.float64(0.0005610956509180131)),\n",
       " 'target': (np.float64(0.0038471398027541486),\n",
       "  np.float64(0.0029489987966883967))}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.feat_norm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8b790b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_norm_feat_dict=copy.deepcopy(train_dataset.feat_norm_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "40163bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.0038471398027541486), np.float64(0.0029489987966883967))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_norm_feat_dict.pop(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "630660e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sub_int_RV': (np.float64(0.0004411965933048684),\n",
       "  np.float64(0.0005610956509180131)),\n",
       " 'target': (np.float64(0.0038471398027541486),\n",
       "  np.float64(0.0029489987966883967))}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.feat_norm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ee121136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sub_int_RV': (np.float64(0.0004411965933048684),\n",
       "  np.float64(0.0005610956509180131))}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_norm_feat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9622afc7",
   "metadata": {},
   "source": [
    "As a reminder, do not apply normalization to target of test set. I am choosing to force the target input features to share the same mean and std as the test dataset's corresponding features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "de12b187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice: sub_int_RV has been normalized.\n",
      "The mean and std of this feature has been stored in feat_norm_dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine2/Desktop/Realized_Volatility_Prediction_-erdos_deeplearning-/NNetwork/../proj_mod/training.py:301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tab_copy.loc[:,\"sub_int_num\"]=np.nan\n"
     ]
    }
   ],
   "source": [
    "test_dataset=training.RVdataset(time_id_list=test_time_id,ts_features=[\"sub_int_RV\"],df_ts_feat=df_RV_ts,df_target=df_target,norm_feature_dict=test_norm_feat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0f6a5622",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=256,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=256,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8c799fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8f5ab2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At  2.5837647914886475  epoch  1 has training loss  tensor(1.3447, device='cuda:0')  and validation loss  tensor(0.9099, device='cuda:0') .\n",
      "\n",
      "At  13.637297868728638  epoch  5 has training loss  tensor(1.3118, device='cuda:0')  and validation loss  tensor(1.0018, device='cuda:0') .\n",
      "\n",
      "At  27.1261146068573  epoch  10 has training loss  tensor(1.4851, device='cuda:0')  and validation loss  tensor(0.9040, device='cuda:0') .\n",
      "\n",
      "At  40.56305813789368  epoch  15 has training loss  tensor(1.2366, device='cuda:0')  and validation loss  tensor(0.8082, device='cuda:0') .\n",
      "\n",
      "At  53.68483304977417  epoch  20 has training loss  tensor(1.2981, device='cuda:0')  and validation loss  tensor(0.9121, device='cuda:0') .\n",
      "\n",
      "The validation loss has not improved for  20  epochs. Stopping current training loop.\n",
      "\n",
      "Best model state dictionary of this training loop is reloaded.\n",
      "\n",
      "According to validation loss, the best model is reached at epoch 3  with validation loss:  tensor(0.5163, device='cuda:0') .\n",
      " The total number of epoch trained is  23 .\n",
      " Training completed in:  61.67832398414612 .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('frozen_conv.frozen_conv.weight',\n",
       "              tensor([[[-1.,  1.]]], device='cuda:0')),\n",
       "             ('linear_proj_input.weight',\n",
       "              tensor([[-0.2268, -0.0019, -0.3465, -0.2738, -0.1228],\n",
       "                      [-0.0999, -0.2266, -0.2293, -0.0694, -0.0952],\n",
       "                      [-0.0383, -0.4969, -0.2131,  0.2253,  0.2242],\n",
       "                      [-0.2461, -0.4352,  0.2240, -0.0601,  0.2112],\n",
       "                      [-0.0067, -0.0707,  0.0228, -0.0945, -0.0102],\n",
       "                      [ 0.1255, -0.6107,  0.0357, -0.0999,  0.3328],\n",
       "                      [-0.2015,  0.2577, -0.3704, -0.0780, -0.2736],\n",
       "                      [ 0.2182,  0.1349,  0.3229, -0.2284, -0.0712],\n",
       "                      [-0.1641,  0.0769,  0.0832,  0.5318, -0.0151],\n",
       "                      [-0.0727, -0.2932,  0.3951, -0.1076,  0.2585],\n",
       "                      [-0.0039, -0.7517, -0.3426, -0.0303,  0.2568],\n",
       "                      [ 0.1358, -0.0690,  0.2719,  0.6412,  0.0106],\n",
       "                      [ 0.1946, -0.2323,  0.3590,  0.3431, -0.0573],\n",
       "                      [-0.0599,  0.2281, -0.3253,  0.0285, -0.0559],\n",
       "                      [ 0.0439,  0.2913, -0.2481, -0.1171, -0.1365],\n",
       "                      [-0.1332, -0.0961, -0.3869, -0.0265, -0.0695],\n",
       "                      [ 0.3810, -0.4401,  0.2634,  0.4332,  0.3969],\n",
       "                      [ 0.0426, -0.1661,  0.0030,  0.2567, -0.3862],\n",
       "                      [ 0.0621, -0.1444, -0.0391, -0.5483, -0.4964],\n",
       "                      [ 0.4175, -0.3645,  0.4609, -0.3068,  0.0040],\n",
       "                      [-0.0739,  0.2782, -0.2051, -0.2330, -0.0889],\n",
       "                      [ 0.0439, -0.4327,  0.5004,  0.3449,  0.1530],\n",
       "                      [ 0.1516,  0.3444, -0.2418, -0.2729, -0.0595],\n",
       "                      [-0.1365,  0.1046, -0.3214,  0.3111,  0.1322],\n",
       "                      [ 0.0057,  0.2029, -0.3909,  0.3755,  0.0976],\n",
       "                      [ 0.0225, -0.0973, -0.2030,  0.1679, -0.0451],\n",
       "                      [ 0.2900,  0.1554,  0.3819, -0.2500, -0.2028],\n",
       "                      [-0.0987,  0.1982,  0.1404,  0.1128,  0.2886],\n",
       "                      [-0.4575, -0.2473,  0.3186,  0.2867,  0.3073],\n",
       "                      [ 0.2852,  0.3874,  0.0671,  0.0552, -0.2281],\n",
       "                      [ 0.0008, -0.3619,  0.5666, -0.3160,  0.1828],\n",
       "                      [-0.0131, -0.1812, -0.0105,  0.2978,  0.2776]], device='cuda:0')),\n",
       "             ('linear_proj_input.bias',\n",
       "              tensor([-0.0301,  0.1536,  0.0874, -0.2434, -0.1029, -0.0687,  0.0771,  0.0911,\n",
       "                       0.1655,  0.1231, -0.0512, -0.0010, -0.0572,  0.1174,  0.0321,  0.1141,\n",
       "                      -0.0426,  0.2033,  0.0707, -0.1239,  0.0065, -0.0711,  0.0697,  0.1419,\n",
       "                       0.0246,  0.1075, -0.0401, -0.2144, -0.1454,  0.1909,  0.1528, -0.1198],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_ih_l0',\n",
       "              tensor([[ 0.2711,  0.2843, -0.1589,  ...,  0.0971, -0.1698, -0.1431],\n",
       "                      [ 0.1211,  0.0686, -0.1140,  ...,  0.2275, -0.3018, -0.1048],\n",
       "                      [ 0.1148, -0.0981, -0.0673,  ...,  0.1262,  0.3705,  0.0032],\n",
       "                      ...,\n",
       "                      [ 0.0980, -0.0798, -0.2622,  ..., -0.0093,  0.0226, -0.1047],\n",
       "                      [ 0.0402, -0.2460,  0.0112,  ..., -0.3164,  0.1137,  0.1737],\n",
       "                      [-0.0382,  0.1294, -0.1002,  ..., -0.0655,  0.1956, -0.2054]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.weight_hh_l0',\n",
       "              tensor([[-0.3535, -0.4519,  0.2629,  ...,  0.2155,  0.0845,  0.4486],\n",
       "                      [-0.3808, -0.3348, -0.0815,  ...,  0.0424, -0.0884,  0.0428],\n",
       "                      [ 0.1247,  0.2414, -0.3095,  ..., -0.2372, -0.1903, -0.3722],\n",
       "                      ...,\n",
       "                      [ 0.0461, -0.0718, -0.2147,  ..., -0.3539, -0.2352, -0.0040],\n",
       "                      [ 0.1863, -0.0383, -0.1425,  ..., -0.1721, -0.3129, -0.2100],\n",
       "                      [ 0.0689,  0.4036, -0.0676,  ..., -0.1752, -0.0271, -0.4273]],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_ih_l0',\n",
       "              tensor([-0.3552, -0.0702,  0.1972, -0.1882, -0.0741, -0.3179, -0.0153, -0.3232,\n",
       "                       0.0753,  0.1271, -0.1983, -0.0404,  0.2048, -0.0308, -0.1680,  0.1437,\n",
       "                      -0.2506, -0.0054,  0.2398, -0.3153,  0.1272,  0.1019,  0.0751, -0.2818,\n",
       "                       0.2148,  0.0704, -0.0728,  0.1893,  0.2956,  0.0073,  0.1487,  0.2204],\n",
       "                     device='cuda:0')),\n",
       "             ('RNN_layer.bias_hh_l0',\n",
       "              tensor([-0.0653, -0.2784, -0.0290, -0.0705, -0.1681, -0.3053,  0.2173, -0.0009,\n",
       "                       0.0221,  0.1680, -0.2058,  0.0542,  0.1882, -0.1566, -0.1952,  0.2267,\n",
       "                      -0.1829,  0.1256,  0.2660, -0.1718,  0.1246,  0.1132,  0.2129, -0.0650,\n",
       "                      -0.0420,  0.1261, -0.3192,  0.1822, -0.0146, -0.0262,  0.2516,  0.4196],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.weight',\n",
       "              tensor([[ 0.0047,  0.0074, -0.0173, -0.0084, -0.0160,  0.0250,  0.0216,  0.0158,\n",
       "                        0.0222, -0.0074, -0.0159, -0.0107, -0.0154, -0.0015,  0.0195,  0.0039,\n",
       "                        0.0111,  0.0134, -0.0111,  0.0014,  0.0049, -0.0080,  0.0004, -0.0053,\n",
       "                        0.0032,  0.0013, -0.0239, -0.0061,  0.0032,  0.0042, -0.0056,  0.0003]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_post_rnn.bias', tensor([0.0008], device='cuda:0'))])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.reg_training_loop_rmspe(optimizer=optimizer_norm_ts,model=RNN_model_norm_ts,train_loader=train_loader,val_loader=test_loader,list_train_loss=train_loss,list_val_loss=val_loss,device=device,n_epochs=200,ot_steps=20,report_interval=5,eps=0,scaler=1,norm_train_target=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea81cbbb",
   "metadata": {},
   "source": [
    "Oh this over trained quickly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0703dbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen_conv.frozen_conv.weight False\n",
      "linear_proj_input.weight True\n",
      "linear_proj_input.bias True\n",
      "RNN_layer.weight_ih_l0 True\n",
      "RNN_layer.weight_hh_l0 True\n",
      "RNN_layer.bias_ih_l0 True\n",
      "RNN_layer.bias_hh_l0 True\n",
      "linear_post_rnn.weight True\n",
      "linear_post_rnn.bias True\n"
     ]
    }
   ],
   "source": [
    "for name,param in RNN_model_norm_ts.named_parameters():\n",
    "    print(name,param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "20ecaf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[x.cpu() for x in train_loss]\n",
    "val_loss=[x.cpu() for x in val_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b859c9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd07573b700>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x=np.linspace(1,len(train_loss),len(train_loss))\n",
    "\n",
    "plt.scatter(x,train_loss,c=\"blue\")\n",
    "plt.scatter(x,val_loss,c=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e44b27b",
   "metadata": {},
   "source": [
    "As of now, the best outcome comes with \"scaling\" the input timeseries by 10000. Maybe adjust the NN a bit? add some linear and conv layers after the RNN? Multiple layers of RNN? We will see. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
